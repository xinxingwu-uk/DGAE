{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random as rn\n",
    "import os\n",
    "from keras import backend as K\n",
    "import  tensorflow.compat.v1  as tf\n",
    "tf.disable_v2_behavior() \n",
    "import tensorflow as tf\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "# Reproducible\n",
    "seed=0\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "np.random.seed(seed)\n",
    "rn.seed(seed)\n",
    "session_conf =tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "tf.compat.v1.set_random_seed(seed)\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "import scipy.sparse as sp\n",
    "import time\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(r\"../../\")\n",
    "\n",
    "from dgae_alpha_beta.evaluation import get_roc_score\n",
    "from dgae_alpha_beta.input_data import load_data, load_label\n",
    "from dgae_alpha_beta.model import *\n",
    "from dgae_alpha_beta.optimizer import *\n",
    "from dgae_alpha_beta.preprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_no=6\n",
    "data_path=\"../../Datasets/\"\n",
    "path_now=\"./log/\"\n",
    "\n",
    "dataset='citeseer'\n",
    "model_name='DGAE_alpha_beta_feature'\n",
    "\n",
    "dropout=0.0\n",
    "epochs=200\n",
    "features_used=True\n",
    "learning_rate=0.01\n",
    "nb_run=10\n",
    "prop_val=5\n",
    "prop_test=10\n",
    "validation=True\n",
    "verbose=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_init, features_init = load_data(dataset,data_path)\n",
    "num_adj=adj_init.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failure\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201: calling weighted_cross_entropy_with_logits (from tensorflow.python.ops.nn_impl) with targets is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "targets is deprecated, use labels instead\n",
      "Epoch: 0001 training loss= 0.00125 time= 2.61430\n",
      "validation roc= 0.64795 validation ap= 0.68302\n",
      "Epoch: 0002 training loss= 0.00124 time= 0.73601\n",
      "validation roc= 0.72584 validation ap= 0.71394\n",
      "Epoch: 0003 training loss= 0.00121 time= 0.51049\n",
      "validation roc= 0.63824 validation ap= 0.64084\n",
      "Epoch: 0004 training loss= 0.00119 time= 0.67381\n",
      "validation roc= 0.70252 validation ap= 0.71981\n",
      "Epoch: 0005 training loss= 0.00116 time= 0.44915\n",
      "validation roc= 0.79534 validation ap= 0.81117\n",
      "Epoch: 0006 training loss= 0.00110 time= 0.47769\n",
      "validation roc= 0.82517 validation ap= 0.83394\n",
      "Epoch: 0007 training loss= 0.00105 time= 0.48289\n",
      "validation roc= 0.83060 validation ap= 0.83022\n",
      "Epoch: 0008 training loss= 0.00101 time= 0.52077\n",
      "validation roc= 0.84091 validation ap= 0.83643\n",
      "Epoch: 0009 training loss= 0.00099 time= 0.75532\n",
      "validation roc= 0.84935 validation ap= 0.84350\n",
      "Epoch: 0010 training loss= 0.00099 time= 0.47804\n",
      "validation roc= 0.86054 validation ap= 0.85388\n",
      "Epoch: 0011 training loss= 0.00096 time= 0.45290\n",
      "validation roc= 0.87329 validation ap= 0.86714\n",
      "Epoch: 0012 training loss= 0.00094 time= 0.49480\n",
      "validation roc= 0.88344 validation ap= 0.87809\n",
      "Epoch: 0013 training loss= 0.00093 time= 0.52095\n",
      "validation roc= 0.88845 validation ap= 0.88559\n",
      "Epoch: 0014 training loss= 0.00092 time= 0.53027\n",
      "validation roc= 0.89008 validation ap= 0.88763\n",
      "Epoch: 0015 training loss= 0.00092 time= 0.49799\n",
      "validation roc= 0.88936 validation ap= 0.88659\n",
      "Epoch: 0016 training loss= 0.00091 time= 0.50119\n",
      "validation roc= 0.89214 validation ap= 0.88899\n",
      "Epoch: 0017 training loss= 0.00091 time= 0.62238\n",
      "validation roc= 0.89656 validation ap= 0.89397\n",
      "Epoch: 0018 training loss= 0.00090 time= 0.48495\n",
      "validation roc= 0.89934 validation ap= 0.89828\n",
      "Epoch: 0019 training loss= 0.00089 time= 0.52651\n",
      "validation roc= 0.89947 validation ap= 0.90043\n",
      "Epoch: 0020 training loss= 0.00089 time= 0.51949\n",
      "validation roc= 0.89748 validation ap= 0.90031\n",
      "Epoch: 0021 training loss= 0.00088 time= 0.52774\n",
      "validation roc= 0.89627 validation ap= 0.90038\n",
      "Epoch: 0022 training loss= 0.00088 time= 0.51428\n",
      "validation roc= 0.89472 validation ap= 0.89922\n",
      "Epoch: 0023 training loss= 0.00088 time= 0.53282\n",
      "validation roc= 0.89431 validation ap= 0.89810\n",
      "Epoch: 0024 training loss= 0.00087 time= 0.47455\n",
      "validation roc= 0.89538 validation ap= 0.89795\n",
      "Epoch: 0025 training loss= 0.00087 time= 0.51023\n",
      "validation roc= 0.89567 validation ap= 0.89738\n",
      "Epoch: 0026 training loss= 0.00086 time= 0.47470\n",
      "validation roc= 0.89631 validation ap= 0.89774\n",
      "Epoch: 0027 training loss= 0.00086 time= 0.51775\n",
      "validation roc= 0.89767 validation ap= 0.89922\n",
      "Epoch: 0028 training loss= 0.00086 time= 0.46363\n",
      "validation roc= 0.90017 validation ap= 0.90230\n",
      "Epoch: 0029 training loss= 0.00085 time= 0.48412\n",
      "validation roc= 0.90134 validation ap= 0.90447\n",
      "Epoch: 0030 training loss= 0.00085 time= 0.47325\n",
      "validation roc= 0.90365 validation ap= 0.90781\n",
      "Epoch: 0031 training loss= 0.00085 time= 0.47734\n",
      "validation roc= 0.90568 validation ap= 0.91019\n",
      "Epoch: 0032 training loss= 0.00084 time= 0.48965\n",
      "validation roc= 0.90759 validation ap= 0.91243\n",
      "Epoch: 0033 training loss= 0.00084 time= 0.46664\n",
      "validation roc= 0.90986 validation ap= 0.91415\n",
      "Epoch: 0034 training loss= 0.00084 time= 0.52274\n",
      "validation roc= 0.91242 validation ap= 0.91570\n",
      "Epoch: 0035 training loss= 0.00083 time= 0.40615\n",
      "validation roc= 0.91415 validation ap= 0.91719\n",
      "Epoch: 0036 training loss= 0.00083 time= 0.40899\n",
      "validation roc= 0.91572 validation ap= 0.91820\n",
      "Epoch: 0037 training loss= 0.00083 time= 0.40115\n",
      "validation roc= 0.91741 validation ap= 0.91960\n",
      "Epoch: 0038 training loss= 0.00083 time= 0.38829\n",
      "validation roc= 0.91915 validation ap= 0.92112\n",
      "Epoch: 0039 training loss= 0.00082 time= 0.41259\n",
      "validation roc= 0.92012 validation ap= 0.92217\n",
      "Epoch: 0040 training loss= 0.00082 time= 0.42065\n",
      "validation roc= 0.92113 validation ap= 0.92357\n",
      "Epoch: 0041 training loss= 0.00082 time= 0.39932\n",
      "validation roc= 0.92181 validation ap= 0.92396\n",
      "Epoch: 0042 training loss= 0.00082 time= 0.42156\n",
      "validation roc= 0.92284 validation ap= 0.92536\n",
      "Epoch: 0043 training loss= 0.00081 time= 0.42366\n",
      "validation roc= 0.92424 validation ap= 0.92722\n",
      "Epoch: 0044 training loss= 0.00081 time= 0.40271\n",
      "validation roc= 0.92563 validation ap= 0.92908\n",
      "Epoch: 0045 training loss= 0.00081 time= 0.39619\n",
      "validation roc= 0.92701 validation ap= 0.93137\n",
      "Epoch: 0046 training loss= 0.00081 time= 0.40080\n",
      "validation roc= 0.92773 validation ap= 0.93216\n",
      "Epoch: 0047 training loss= 0.00081 time= 0.39542\n",
      "validation roc= 0.92847 validation ap= 0.93327\n",
      "Epoch: 0048 training loss= 0.00080 time= 0.41687\n",
      "validation roc= 0.92829 validation ap= 0.93336\n",
      "Epoch: 0049 training loss= 0.00080 time= 0.42129\n",
      "validation roc= 0.92738 validation ap= 0.93281\n",
      "Epoch: 0050 training loss= 0.00080 time= 0.38901\n",
      "validation roc= 0.92767 validation ap= 0.93331\n",
      "Epoch: 0051 training loss= 0.00080 time= 0.41096\n",
      "validation roc= 0.92767 validation ap= 0.93330\n",
      "Epoch: 0052 training loss= 0.00080 time= 0.39792\n",
      "validation roc= 0.92802 validation ap= 0.93352\n",
      "Epoch: 0053 training loss= 0.00080 time= 0.41666\n",
      "validation roc= 0.92872 validation ap= 0.93388\n",
      "Epoch: 0054 training loss= 0.00080 time= 0.38505\n",
      "validation roc= 0.92919 validation ap= 0.93425\n",
      "Epoch: 0055 training loss= 0.00079 time= 0.40138\n",
      "validation roc= 0.92938 validation ap= 0.93415\n",
      "Epoch: 0056 training loss= 0.00079 time= 0.45086\n",
      "validation roc= 0.92986 validation ap= 0.93416\n",
      "Epoch: 0057 training loss= 0.00079 time= 0.45078\n",
      "validation roc= 0.93008 validation ap= 0.93400\n",
      "Epoch: 0058 training loss= 0.00079 time= 0.45267\n",
      "validation roc= 0.93078 validation ap= 0.93463\n",
      "Epoch: 0059 training loss= 0.00079 time= 0.47027\n",
      "validation roc= 0.93113 validation ap= 0.93485\n",
      "Epoch: 0060 training loss= 0.00079 time= 0.60618\n",
      "validation roc= 0.93167 validation ap= 0.93538\n",
      "Epoch: 0061 training loss= 0.00079 time= 0.67589\n",
      "validation roc= 0.93247 validation ap= 0.93601\n",
      "Epoch: 0062 training loss= 0.00078 time= 0.48465\n",
      "validation roc= 0.93225 validation ap= 0.93561\n",
      "Epoch: 0063 training loss= 0.00078 time= 0.40464\n",
      "validation roc= 0.93223 validation ap= 0.93567\n",
      "Epoch: 0064 training loss= 0.00078 time= 0.40033\n",
      "validation roc= 0.93221 validation ap= 0.93572\n",
      "Epoch: 0065 training loss= 0.00078 time= 0.43782\n",
      "validation roc= 0.93258 validation ap= 0.93617\n",
      "Epoch: 0066 training loss= 0.00078 time= 0.44663\n",
      "validation roc= 0.93239 validation ap= 0.93596\n",
      "Epoch: 0067 training loss= 0.00078 time= 0.40185\n",
      "validation roc= 0.93177 validation ap= 0.93534\n",
      "Epoch: 0068 training loss= 0.00078 time= 0.39922\n",
      "validation roc= 0.93196 validation ap= 0.93552\n",
      "Epoch: 0069 training loss= 0.00078 time= 0.39781\n",
      "validation roc= 0.93200 validation ap= 0.93572\n",
      "Epoch: 0070 training loss= 0.00077 time= 0.40062\n",
      "validation roc= 0.93208 validation ap= 0.93604\n",
      "Epoch: 0071 training loss= 0.00077 time= 0.39749\n",
      "validation roc= 0.93173 validation ap= 0.93552\n",
      "Epoch: 0072 training loss= 0.00077 time= 0.37701\n",
      "validation roc= 0.93140 validation ap= 0.93549\n",
      "Epoch: 0073 training loss= 0.00077 time= 0.38844\n",
      "validation roc= 0.93132 validation ap= 0.93537\n",
      "Epoch: 0074 training loss= 0.00077 time= 0.42417\n",
      "validation roc= 0.93128 validation ap= 0.93568\n",
      "Epoch: 0075 training loss= 0.00077 time= 0.42426\n",
      "validation roc= 0.93116 validation ap= 0.93558\n",
      "Epoch: 0076 training loss= 0.00077 time= 0.43699\n",
      "validation roc= 0.93113 validation ap= 0.93585\n",
      "Epoch: 0077 training loss= 0.00077 time= 0.51205\n",
      "validation roc= 0.93093 validation ap= 0.93643\n",
      "Epoch: 0078 training loss= 0.00076 time= 0.56907\n",
      "validation roc= 0.93103 validation ap= 0.93681\n",
      "Epoch: 0079 training loss= 0.00076 time= 1.02003\n",
      "validation roc= 0.93103 validation ap= 0.93663\n",
      "Epoch: 0080 training loss= 0.00076 time= 0.55898\n",
      "validation roc= 0.93078 validation ap= 0.93663\n",
      "Epoch: 0081 training loss= 0.00076 time= 0.79567\n",
      "validation roc= 0.93052 validation ap= 0.93675\n",
      "Epoch: 0082 training loss= 0.00076 time= 0.50879\n",
      "validation roc= 0.93062 validation ap= 0.93691\n",
      "Epoch: 0083 training loss= 0.00076 time= 0.54919\n",
      "validation roc= 0.93064 validation ap= 0.93716\n",
      "Epoch: 0084 training loss= 0.00076 time= 0.92375\n",
      "validation roc= 0.93066 validation ap= 0.93749\n",
      "Epoch: 0085 training loss= 0.00076 time= 0.50016\n",
      "validation roc= 0.93023 validation ap= 0.93722\n",
      "Epoch: 0086 training loss= 0.00076 time= 0.48972\n",
      "validation roc= 0.93029 validation ap= 0.93749\n",
      "Epoch: 0087 training loss= 0.00075 time= 0.47078\n",
      "validation roc= 0.93037 validation ap= 0.93801\n",
      "Epoch: 0088 training loss= 0.00075 time= 0.45455\n",
      "validation roc= 0.93045 validation ap= 0.93840\n",
      "Epoch: 0089 training loss= 0.00075 time= 0.49788\n",
      "validation roc= 0.93076 validation ap= 0.93885\n",
      "Epoch: 0090 training loss= 0.00075 time= 0.54050\n",
      "validation roc= 0.93047 validation ap= 0.93873\n",
      "Epoch: 0091 training loss= 0.00075 time= 0.74231\n",
      "validation roc= 0.93058 validation ap= 0.93909\n",
      "Epoch: 0092 training loss= 0.00075 time= 0.42669\n",
      "validation roc= 0.93054 validation ap= 0.93909\n",
      "Epoch: 0093 training loss= 0.00075 time= 0.47727\n",
      "validation roc= 0.93056 validation ap= 0.93939\n",
      "Epoch: 0094 training loss= 0.00075 time= 0.44851\n",
      "validation roc= 0.93039 validation ap= 0.93936\n",
      "Epoch: 0095 training loss= 0.00075 time= 0.45021\n",
      "validation roc= 0.93037 validation ap= 0.93952\n",
      "Epoch: 0096 training loss= 0.00075 time= 0.46168\n",
      "validation roc= 0.93021 validation ap= 0.93955\n",
      "Epoch: 0097 training loss= 0.00075 time= 0.50383\n",
      "validation roc= 0.93041 validation ap= 0.93988\n",
      "Epoch: 0098 training loss= 0.00074 time= 0.50675\n",
      "validation roc= 0.93070 validation ap= 0.94026\n",
      "Epoch: 0099 training loss= 0.00074 time= 0.46043\n",
      "validation roc= 0.93070 validation ap= 0.94046\n",
      "Epoch: 0100 training loss= 0.00074 time= 0.48852\n",
      "validation roc= 0.93062 validation ap= 0.94053\n",
      "Epoch: 0101 training loss= 0.00074 time= 0.57756\n",
      "validation roc= 0.93052 validation ap= 0.94071\n",
      "Epoch: 0102 training loss= 0.00074 time= 0.50620\n",
      "validation roc= 0.93010 validation ap= 0.94053\n",
      "Epoch: 0103 training loss= 0.00074 time= 0.50555\n",
      "validation roc= 0.93031 validation ap= 0.94084\n",
      "Epoch: 0104 training loss= 0.00074 time= 0.56853\n",
      "validation roc= 0.93035 validation ap= 0.94105\n",
      "Epoch: 0105 training loss= 0.00074 time= 0.50344\n",
      "validation roc= 0.93056 validation ap= 0.94136\n",
      "Epoch: 0106 training loss= 0.00074 time= 0.53011\n",
      "validation roc= 0.93062 validation ap= 0.94151\n",
      "Epoch: 0107 training loss= 0.00074 time= 0.45468\n",
      "validation roc= 0.93058 validation ap= 0.94145\n",
      "Epoch: 0108 training loss= 0.00074 time= 0.46948\n",
      "validation roc= 0.93066 validation ap= 0.94183\n",
      "Epoch: 0109 training loss= 0.00074 time= 0.47686\n",
      "validation roc= 0.93074 validation ap= 0.94205\n",
      "Epoch: 0110 training loss= 0.00074 time= 0.44179\n",
      "validation roc= 0.93093 validation ap= 0.94225\n",
      "Epoch: 0111 training loss= 0.00073 time= 0.48384\n",
      "validation roc= 0.93097 validation ap= 0.94236\n",
      "Epoch: 0112 training loss= 0.00073 time= 0.50259\n",
      "validation roc= 0.93089 validation ap= 0.94232\n",
      "Epoch: 0113 training loss= 0.00073 time= 0.52276\n",
      "validation roc= 0.93099 validation ap= 0.94227\n",
      "Epoch: 0114 training loss= 0.00073 time= 0.86768\n",
      "validation roc= 0.93091 validation ap= 0.94234\n",
      "Epoch: 0115 training loss= 0.00073 time= 0.49055\n",
      "validation roc= 0.93099 validation ap= 0.94233\n",
      "Epoch: 0116 training loss= 0.00073 time= 0.49835\n",
      "validation roc= 0.93095 validation ap= 0.94248\n",
      "Epoch: 0117 training loss= 0.00073 time= 0.53624\n",
      "validation roc= 0.93107 validation ap= 0.94263\n",
      "Epoch: 0118 training loss= 0.00073 time= 0.51142\n",
      "validation roc= 0.93089 validation ap= 0.94259\n",
      "Epoch: 0119 training loss= 0.00073 time= 0.53032\n",
      "validation roc= 0.93120 validation ap= 0.94285\n",
      "Epoch: 0120 training loss= 0.00073 time= 0.50820\n",
      "validation roc= 0.92977 validation ap= 0.94174\n",
      "Epoch: 0121 training loss= 0.00073 time= 0.52314\n",
      "validation roc= 0.93085 validation ap= 0.94269\n",
      "Epoch: 0122 training loss= 0.00073 time= 0.51164\n",
      "validation roc= 0.92779 validation ap= 0.93974\n",
      "Epoch: 0123 training loss= 0.00073 time= 0.50982\n",
      "validation roc= 0.93064 validation ap= 0.94269\n",
      "Epoch: 0124 training loss= 0.00073 time= 0.52398\n",
      "validation roc= 0.92977 validation ap= 0.94149\n",
      "Epoch: 0125 training loss= 0.00073 time= 0.54892\n",
      "validation roc= 0.92763 validation ap= 0.93957\n",
      "Epoch: 0126 training loss= 0.00073 time= 0.62914\n",
      "validation roc= 0.93149 validation ap= 0.94332\n",
      "Epoch: 0127 training loss= 0.00073 time= 0.43628\n",
      "validation roc= 0.92798 validation ap= 0.93983\n",
      "Epoch: 0128 training loss= 0.00073 time= 0.43189\n",
      "validation roc= 0.92831 validation ap= 0.93998\n",
      "Epoch: 0129 training loss= 0.00072 time= 0.46233\n",
      "validation roc= 0.93122 validation ap= 0.94283\n",
      "Epoch: 0130 training loss= 0.00072 time= 0.53917\n",
      "validation roc= 0.92763 validation ap= 0.93932\n",
      "Epoch: 0131 training loss= 0.00072 time= 0.42187\n",
      "validation roc= 0.92880 validation ap= 0.94041\n",
      "Epoch: 0132 training loss= 0.00072 time= 0.41528\n",
      "validation roc= 0.93037 validation ap= 0.94206\n",
      "Epoch: 0133 training loss= 0.00072 time= 0.52121\n",
      "validation roc= 0.92777 validation ap= 0.93920\n",
      "Epoch: 0134 training loss= 0.00072 time= 0.44407\n",
      "validation roc= 0.92915 validation ap= 0.94041\n",
      "Epoch: 0135 training loss= 0.00072 time= 0.42587\n",
      "validation roc= 0.92977 validation ap= 0.94115\n",
      "Epoch: 0136 training loss= 0.00072 time= 0.42837\n",
      "validation roc= 0.92843 validation ap= 0.93957\n",
      "Epoch: 0137 training loss= 0.00072 time= 0.42409\n",
      "validation roc= 0.92876 validation ap= 0.93995\n",
      "Epoch: 0138 training loss= 0.00072 time= 0.42154\n",
      "validation roc= 0.92971 validation ap= 0.94075\n",
      "Epoch: 0139 training loss= 0.00072 time= 0.44649\n",
      "validation roc= 0.92876 validation ap= 0.93957\n",
      "Epoch: 0140 training loss= 0.00072 time= 0.56367\n",
      "validation roc= 0.92856 validation ap= 0.93974\n",
      "Epoch: 0141 training loss= 0.00072 time= 0.76203\n",
      "validation roc= 0.92957 validation ap= 0.94055\n",
      "Epoch: 0142 training loss= 0.00072 time= 0.37514\n",
      "validation roc= 0.92820 validation ap= 0.93902\n",
      "Epoch: 0143 training loss= 0.00072 time= 0.59250\n",
      "validation roc= 0.92874 validation ap= 0.93975\n",
      "Epoch: 0144 training loss= 0.00072 time= 0.58649\n",
      "validation roc= 0.92961 validation ap= 0.94051\n",
      "Epoch: 0145 training loss= 0.00072 time= 0.62362\n",
      "validation roc= 0.92798 validation ap= 0.93884\n",
      "Epoch: 0146 training loss= 0.00072 time= 0.47846\n",
      "validation roc= 0.92899 validation ap= 0.93973\n",
      "Epoch: 0147 training loss= 0.00072 time= 0.75567\n",
      "validation roc= 0.92926 validation ap= 0.94004\n",
      "Epoch: 0148 training loss= 0.00072 time= 0.41145\n",
      "validation roc= 0.92874 validation ap= 0.93937\n",
      "Epoch: 0149 training loss= 0.00071 time= 0.54672\n",
      "validation roc= 0.92858 validation ap= 0.93953\n",
      "Epoch: 0150 training loss= 0.00071 time= 0.49603\n",
      "validation roc= 0.92936 validation ap= 0.94029\n",
      "Epoch: 0151 training loss= 0.00071 time= 0.41716\n",
      "validation roc= 0.92783 validation ap= 0.93877\n",
      "Epoch: 0152 training loss= 0.00071 time= 0.42696\n",
      "validation roc= 0.92853 validation ap= 0.93963\n",
      "Epoch: 0153 training loss= 0.00071 time= 0.43411\n",
      "validation roc= 0.92843 validation ap= 0.93955\n",
      "Epoch: 0154 training loss= 0.00071 time= 0.42946\n",
      "validation roc= 0.92825 validation ap= 0.93924\n",
      "Epoch: 0155 training loss= 0.00071 time= 0.48491\n",
      "validation roc= 0.92851 validation ap= 0.93972\n",
      "Epoch: 0156 training loss= 0.00071 time= 0.41633\n",
      "validation roc= 0.92843 validation ap= 0.93957\n",
      "Epoch: 0157 training loss= 0.00071 time= 0.48131\n",
      "validation roc= 0.92798 validation ap= 0.93922\n",
      "Epoch: 0158 training loss= 0.00071 time= 0.42961\n",
      "validation roc= 0.92851 validation ap= 0.93958\n",
      "Epoch: 0159 training loss= 0.00071 time= 0.44945\n",
      "validation roc= 0.92804 validation ap= 0.93940\n",
      "Epoch: 0160 training loss= 0.00071 time= 0.48199\n",
      "validation roc= 0.92823 validation ap= 0.93938\n",
      "Epoch: 0161 training loss= 0.00071 time= 0.51295\n",
      "validation roc= 0.92783 validation ap= 0.93929\n",
      "Epoch: 0162 training loss= 0.00071 time= 0.48383\n",
      "validation roc= 0.92872 validation ap= 0.93961\n",
      "Epoch: 0163 training loss= 0.00071 time= 0.53267\n",
      "validation roc= 0.92637 validation ap= 0.93817\n",
      "Epoch: 0164 training loss= 0.00071 time= 0.51381\n",
      "validation roc= 0.92973 validation ap= 0.94036\n",
      "Epoch: 0165 training loss= 0.00071 time= 0.54052\n",
      "validation roc= 0.92439 validation ap= 0.93588\n",
      "Epoch: 0166 training loss= 0.00071 time= 0.50318\n",
      "validation roc= 0.92983 validation ap= 0.94086\n",
      "Epoch: 0167 training loss= 0.00071 time= 0.50548\n",
      "validation roc= 0.92792 validation ap= 0.93864\n",
      "Epoch: 0168 training loss= 0.00071 time= 0.53882\n",
      "validation roc= 0.92657 validation ap= 0.93792\n",
      "Epoch: 0169 training loss= 0.00071 time= 0.50600\n",
      "validation roc= 0.92948 validation ap= 0.94032\n",
      "Epoch: 0170 training loss= 0.00071 time= 0.51879\n",
      "validation roc= 0.92790 validation ap= 0.93847\n",
      "Epoch: 0171 training loss= 0.00071 time= 0.46248\n",
      "validation roc= 0.92723 validation ap= 0.93836\n",
      "Epoch: 0172 training loss= 0.00071 time= 0.47410\n",
      "validation roc= 0.92915 validation ap= 0.93996\n",
      "Epoch: 0173 training loss= 0.00071 time= 0.45990\n",
      "validation roc= 0.92833 validation ap= 0.93875\n",
      "Epoch: 0174 training loss= 0.00071 time= 0.49998\n",
      "validation roc= 0.92734 validation ap= 0.93822\n",
      "Epoch: 0175 training loss= 0.00071 time= 0.50319\n",
      "validation roc= 0.92835 validation ap= 0.93916\n",
      "Epoch: 0176 training loss= 0.00071 time= 0.49508\n",
      "validation roc= 0.92808 validation ap= 0.93854\n",
      "Epoch: 0177 training loss= 0.00071 time= 0.48372\n",
      "validation roc= 0.92674 validation ap= 0.93767\n",
      "Epoch: 0178 training loss= 0.00071 time= 0.61521\n",
      "validation roc= 0.92779 validation ap= 0.93866\n",
      "Epoch: 0179 training loss= 0.00070 time= 0.50232\n",
      "validation roc= 0.92761 validation ap= 0.93810\n",
      "Epoch: 0180 training loss= 0.00070 time= 0.70667\n",
      "validation roc= 0.92635 validation ap= 0.93736\n",
      "Epoch: 0181 training loss= 0.00070 time= 0.50121\n",
      "validation roc= 0.92734 validation ap= 0.93827\n",
      "Epoch: 0182 training loss= 0.00070 time= 0.47625\n",
      "validation roc= 0.92705 validation ap= 0.93790\n",
      "Epoch: 0183 training loss= 0.00070 time= 0.52881\n",
      "validation roc= 0.92635 validation ap= 0.93737\n",
      "Epoch: 0184 training loss= 0.00070 time= 0.49583\n",
      "validation roc= 0.92703 validation ap= 0.93788\n",
      "Epoch: 0185 training loss= 0.00070 time= 0.49600\n",
      "validation roc= 0.92676 validation ap= 0.93781\n",
      "Epoch: 0186 training loss= 0.00070 time= 0.50027\n",
      "validation roc= 0.92635 validation ap= 0.93739\n",
      "Epoch: 0187 training loss= 0.00070 time= 0.48646\n",
      "validation roc= 0.92690 validation ap= 0.93779\n",
      "Epoch: 0188 training loss= 0.00070 time= 0.50196\n",
      "validation roc= 0.92618 validation ap= 0.93722\n",
      "Epoch: 0189 training loss= 0.00070 time= 0.48379\n",
      "validation roc= 0.92573 validation ap= 0.93692\n",
      "Epoch: 0190 training loss= 0.00070 time= 0.50485\n",
      "validation roc= 0.92674 validation ap= 0.93761\n",
      "Epoch: 0191 training loss= 0.00070 time= 0.59941\n",
      "validation roc= 0.92583 validation ap= 0.93687\n",
      "Epoch: 0192 training loss= 0.00070 time= 0.50022\n",
      "validation roc= 0.92552 validation ap= 0.93674\n",
      "Epoch: 0193 training loss= 0.00070 time= 0.48687\n",
      "validation roc= 0.92614 validation ap= 0.93711\n",
      "Epoch: 0194 training loss= 0.00070 time= 0.50855\n",
      "validation roc= 0.92548 validation ap= 0.93674\n",
      "Epoch: 0195 training loss= 0.00070 time= 0.50434\n",
      "validation roc= 0.92519 validation ap= 0.93651\n",
      "Epoch: 0196 training loss= 0.00070 time= 0.50992\n",
      "validation roc= 0.92583 validation ap= 0.93691\n",
      "Epoch: 0197 training loss= 0.00070 time= 0.52540\n",
      "validation roc= 0.92523 validation ap= 0.93657\n",
      "Epoch: 0198 training loss= 0.00070 time= 0.47504\n",
      "validation roc= 0.92528 validation ap= 0.93648\n",
      "Epoch: 0199 training loss= 0.00070 time= 0.49866\n",
      "validation roc= 0.92561 validation ap= 0.93689\n",
      "Epoch: 0200 training loss= 0.00070 time= 0.48691\n",
      "validation roc= 0.92505 validation ap= 0.93649\n",
      "testing roc= 0.95034 testing ap= 0.95501\n",
      "Epoch: 0001 training loss= 0.00125 time= 1.79765\n",
      "validation roc= 0.68513 validation ap= 0.69886\n",
      "Epoch: 0002 training loss= 0.00125 time= 0.48716\n",
      "validation roc= 0.75299 validation ap= 0.76617\n",
      "Epoch: 0003 training loss= 0.00121 time= 0.50340\n",
      "validation roc= 0.71123 validation ap= 0.71961\n",
      "Epoch: 0004 training loss= 0.00119 time= 0.47957\n",
      "validation roc= 0.77056 validation ap= 0.79997\n",
      "Epoch: 0005 training loss= 0.00116 time= 0.54961\n",
      "validation roc= 0.83077 validation ap= 0.85256\n",
      "Epoch: 0006 training loss= 0.00110 time= 0.46135\n",
      "validation roc= 0.84184 validation ap= 0.85520\n",
      "Epoch: 0007 training loss= 0.00104 time= 0.50110\n",
      "validation roc= 0.83947 validation ap= 0.84885\n",
      "Epoch: 0008 training loss= 0.00100 time= 0.46930\n",
      "validation roc= 0.84302 validation ap= 0.85372\n",
      "Epoch: 0009 training loss= 0.00099 time= 0.47725\n",
      "validation roc= 0.84795 validation ap= 0.86045\n",
      "Epoch: 0010 training loss= 0.00099 time= 0.49976\n",
      "validation roc= 0.85795 validation ap= 0.86838\n",
      "Epoch: 0011 training loss= 0.00096 time= 0.58255\n",
      "validation roc= 0.86924 validation ap= 0.87811\n",
      "Epoch: 0012 training loss= 0.00094 time= 0.48464\n",
      "validation roc= 0.87743 validation ap= 0.88498\n",
      "Epoch: 0013 training loss= 0.00092 time= 0.46966\n",
      "validation roc= 0.88094 validation ap= 0.88896\n",
      "Epoch: 0014 training loss= 0.00092 time= 0.50002\n",
      "validation roc= 0.88146 validation ap= 0.89098\n",
      "Epoch: 0015 training loss= 0.00091 time= 0.43343\n",
      "validation roc= 0.88181 validation ap= 0.89166\n",
      "Epoch: 0016 training loss= 0.00091 time= 0.45724\n",
      "validation roc= 0.88589 validation ap= 0.89585\n",
      "Epoch: 0017 training loss= 0.00091 time= 0.43559\n",
      "validation roc= 0.89183 validation ap= 0.90139\n",
      "Epoch: 0018 training loss= 0.00090 time= 0.43910\n",
      "validation roc= 0.89720 validation ap= 0.90677\n",
      "Epoch: 0019 training loss= 0.00089 time= 0.41979\n",
      "validation roc= 0.89928 validation ap= 0.90796\n",
      "Epoch: 0020 training loss= 0.00089 time= 0.43245\n",
      "validation roc= 0.89631 validation ap= 0.90374\n",
      "Epoch: 0021 training loss= 0.00088 time= 0.43144\n",
      "validation roc= 0.89305 validation ap= 0.89975\n",
      "Epoch: 0022 training loss= 0.00088 time= 0.43323\n",
      "validation roc= 0.89229 validation ap= 0.89861\n",
      "Epoch: 0023 training loss= 0.00088 time= 0.41861\n",
      "validation roc= 0.89439 validation ap= 0.90089\n",
      "Epoch: 0024 training loss= 0.00087 time= 0.41808\n",
      "validation roc= 0.89662 validation ap= 0.90339\n",
      "Epoch: 0025 training loss= 0.00087 time= 0.41537\n",
      "validation roc= 0.89897 validation ap= 0.90614\n",
      "Epoch: 0026 training loss= 0.00086 time= 0.41608\n",
      "validation roc= 0.89992 validation ap= 0.90728\n",
      "Epoch: 0027 training loss= 0.00086 time= 0.42268\n",
      "validation roc= 0.90186 validation ap= 0.90953\n",
      "Epoch: 0028 training loss= 0.00086 time= 0.40795\n",
      "validation roc= 0.90242 validation ap= 0.91097\n",
      "Epoch: 0029 training loss= 0.00085 time= 0.39209\n",
      "validation roc= 0.90301 validation ap= 0.91251\n",
      "Epoch: 0030 training loss= 0.00085 time= 0.41263\n",
      "validation roc= 0.90409 validation ap= 0.91395\n",
      "Epoch: 0031 training loss= 0.00084 time= 0.39924\n",
      "validation roc= 0.90438 validation ap= 0.91456\n",
      "Epoch: 0032 training loss= 0.00084 time= 0.47510\n",
      "validation roc= 0.90435 validation ap= 0.91433\n",
      "Epoch: 0033 training loss= 0.00084 time= 0.50181\n",
      "validation roc= 0.90483 validation ap= 0.91461\n",
      "Epoch: 0034 training loss= 0.00084 time= 0.52213\n",
      "validation roc= 0.90516 validation ap= 0.91476\n",
      "Epoch: 0035 training loss= 0.00083 time= 0.71623\n",
      "validation roc= 0.90576 validation ap= 0.91556\n",
      "Epoch: 0036 training loss= 0.00083 time= 0.49620\n",
      "validation roc= 0.90652 validation ap= 0.91615\n",
      "Epoch: 0037 training loss= 0.00083 time= 0.45264\n",
      "validation roc= 0.90739 validation ap= 0.91698\n",
      "Epoch: 0038 training loss= 0.00083 time= 0.51657\n",
      "validation roc= 0.90871 validation ap= 0.91845\n",
      "Epoch: 0039 training loss= 0.00082 time= 0.50630\n",
      "validation roc= 0.90939 validation ap= 0.91940\n",
      "Epoch: 0040 training loss= 0.00082 time= 0.50845\n",
      "validation roc= 0.91056 validation ap= 0.92134\n",
      "Epoch: 0041 training loss= 0.00082 time= 0.48888\n",
      "validation roc= 0.91228 validation ap= 0.92358\n",
      "Epoch: 0042 training loss= 0.00082 time= 0.51217\n",
      "validation roc= 0.91482 validation ap= 0.92620\n",
      "Epoch: 0043 training loss= 0.00081 time= 0.48164\n",
      "validation roc= 0.91702 validation ap= 0.92837\n",
      "Epoch: 0044 training loss= 0.00081 time= 0.54676\n",
      "validation roc= 0.91894 validation ap= 0.93039\n",
      "Epoch: 0045 training loss= 0.00081 time= 0.45988\n",
      "validation roc= 0.92065 validation ap= 0.93224\n",
      "Epoch: 0046 training loss= 0.00081 time= 0.46071\n",
      "validation roc= 0.92191 validation ap= 0.93367\n",
      "Epoch: 0047 training loss= 0.00081 time= 0.52297\n",
      "validation roc= 0.92327 validation ap= 0.93506\n",
      "Epoch: 0048 training loss= 0.00080 time= 0.57523\n",
      "validation roc= 0.92420 validation ap= 0.93593\n",
      "Epoch: 0049 training loss= 0.00080 time= 0.50062\n",
      "validation roc= 0.92548 validation ap= 0.93721\n",
      "Epoch: 0050 training loss= 0.00080 time= 0.51821\n",
      "validation roc= 0.92633 validation ap= 0.93807\n",
      "Epoch: 0051 training loss= 0.00080 time= 0.47290\n",
      "validation roc= 0.92765 validation ap= 0.93914\n",
      "Epoch: 0052 training loss= 0.00080 time= 0.49666\n",
      "validation roc= 0.92835 validation ap= 0.93986\n",
      "Epoch: 0053 training loss= 0.00079 time= 0.47335\n",
      "validation roc= 0.92922 validation ap= 0.94055\n",
      "Epoch: 0054 training loss= 0.00079 time= 0.49057\n",
      "validation roc= 0.93033 validation ap= 0.94137\n",
      "Epoch: 0055 training loss= 0.00079 time= 0.53417\n",
      "validation roc= 0.93165 validation ap= 0.94238\n",
      "Epoch: 0056 training loss= 0.00079 time= 0.51011\n",
      "validation roc= 0.93285 validation ap= 0.94336\n",
      "Epoch: 0057 training loss= 0.00079 time= 0.52223\n",
      "validation roc= 0.93388 validation ap= 0.94422\n",
      "Epoch: 0058 training loss= 0.00079 time= 0.48423\n",
      "validation roc= 0.93470 validation ap= 0.94477\n",
      "Epoch: 0059 training loss= 0.00079 time= 0.52817\n",
      "validation roc= 0.93547 validation ap= 0.94556\n",
      "Epoch: 0060 training loss= 0.00078 time= 0.51369\n",
      "validation roc= 0.93613 validation ap= 0.94606\n",
      "Epoch: 0061 training loss= 0.00078 time= 0.48352\n",
      "validation roc= 0.93706 validation ap= 0.94659\n",
      "Epoch: 0062 training loss= 0.00078 time= 0.51254\n",
      "validation roc= 0.93774 validation ap= 0.94711\n",
      "Epoch: 0063 training loss= 0.00078 time= 0.47548\n",
      "validation roc= 0.93891 validation ap= 0.94815\n",
      "Epoch: 0064 training loss= 0.00078 time= 0.49573\n",
      "validation roc= 0.93994 validation ap= 0.94896\n",
      "Epoch: 0065 training loss= 0.00078 time= 0.49645\n",
      "validation roc= 0.94062 validation ap= 0.94959\n",
      "Epoch: 0066 training loss= 0.00078 time= 0.81605\n",
      "validation roc= 0.94126 validation ap= 0.95013\n",
      "Epoch: 0067 training loss= 0.00077 time= 0.48879\n",
      "validation roc= 0.94153 validation ap= 0.95042\n",
      "Epoch: 0068 training loss= 0.00077 time= 0.50021\n",
      "validation roc= 0.94225 validation ap= 0.95104\n",
      "Epoch: 0069 training loss= 0.00077 time= 0.51465\n",
      "validation roc= 0.94256 validation ap= 0.95134\n",
      "Epoch: 0070 training loss= 0.00077 time= 0.49527\n",
      "validation roc= 0.94312 validation ap= 0.95188\n",
      "Epoch: 0071 training loss= 0.00077 time= 0.49715\n",
      "validation roc= 0.94362 validation ap= 0.95238\n",
      "Epoch: 0072 training loss= 0.00077 time= 0.50559\n",
      "validation roc= 0.94399 validation ap= 0.95268\n",
      "Epoch: 0073 training loss= 0.00077 time= 0.46778\n",
      "validation roc= 0.94424 validation ap= 0.95283\n",
      "Epoch: 0074 training loss= 0.00077 time= 0.46350\n",
      "validation roc= 0.94483 validation ap= 0.95340\n",
      "Epoch: 0075 training loss= 0.00076 time= 0.46020\n",
      "validation roc= 0.94510 validation ap= 0.95369\n",
      "Epoch: 0076 training loss= 0.00076 time= 0.47286\n",
      "validation roc= 0.94566 validation ap= 0.95416\n",
      "Epoch: 0077 training loss= 0.00076 time= 0.51164\n",
      "validation roc= 0.94578 validation ap= 0.95430\n",
      "Epoch: 0078 training loss= 0.00076 time= 0.50041\n",
      "validation roc= 0.94624 validation ap= 0.95454\n",
      "Epoch: 0079 training loss= 0.00076 time= 0.47111\n",
      "validation roc= 0.94677 validation ap= 0.95501\n",
      "Epoch: 0080 training loss= 0.00076 time= 0.51986\n",
      "validation roc= 0.94671 validation ap= 0.95494\n",
      "Epoch: 0081 training loss= 0.00076 time= 0.52888\n",
      "validation roc= 0.94650 validation ap= 0.95476\n",
      "Epoch: 0082 training loss= 0.00076 time= 0.64015\n",
      "validation roc= 0.94659 validation ap= 0.95474\n",
      "Epoch: 0083 training loss= 0.00076 time= 0.50132\n",
      "validation roc= 0.94681 validation ap= 0.95498\n",
      "Epoch: 0084 training loss= 0.00075 time= 0.47636\n",
      "validation roc= 0.94686 validation ap= 0.95509\n",
      "Epoch: 0085 training loss= 0.00075 time= 0.48511\n",
      "validation roc= 0.94702 validation ap= 0.95511\n",
      "Epoch: 0086 training loss= 0.00075 time= 0.51536\n",
      "validation roc= 0.94698 validation ap= 0.95507\n",
      "Epoch: 0087 training loss= 0.00075 time= 0.47913\n",
      "validation roc= 0.94710 validation ap= 0.95509\n",
      "Epoch: 0088 training loss= 0.00075 time= 0.50810\n",
      "validation roc= 0.94708 validation ap= 0.95525\n",
      "Epoch: 0089 training loss= 0.00075 time= 0.49467\n",
      "validation roc= 0.94725 validation ap= 0.95523\n",
      "Epoch: 0090 training loss= 0.00075 time= 0.51851\n",
      "validation roc= 0.94718 validation ap= 0.95533\n",
      "Epoch: 0091 training loss= 0.00075 time= 0.50153\n",
      "validation roc= 0.94716 validation ap= 0.95537\n",
      "Epoch: 0092 training loss= 0.00075 time= 0.73530\n",
      "validation roc= 0.94692 validation ap= 0.95525\n",
      "Epoch: 0093 training loss= 0.00075 time= 0.52294\n",
      "validation roc= 0.94700 validation ap= 0.95552\n",
      "Epoch: 0094 training loss= 0.00075 time= 0.47648\n",
      "validation roc= 0.94716 validation ap= 0.95567\n",
      "Epoch: 0095 training loss= 0.00074 time= 0.49399\n",
      "validation roc= 0.94716 validation ap= 0.95575\n",
      "Epoch: 0096 training loss= 0.00074 time= 0.45282\n",
      "validation roc= 0.94739 validation ap= 0.95596\n",
      "Epoch: 0097 training loss= 0.00074 time= 0.48739\n",
      "validation roc= 0.94745 validation ap= 0.95613\n",
      "Epoch: 0098 training loss= 0.00074 time= 0.49150\n",
      "validation roc= 0.94776 validation ap= 0.95648\n",
      "Epoch: 0099 training loss= 0.00074 time= 0.48772\n",
      "validation roc= 0.94751 validation ap= 0.95636\n",
      "Epoch: 0100 training loss= 0.00074 time= 0.51670\n",
      "validation roc= 0.94696 validation ap= 0.95621\n",
      "Epoch: 0101 training loss= 0.00074 time= 0.41843\n",
      "validation roc= 0.94685 validation ap= 0.95641\n",
      "Epoch: 0102 training loss= 0.00074 time= 0.40348\n",
      "validation roc= 0.94657 validation ap= 0.95633\n",
      "Epoch: 0103 training loss= 0.00074 time= 0.43631\n",
      "validation roc= 0.94601 validation ap= 0.95599\n",
      "Epoch: 0104 training loss= 0.00074 time= 0.40682\n",
      "validation roc= 0.94589 validation ap= 0.95604\n",
      "Epoch: 0105 training loss= 0.00074 time= 0.41620\n",
      "validation roc= 0.94578 validation ap= 0.95604\n",
      "Epoch: 0106 training loss= 0.00074 time= 0.42731\n",
      "validation roc= 0.94574 validation ap= 0.95611\n",
      "Epoch: 0107 training loss= 0.00074 time= 0.40915\n",
      "validation roc= 0.94564 validation ap= 0.95608\n",
      "Epoch: 0108 training loss= 0.00073 time= 0.42466\n",
      "validation roc= 0.94545 validation ap= 0.95594\n",
      "Epoch: 0109 training loss= 0.00073 time= 0.41817\n",
      "validation roc= 0.94506 validation ap= 0.95565\n",
      "Epoch: 0110 training loss= 0.00073 time= 0.41550\n",
      "validation roc= 0.94461 validation ap= 0.95538\n",
      "Epoch: 0111 training loss= 0.00073 time= 0.40062\n",
      "validation roc= 0.94430 validation ap= 0.95513\n",
      "Epoch: 0112 training loss= 0.00073 time= 0.41554\n",
      "validation roc= 0.94438 validation ap= 0.95510\n",
      "Epoch: 0113 training loss= 0.00073 time= 0.40426\n",
      "validation roc= 0.94434 validation ap= 0.95506\n",
      "Epoch: 0114 training loss= 0.00073 time= 0.40094\n",
      "validation roc= 0.94424 validation ap= 0.95505\n",
      "Epoch: 0115 training loss= 0.00073 time= 0.42550\n",
      "validation roc= 0.94421 validation ap= 0.95496\n",
      "Epoch: 0116 training loss= 0.00073 time= 0.43252\n",
      "validation roc= 0.94407 validation ap= 0.95487\n",
      "Epoch: 0117 training loss= 0.00073 time= 0.42147\n",
      "validation roc= 0.94411 validation ap= 0.95495\n",
      "Epoch: 0118 training loss= 0.00073 time= 0.43226\n",
      "validation roc= 0.94424 validation ap= 0.95502\n",
      "Epoch: 0119 training loss= 0.00073 time= 0.46858\n",
      "validation roc= 0.94456 validation ap= 0.95543\n",
      "Epoch: 0120 training loss= 0.00073 time= 0.47348\n",
      "validation roc= 0.94419 validation ap= 0.95517\n",
      "Epoch: 0121 training loss= 0.00073 time= 0.49898\n",
      "validation roc= 0.94459 validation ap= 0.95567\n",
      "Epoch: 0122 training loss= 0.00073 time= 0.50037\n",
      "validation roc= 0.94423 validation ap= 0.95505\n",
      "Epoch: 0123 training loss= 0.00073 time= 0.49900\n",
      "validation roc= 0.94520 validation ap= 0.95608\n",
      "Epoch: 0124 training loss= 0.00073 time= 0.51876\n",
      "validation roc= 0.94372 validation ap= 0.95459\n",
      "Epoch: 0125 training loss= 0.00073 time= 0.58279\n",
      "validation roc= 0.94607 validation ap= 0.95709\n",
      "Epoch: 0126 training loss= 0.00073 time= 0.52134\n",
      "validation roc= 0.94456 validation ap= 0.95532\n",
      "Epoch: 0127 training loss= 0.00072 time= 0.53390\n",
      "validation roc= 0.94605 validation ap= 0.95687\n",
      "Epoch: 0128 training loss= 0.00072 time= 0.41174\n",
      "validation roc= 0.94607 validation ap= 0.95710\n",
      "Epoch: 0129 training loss= 0.00072 time= 0.43094\n",
      "validation roc= 0.94589 validation ap= 0.95648\n",
      "Epoch: 0130 training loss= 0.00072 time= 0.42963\n",
      "validation roc= 0.94648 validation ap= 0.95744\n",
      "Epoch: 0131 training loss= 0.00072 time= 0.43578\n",
      "validation roc= 0.94675 validation ap= 0.95758\n",
      "Epoch: 0132 training loss= 0.00072 time= 0.41146\n",
      "validation roc= 0.94679 validation ap= 0.95731\n",
      "Epoch: 0133 training loss= 0.00072 time= 0.42921\n",
      "validation roc= 0.94683 validation ap= 0.95764\n",
      "Epoch: 0134 training loss= 0.00072 time= 0.42452\n",
      "validation roc= 0.94766 validation ap= 0.95837\n",
      "Epoch: 0135 training loss= 0.00072 time= 0.42026\n",
      "validation roc= 0.94712 validation ap= 0.95779\n",
      "Epoch: 0136 training loss= 0.00072 time= 0.42590\n",
      "validation roc= 0.94745 validation ap= 0.95826\n",
      "Epoch: 0137 training loss= 0.00072 time= 0.39548\n",
      "validation roc= 0.94784 validation ap= 0.95847\n",
      "Epoch: 0138 training loss= 0.00072 time= 0.45896\n",
      "validation roc= 0.94758 validation ap= 0.95825\n",
      "Epoch: 0139 training loss= 0.00072 time= 0.40484\n",
      "validation roc= 0.94813 validation ap= 0.95879\n",
      "Epoch: 0140 training loss= 0.00072 time= 0.51392\n",
      "validation roc= 0.94784 validation ap= 0.95833\n",
      "Epoch: 0141 training loss= 0.00072 time= 0.51299\n",
      "validation roc= 0.94830 validation ap= 0.95883\n",
      "Epoch: 0142 training loss= 0.00072 time= 0.43999\n",
      "validation roc= 0.94805 validation ap= 0.95867\n",
      "Epoch: 0143 training loss= 0.00072 time= 0.44343\n",
      "validation roc= 0.94863 validation ap= 0.95901\n",
      "Epoch: 0144 training loss= 0.00071 time= 0.68601\n",
      "validation roc= 0.94801 validation ap= 0.95854\n",
      "Epoch: 0145 training loss= 0.00071 time= 0.47514\n",
      "validation roc= 0.94865 validation ap= 0.95916\n",
      "Epoch: 0146 training loss= 0.00071 time= 0.76893\n",
      "validation roc= 0.94828 validation ap= 0.95876\n",
      "Epoch: 0147 training loss= 0.00071 time= 0.53850\n",
      "validation roc= 0.94875 validation ap= 0.95931\n",
      "Epoch: 0148 training loss= 0.00071 time= 0.44407\n",
      "validation roc= 0.94846 validation ap= 0.95908\n",
      "Epoch: 0149 training loss= 0.00071 time= 0.45566\n",
      "validation roc= 0.94900 validation ap= 0.95942\n",
      "Epoch: 0150 training loss= 0.00071 time= 0.50430\n",
      "validation roc= 0.94855 validation ap= 0.95929\n",
      "Epoch: 0151 training loss= 0.00071 time= 0.46309\n",
      "validation roc= 0.94954 validation ap= 0.95992\n",
      "Epoch: 0152 training loss= 0.00071 time= 0.48224\n",
      "validation roc= 0.94853 validation ap= 0.95913\n",
      "Epoch: 0153 training loss= 0.00071 time= 0.47361\n",
      "validation roc= 0.94974 validation ap= 0.96018\n",
      "Epoch: 0154 training loss= 0.00071 time= 0.49813\n",
      "validation roc= 0.94848 validation ap= 0.95898\n",
      "Epoch: 0155 training loss= 0.00071 time= 0.51615\n",
      "validation roc= 0.95055 validation ap= 0.96064\n",
      "Epoch: 0156 training loss= 0.00071 time= 0.52607\n",
      "validation roc= 0.94830 validation ap= 0.95886\n",
      "Epoch: 0157 training loss= 0.00071 time= 0.64818\n",
      "validation roc= 0.95069 validation ap= 0.96073\n",
      "Epoch: 0158 training loss= 0.00071 time= 0.50285\n",
      "validation roc= 0.94954 validation ap= 0.95992\n",
      "Epoch: 0159 training loss= 0.00071 time= 0.48781\n",
      "validation roc= 0.94976 validation ap= 0.96012\n",
      "Epoch: 0160 training loss= 0.00071 time= 0.51575\n",
      "validation roc= 0.95063 validation ap= 0.96061\n",
      "Epoch: 0161 training loss= 0.00071 time= 0.60952\n",
      "validation roc= 0.94968 validation ap= 0.95993\n",
      "Epoch: 0162 training loss= 0.00071 time= 0.54513\n",
      "validation roc= 0.95073 validation ap= 0.96073\n",
      "Epoch: 0163 training loss= 0.00071 time= 0.51967\n",
      "validation roc= 0.95020 validation ap= 0.96017\n",
      "Epoch: 0164 training loss= 0.00071 time= 0.47630\n",
      "validation roc= 0.95028 validation ap= 0.96034\n",
      "Epoch: 0165 training loss= 0.00071 time= 0.50129\n",
      "validation roc= 0.95106 validation ap= 0.96087\n",
      "Epoch: 0166 training loss= 0.00071 time= 0.51562\n",
      "validation roc= 0.95018 validation ap= 0.95995\n",
      "Epoch: 0167 training loss= 0.00071 time= 0.49230\n",
      "validation roc= 0.95055 validation ap= 0.96054\n",
      "Epoch: 0168 training loss= 0.00071 time= 0.50645\n",
      "validation roc= 0.95077 validation ap= 0.96032\n",
      "Epoch: 0169 training loss= 0.00071 time= 0.50192\n",
      "validation roc= 0.95038 validation ap= 0.96021\n",
      "Epoch: 0170 training loss= 0.00071 time= 0.48418\n",
      "validation roc= 0.95088 validation ap= 0.96053\n",
      "Epoch: 0171 training loss= 0.00070 time= 0.50703\n",
      "validation roc= 0.95055 validation ap= 0.96013\n",
      "Epoch: 0172 training loss= 0.00070 time= 0.46952\n",
      "validation roc= 0.95053 validation ap= 0.96031\n",
      "Epoch: 0173 training loss= 0.00070 time= 0.49939\n",
      "validation roc= 0.95082 validation ap= 0.96028\n",
      "Epoch: 0174 training loss= 0.00070 time= 0.47767\n",
      "validation roc= 0.95049 validation ap= 0.96019\n",
      "Epoch: 0175 training loss= 0.00070 time= 0.52106\n",
      "validation roc= 0.95082 validation ap= 0.96047\n",
      "Epoch: 0176 training loss= 0.00070 time= 0.51388\n",
      "validation roc= 0.95049 validation ap= 0.95995\n",
      "Epoch: 0177 training loss= 0.00070 time= 0.52814\n",
      "validation roc= 0.95075 validation ap= 0.96042\n",
      "Epoch: 0178 training loss= 0.00070 time= 0.49805\n",
      "validation roc= 0.95065 validation ap= 0.96023\n",
      "Epoch: 0179 training loss= 0.00070 time= 0.46204\n",
      "validation roc= 0.95073 validation ap= 0.96034\n",
      "Epoch: 0180 training loss= 0.00070 time= 0.50611\n",
      "validation roc= 0.95077 validation ap= 0.96039\n",
      "Epoch: 0181 training loss= 0.00070 time= 0.51091\n",
      "validation roc= 0.95049 validation ap= 0.96017\n",
      "Epoch: 0182 training loss= 0.00070 time= 0.47246\n",
      "validation roc= 0.95073 validation ap= 0.96038\n",
      "Epoch: 0183 training loss= 0.00070 time= 0.50325\n",
      "validation roc= 0.95028 validation ap= 0.96005\n",
      "Epoch: 0184 training loss= 0.00070 time= 0.49403\n",
      "validation roc= 0.95018 validation ap= 0.95999\n",
      "Epoch: 0185 training loss= 0.00070 time= 0.49590\n",
      "validation roc= 0.95047 validation ap= 0.96037\n",
      "Epoch: 0186 training loss= 0.00070 time= 0.49334\n",
      "validation roc= 0.94948 validation ap= 0.95939\n",
      "Epoch: 0187 training loss= 0.00070 time= 0.46067\n",
      "validation roc= 0.95067 validation ap= 0.96069\n",
      "Epoch: 0188 training loss= 0.00070 time= 0.40394\n",
      "validation roc= 0.95011 validation ap= 0.95977\n",
      "Epoch: 0189 training loss= 0.00070 time= 0.41361\n",
      "validation roc= 0.95016 validation ap= 0.96001\n",
      "Epoch: 0190 training loss= 0.00070 time= 0.42483\n",
      "validation roc= 0.95044 validation ap= 0.96026\n",
      "Epoch: 0191 training loss= 0.00070 time= 0.44212\n",
      "validation roc= 0.95009 validation ap= 0.95985\n",
      "Epoch: 0192 training loss= 0.00070 time= 0.40942\n",
      "validation roc= 0.95003 validation ap= 0.96012\n",
      "Epoch: 0193 training loss= 0.00070 time= 0.42531\n",
      "validation roc= 0.94999 validation ap= 0.95986\n",
      "Epoch: 0194 training loss= 0.00070 time= 0.41255\n",
      "validation roc= 0.94960 validation ap= 0.95948\n",
      "Epoch: 0195 training loss= 0.00070 time= 0.41711\n",
      "validation roc= 0.94985 validation ap= 0.95992\n",
      "Epoch: 0196 training loss= 0.00070 time= 0.40043\n",
      "validation roc= 0.94962 validation ap= 0.95964\n",
      "Epoch: 0197 training loss= 0.00070 time= 0.41206\n",
      "validation roc= 0.94937 validation ap= 0.95949\n",
      "Epoch: 0198 training loss= 0.00070 time= 0.41436\n",
      "validation roc= 0.94976 validation ap= 0.95992\n",
      "Epoch: 0199 training loss= 0.00070 time= 0.41324\n",
      "validation roc= 0.94912 validation ap= 0.95921\n",
      "Epoch: 0200 training loss= 0.00070 time= 0.39715\n",
      "validation roc= 0.94888 validation ap= 0.95920\n",
      "testing roc= 0.94599 testing ap= 0.95055\n",
      "Epoch: 0001 training loss= 0.00125 time= 1.91290\n",
      "validation roc= 0.70239 validation ap= 0.72057\n",
      "Epoch: 0002 training loss= 0.00125 time= 0.51309\n",
      "validation roc= 0.76540 validation ap= 0.76604\n",
      "Epoch: 0003 training loss= 0.00121 time= 0.55217\n",
      "validation roc= 0.69632 validation ap= 0.70632\n",
      "Epoch: 0004 training loss= 0.00119 time= 0.52241\n",
      "validation roc= 0.76360 validation ap= 0.77927\n",
      "Epoch: 0005 training loss= 0.00116 time= 0.79921\n",
      "validation roc= 0.84066 validation ap= 0.84854\n",
      "Epoch: 0006 training loss= 0.00110 time= 0.53681\n",
      "validation roc= 0.85378 validation ap= 0.85793\n",
      "Epoch: 0007 training loss= 0.00104 time= 0.52821\n",
      "validation roc= 0.85733 validation ap= 0.85790\n",
      "Epoch: 0008 training loss= 0.00100 time= 0.53464\n",
      "validation roc= 0.86411 validation ap= 0.86419\n",
      "Epoch: 0009 training loss= 0.00099 time= 0.49185\n",
      "validation roc= 0.86760 validation ap= 0.86603\n",
      "Epoch: 0010 training loss= 0.00098 time= 0.53039\n",
      "validation roc= 0.87525 validation ap= 0.87420\n",
      "Epoch: 0011 training loss= 0.00096 time= 0.50028\n",
      "validation roc= 0.88334 validation ap= 0.88353\n",
      "Epoch: 0012 training loss= 0.00094 time= 0.46075\n",
      "validation roc= 0.89077 validation ap= 0.89265\n",
      "Epoch: 0013 training loss= 0.00092 time= 0.48575\n",
      "validation roc= 0.89331 validation ap= 0.89628\n",
      "Epoch: 0014 training loss= 0.00092 time= 0.43872\n",
      "validation roc= 0.89514 validation ap= 0.89860\n",
      "Epoch: 0015 training loss= 0.00091 time= 0.46837\n",
      "validation roc= 0.89502 validation ap= 0.89821\n",
      "Epoch: 0016 training loss= 0.00091 time= 0.47969\n",
      "validation roc= 0.89714 validation ap= 0.90037\n",
      "Epoch: 0017 training loss= 0.00091 time= 0.50410\n",
      "validation roc= 0.90160 validation ap= 0.90643\n",
      "Epoch: 0018 training loss= 0.00090 time= 0.50624\n",
      "validation roc= 0.90410 validation ap= 0.91029\n",
      "Epoch: 0019 training loss= 0.00089 time= 0.53238\n",
      "validation roc= 0.90443 validation ap= 0.91014\n",
      "Epoch: 0020 training loss= 0.00089 time= 0.50090\n",
      "validation roc= 0.90278 validation ap= 0.90607\n",
      "Epoch: 0021 training loss= 0.00088 time= 0.45656\n",
      "validation roc= 0.89923 validation ap= 0.90002\n",
      "Epoch: 0022 training loss= 0.00088 time= 0.48923\n",
      "validation roc= 0.89752 validation ap= 0.89802\n",
      "Epoch: 0023 training loss= 0.00088 time= 0.47618\n",
      "validation roc= 0.89714 validation ap= 0.89912\n",
      "Epoch: 0024 training loss= 0.00087 time= 0.68400\n",
      "validation roc= 0.89745 validation ap= 0.90174\n",
      "Epoch: 0025 training loss= 0.00087 time= 0.51674\n",
      "validation roc= 0.89908 validation ap= 0.90560\n",
      "Epoch: 0026 training loss= 0.00086 time= 0.48655\n",
      "validation roc= 0.89944 validation ap= 0.90715\n",
      "Epoch: 0027 training loss= 0.00086 time= 0.46727\n",
      "validation roc= 0.89972 validation ap= 0.90829\n",
      "Epoch: 0028 training loss= 0.00085 time= 0.47616\n",
      "validation roc= 0.90018 validation ap= 0.90971\n",
      "Epoch: 0029 training loss= 0.00085 time= 0.47647\n",
      "validation roc= 0.90191 validation ap= 0.91281\n",
      "Epoch: 0030 training loss= 0.00085 time= 0.50173\n",
      "validation roc= 0.90305 validation ap= 0.91484\n",
      "Epoch: 0031 training loss= 0.00084 time= 0.54193\n",
      "validation roc= 0.90482 validation ap= 0.91703\n",
      "Epoch: 0032 training loss= 0.00084 time= 0.47209\n",
      "validation roc= 0.90649 validation ap= 0.91865\n",
      "Epoch: 0033 training loss= 0.00084 time= 0.48671\n",
      "validation roc= 0.90777 validation ap= 0.91955\n",
      "Epoch: 0034 training loss= 0.00083 time= 0.51013\n",
      "validation roc= 0.90899 validation ap= 0.92009\n",
      "Epoch: 0035 training loss= 0.00083 time= 0.46680\n",
      "validation roc= 0.91004 validation ap= 0.92107\n",
      "Epoch: 0036 training loss= 0.00083 time= 0.47477\n",
      "validation roc= 0.91078 validation ap= 0.92195\n",
      "Epoch: 0037 training loss= 0.00083 time= 0.48531\n",
      "validation roc= 0.91107 validation ap= 0.92279\n",
      "Epoch: 0038 training loss= 0.00082 time= 0.47413\n",
      "validation roc= 0.91152 validation ap= 0.92345\n",
      "Epoch: 0039 training loss= 0.00082 time= 0.48713\n",
      "validation roc= 0.91144 validation ap= 0.92370\n",
      "Epoch: 0040 training loss= 0.00082 time= 0.47524\n",
      "validation roc= 0.91190 validation ap= 0.92402\n",
      "Epoch: 0041 training loss= 0.00082 time= 0.49786\n",
      "validation roc= 0.91225 validation ap= 0.92420\n",
      "Epoch: 0042 training loss= 0.00082 time= 0.50248\n",
      "validation roc= 0.91320 validation ap= 0.92492\n",
      "Epoch: 0043 training loss= 0.00081 time= 0.50252\n",
      "validation roc= 0.91431 validation ap= 0.92583\n",
      "Epoch: 0044 training loss= 0.00081 time= 0.51177\n",
      "validation roc= 0.91557 validation ap= 0.92691\n",
      "Epoch: 0045 training loss= 0.00081 time= 0.48032\n",
      "validation roc= 0.91714 validation ap= 0.92826\n",
      "Epoch: 0046 training loss= 0.00081 time= 0.53910\n",
      "validation roc= 0.91809 validation ap= 0.92915\n",
      "Epoch: 0047 training loss= 0.00081 time= 0.59698\n",
      "validation roc= 0.91901 validation ap= 0.93014\n",
      "Epoch: 0048 training loss= 0.00080 time= 0.50896\n",
      "validation roc= 0.92015 validation ap= 0.93118\n",
      "Epoch: 0049 training loss= 0.00080 time= 0.53751\n",
      "validation roc= 0.92073 validation ap= 0.93198\n",
      "Epoch: 0050 training loss= 0.00080 time= 0.47888\n",
      "validation roc= 0.92200 validation ap= 0.93320\n",
      "Epoch: 0051 training loss= 0.00080 time= 0.50744\n",
      "validation roc= 0.92333 validation ap= 0.93463\n",
      "Epoch: 0052 training loss= 0.00080 time= 0.52304\n",
      "validation roc= 0.92477 validation ap= 0.93595\n",
      "Epoch: 0053 training loss= 0.00080 time= 0.51191\n",
      "validation roc= 0.92568 validation ap= 0.93687\n",
      "Epoch: 0054 training loss= 0.00079 time= 0.51245\n",
      "validation roc= 0.92689 validation ap= 0.93772\n",
      "Epoch: 0055 training loss= 0.00079 time= 0.48007\n",
      "validation roc= 0.92784 validation ap= 0.93843\n",
      "Epoch: 0056 training loss= 0.00079 time= 0.50382\n",
      "validation roc= 0.92863 validation ap= 0.93905\n",
      "Epoch: 0057 training loss= 0.00079 time= 0.50313\n",
      "validation roc= 0.92939 validation ap= 0.93963\n",
      "Epoch: 0058 training loss= 0.00079 time= 0.52389\n",
      "validation roc= 0.93034 validation ap= 0.94055\n",
      "Epoch: 0059 training loss= 0.00079 time= 0.43765\n",
      "validation roc= 0.93090 validation ap= 0.94091\n",
      "Epoch: 0060 training loss= 0.00079 time= 0.41791\n",
      "validation roc= 0.93150 validation ap= 0.94147\n",
      "Epoch: 0061 training loss= 0.00078 time= 0.43759\n",
      "validation roc= 0.93199 validation ap= 0.94187\n",
      "Epoch: 0062 training loss= 0.00078 time= 0.44136\n",
      "validation roc= 0.93230 validation ap= 0.94207\n",
      "Epoch: 0063 training loss= 0.00078 time= 0.39732\n",
      "validation roc= 0.93269 validation ap= 0.94245\n",
      "Epoch: 0064 training loss= 0.00078 time= 0.42160\n",
      "validation roc= 0.93350 validation ap= 0.94315\n",
      "Epoch: 0065 training loss= 0.00078 time= 0.43599\n",
      "validation roc= 0.93393 validation ap= 0.94350\n",
      "Epoch: 0066 training loss= 0.00078 time= 0.41240\n",
      "validation roc= 0.93461 validation ap= 0.94403\n",
      "Epoch: 0067 training loss= 0.00078 time= 0.47358\n",
      "validation roc= 0.93558 validation ap= 0.94509\n",
      "Epoch: 0068 training loss= 0.00078 time= 0.41107\n",
      "validation roc= 0.93612 validation ap= 0.94560\n",
      "Epoch: 0069 training loss= 0.00077 time= 0.41551\n",
      "validation roc= 0.93669 validation ap= 0.94606\n",
      "Epoch: 0070 training loss= 0.00077 time= 0.41656\n",
      "validation roc= 0.93704 validation ap= 0.94652\n",
      "Epoch: 0071 training loss= 0.00077 time= 0.42129\n",
      "validation roc= 0.93764 validation ap= 0.94723\n",
      "Epoch: 0072 training loss= 0.00077 time= 0.39603\n",
      "validation roc= 0.93834 validation ap= 0.94790\n",
      "Epoch: 0073 training loss= 0.00077 time= 0.40701\n",
      "validation roc= 0.93907 validation ap= 0.94858\n",
      "Epoch: 0074 training loss= 0.00077 time= 0.40716\n",
      "validation roc= 0.93956 validation ap= 0.94905\n",
      "Epoch: 0075 training loss= 0.00077 time= 0.40618\n",
      "validation roc= 0.94010 validation ap= 0.94959\n",
      "Epoch: 0076 training loss= 0.00077 time= 0.41247\n",
      "validation roc= 0.94065 validation ap= 0.95022\n",
      "Epoch: 0077 training loss= 0.00077 time= 0.42799\n",
      "validation roc= 0.94111 validation ap= 0.95080\n",
      "Epoch: 0078 training loss= 0.00076 time= 0.40443\n",
      "validation roc= 0.94171 validation ap= 0.95134\n",
      "Epoch: 0079 training loss= 0.00076 time= 0.40648\n",
      "validation roc= 0.94229 validation ap= 0.95186\n",
      "Epoch: 0080 training loss= 0.00076 time= 0.38883\n",
      "validation roc= 0.94270 validation ap= 0.95225\n",
      "Epoch: 0081 training loss= 0.00076 time= 0.40817\n",
      "validation roc= 0.94321 validation ap= 0.95278\n",
      "Epoch: 0082 training loss= 0.00076 time= 0.47234\n",
      "validation roc= 0.94377 validation ap= 0.95334\n",
      "Epoch: 0083 training loss= 0.00076 time= 0.44336\n",
      "validation roc= 0.94431 validation ap= 0.95387\n",
      "Epoch: 0084 training loss= 0.00076 time= 0.48451\n",
      "validation roc= 0.94495 validation ap= 0.95451\n",
      "Epoch: 0085 training loss= 0.00076 time= 0.50631\n",
      "validation roc= 0.94536 validation ap= 0.95494\n",
      "Epoch: 0086 training loss= 0.00076 time= 0.50740\n",
      "validation roc= 0.94594 validation ap= 0.95538\n",
      "Epoch: 0087 training loss= 0.00075 time= 0.52471\n",
      "validation roc= 0.94649 validation ap= 0.95584\n",
      "Epoch: 0088 training loss= 0.00075 time= 0.52440\n",
      "validation roc= 0.94691 validation ap= 0.95623\n",
      "Epoch: 0089 training loss= 0.00075 time= 0.49177\n",
      "validation roc= 0.94750 validation ap= 0.95674\n",
      "Epoch: 0090 training loss= 0.00075 time= 0.46043\n",
      "validation roc= 0.94786 validation ap= 0.95700\n",
      "Epoch: 0091 training loss= 0.00075 time= 0.48217\n",
      "validation roc= 0.94814 validation ap= 0.95730\n",
      "Epoch: 0092 training loss= 0.00075 time= 0.50538\n",
      "validation roc= 0.94837 validation ap= 0.95756\n",
      "Epoch: 0093 training loss= 0.00075 time= 0.50085\n",
      "validation roc= 0.94854 validation ap= 0.95769\n",
      "Epoch: 0094 training loss= 0.00075 time= 0.54548\n",
      "validation roc= 0.94874 validation ap= 0.95771\n",
      "Epoch: 0095 training loss= 0.00075 time= 0.75244\n",
      "validation roc= 0.94883 validation ap= 0.95787\n",
      "Epoch: 0096 training loss= 0.00075 time= 0.50315\n",
      "validation roc= 0.94907 validation ap= 0.95809\n",
      "Epoch: 0097 training loss= 0.00075 time= 0.59692\n",
      "validation roc= 0.94944 validation ap= 0.95826\n",
      "Epoch: 0098 training loss= 0.00074 time= 0.49019\n",
      "validation roc= 0.94980 validation ap= 0.95862\n",
      "Epoch: 0099 training loss= 0.00074 time= 0.49828\n",
      "validation roc= 0.95043 validation ap= 0.95901\n",
      "Epoch: 0100 training loss= 0.00074 time= 0.48937\n",
      "validation roc= 0.95078 validation ap= 0.95929\n",
      "Epoch: 0101 training loss= 0.00074 time= 0.51509\n",
      "validation roc= 0.95116 validation ap= 0.95952\n",
      "Epoch: 0102 training loss= 0.00074 time= 0.51074\n",
      "validation roc= 0.95136 validation ap= 0.95966\n",
      "Epoch: 0103 training loss= 0.00074 time= 0.50627\n",
      "validation roc= 0.95167 validation ap= 0.95993\n",
      "Epoch: 0104 training loss= 0.00074 time= 0.53826\n",
      "validation roc= 0.95233 validation ap= 0.96039\n",
      "Epoch: 0105 training loss= 0.00074 time= 0.47747\n",
      "validation roc= 0.95250 validation ap= 0.96046\n",
      "Epoch: 0106 training loss= 0.00074 time= 0.49754\n",
      "validation roc= 0.95279 validation ap= 0.96058\n",
      "Epoch: 0107 training loss= 0.00074 time= 0.49204\n",
      "validation roc= 0.95320 validation ap= 0.96084\n",
      "Epoch: 0108 training loss= 0.00074 time= 0.52542\n",
      "validation roc= 0.95367 validation ap= 0.96117\n",
      "Epoch: 0109 training loss= 0.00074 time= 0.47782\n",
      "validation roc= 0.95396 validation ap= 0.96136\n",
      "Epoch: 0110 training loss= 0.00074 time= 0.51890\n",
      "validation roc= 0.95442 validation ap= 0.96166\n",
      "Epoch: 0111 training loss= 0.00073 time= 0.48360\n",
      "validation roc= 0.95475 validation ap= 0.96192\n",
      "Epoch: 0112 training loss= 0.00073 time= 0.49725\n",
      "validation roc= 0.95501 validation ap= 0.96211\n",
      "Epoch: 0113 training loss= 0.00073 time= 0.46726\n",
      "validation roc= 0.95522 validation ap= 0.96223\n",
      "Epoch: 0114 training loss= 0.00073 time= 0.52885\n",
      "validation roc= 0.95532 validation ap= 0.96231\n",
      "Epoch: 0115 training loss= 0.00073 time= 0.55849\n",
      "validation roc= 0.95551 validation ap= 0.96241\n",
      "Epoch: 0116 training loss= 0.00073 time= 0.46864\n",
      "validation roc= 0.95569 validation ap= 0.96245\n",
      "Epoch: 0117 training loss= 0.00073 time= 0.47855\n",
      "validation roc= 0.95555 validation ap= 0.96227\n",
      "Epoch: 0118 training loss= 0.00073 time= 0.48381\n",
      "validation roc= 0.95559 validation ap= 0.96230\n",
      "Epoch: 0119 training loss= 0.00073 time= 0.49880\n",
      "validation roc= 0.95586 validation ap= 0.96246\n",
      "Epoch: 0120 training loss= 0.00073 time= 0.50789\n",
      "validation roc= 0.95565 validation ap= 0.96233\n",
      "Epoch: 0121 training loss= 0.00073 time= 0.48970\n",
      "validation roc= 0.95580 validation ap= 0.96250\n",
      "Epoch: 0122 training loss= 0.00073 time= 0.50756\n",
      "validation roc= 0.95555 validation ap= 0.96229\n",
      "Epoch: 0123 training loss= 0.00073 time= 0.56746\n",
      "validation roc= 0.95617 validation ap= 0.96287\n",
      "Epoch: 0124 training loss= 0.00073 time= 0.43593\n",
      "validation roc= 0.95532 validation ap= 0.96219\n",
      "Epoch: 0125 training loss= 0.00073 time= 0.45757\n",
      "validation roc= 0.95673 validation ap= 0.96321\n",
      "Epoch: 0126 training loss= 0.00073 time= 0.41497\n",
      "validation roc= 0.95506 validation ap= 0.96199\n",
      "Epoch: 0127 training loss= 0.00073 time= 0.39960\n",
      "validation roc= 0.95730 validation ap= 0.96378\n",
      "Epoch: 0128 training loss= 0.00073 time= 0.42859\n",
      "validation roc= 0.95555 validation ap= 0.96236\n",
      "Epoch: 0129 training loss= 0.00073 time= 0.42073\n",
      "validation roc= 0.95697 validation ap= 0.96355\n",
      "Epoch: 0130 training loss= 0.00072 time= 0.42515\n",
      "validation roc= 0.95741 validation ap= 0.96375\n",
      "Epoch: 0131 training loss= 0.00072 time= 0.42002\n",
      "validation roc= 0.95611 validation ap= 0.96283\n",
      "Epoch: 0132 training loss= 0.00072 time= 0.40723\n",
      "validation roc= 0.95749 validation ap= 0.96389\n",
      "Epoch: 0133 training loss= 0.00072 time= 0.42956\n",
      "validation roc= 0.95776 validation ap= 0.96390\n",
      "Epoch: 0134 training loss= 0.00072 time= 0.39666\n",
      "validation roc= 0.95710 validation ap= 0.96372\n",
      "Epoch: 0135 training loss= 0.00072 time= 0.41395\n",
      "validation roc= 0.95759 validation ap= 0.96384\n",
      "Epoch: 0136 training loss= 0.00072 time= 0.43417\n",
      "validation roc= 0.95778 validation ap= 0.96401\n",
      "Epoch: 0137 training loss= 0.00072 time= 0.48181\n",
      "validation roc= 0.95735 validation ap= 0.96391\n",
      "Epoch: 0138 training loss= 0.00072 time= 0.44835\n",
      "validation roc= 0.95768 validation ap= 0.96381\n",
      "Epoch: 0139 training loss= 0.00072 time= 0.47847\n",
      "validation roc= 0.95784 validation ap= 0.96398\n",
      "Epoch: 0140 training loss= 0.00072 time= 0.46287\n",
      "validation roc= 0.95710 validation ap= 0.96368\n",
      "Epoch: 0141 training loss= 0.00072 time= 0.41653\n",
      "validation roc= 0.95784 validation ap= 0.96408\n",
      "Epoch: 0142 training loss= 0.00072 time= 0.47341\n",
      "validation roc= 0.95763 validation ap= 0.96396\n",
      "Epoch: 0143 training loss= 0.00072 time= 0.47322\n",
      "validation roc= 0.95689 validation ap= 0.96356\n",
      "Epoch: 0144 training loss= 0.00072 time= 0.55675\n",
      "validation roc= 0.95790 validation ap= 0.96429\n",
      "Epoch: 0145 training loss= 0.00072 time= 0.55249\n",
      "validation roc= 0.95708 validation ap= 0.96365\n",
      "Epoch: 0146 training loss= 0.00072 time= 0.52786\n",
      "validation roc= 0.95679 validation ap= 0.96367\n",
      "Epoch: 0147 training loss= 0.00072 time= 0.45228\n",
      "validation roc= 0.95724 validation ap= 0.96395\n",
      "Epoch: 0148 training loss= 0.00072 time= 0.44136\n",
      "validation roc= 0.95619 validation ap= 0.96324\n",
      "Epoch: 0149 training loss= 0.00071 time= 0.50400\n",
      "validation roc= 0.95619 validation ap= 0.96350\n",
      "Epoch: 0150 training loss= 0.00071 time= 0.40539\n",
      "validation roc= 0.95625 validation ap= 0.96338\n",
      "Epoch: 0151 training loss= 0.00071 time= 0.41833\n",
      "validation roc= 0.95588 validation ap= 0.96335\n",
      "Epoch: 0152 training loss= 0.00071 time= 0.40469\n",
      "validation roc= 0.95543 validation ap= 0.96305\n",
      "Epoch: 0153 training loss= 0.00071 time= 0.41345\n",
      "validation roc= 0.95545 validation ap= 0.96313\n",
      "Epoch: 0154 training loss= 0.00071 time= 0.43366\n",
      "validation roc= 0.95477 validation ap= 0.96282\n",
      "Epoch: 0155 training loss= 0.00071 time= 0.42350\n",
      "validation roc= 0.95485 validation ap= 0.96294\n",
      "Epoch: 0156 training loss= 0.00071 time= 0.42734\n",
      "validation roc= 0.95421 validation ap= 0.96248\n",
      "Epoch: 0157 training loss= 0.00071 time= 0.40743\n",
      "validation roc= 0.95396 validation ap= 0.96250\n",
      "Epoch: 0158 training loss= 0.00071 time= 0.43072\n",
      "validation roc= 0.95373 validation ap= 0.96227\n",
      "Epoch: 0159 training loss= 0.00071 time= 0.44477\n",
      "validation roc= 0.95353 validation ap= 0.96224\n",
      "Epoch: 0160 training loss= 0.00071 time= 0.40674\n",
      "validation roc= 0.95345 validation ap= 0.96232\n",
      "Epoch: 0161 training loss= 0.00071 time= 0.39901\n",
      "validation roc= 0.95301 validation ap= 0.96194\n",
      "Epoch: 0162 training loss= 0.00071 time= 0.41307\n",
      "validation roc= 0.95314 validation ap= 0.96238\n",
      "Epoch: 0163 training loss= 0.00071 time= 0.42449\n",
      "validation roc= 0.95272 validation ap= 0.96192\n",
      "Epoch: 0164 training loss= 0.00071 time= 0.41943\n",
      "validation roc= 0.95297 validation ap= 0.96234\n",
      "Epoch: 0165 training loss= 0.00071 time= 0.44430\n",
      "validation roc= 0.95225 validation ap= 0.96187\n",
      "Epoch: 0166 training loss= 0.00071 time= 0.42227\n",
      "validation roc= 0.95242 validation ap= 0.96195\n",
      "Epoch: 0167 training loss= 0.00071 time= 0.42259\n",
      "validation roc= 0.95200 validation ap= 0.96183\n",
      "Epoch: 0168 training loss= 0.00071 time= 0.42083\n",
      "validation roc= 0.95171 validation ap= 0.96154\n",
      "Epoch: 0169 training loss= 0.00071 time= 0.42557\n",
      "validation roc= 0.95178 validation ap= 0.96178\n",
      "Epoch: 0170 training loss= 0.00071 time= 0.38640\n",
      "validation roc= 0.95153 validation ap= 0.96150\n",
      "Epoch: 0171 training loss= 0.00071 time= 0.43176\n",
      "validation roc= 0.95087 validation ap= 0.96115\n",
      "Epoch: 0172 training loss= 0.00071 time= 0.48480\n",
      "validation roc= 0.95159 validation ap= 0.96183\n",
      "Epoch: 0173 training loss= 0.00071 time= 0.50914\n",
      "validation roc= 0.94825 validation ap= 0.95924\n",
      "Epoch: 0174 training loss= 0.00071 time= 0.51750\n",
      "validation roc= 0.95190 validation ap= 0.96187\n",
      "Epoch: 0175 training loss= 0.00071 time= 0.51744\n",
      "validation roc= 0.94845 validation ap= 0.95974\n",
      "Epoch: 0176 training loss= 0.00071 time= 0.47520\n",
      "validation roc= 0.95072 validation ap= 0.96112\n",
      "Epoch: 0177 training loss= 0.00071 time= 0.48287\n",
      "validation roc= 0.95126 validation ap= 0.96173\n",
      "Epoch: 0178 training loss= 0.00071 time= 0.51765\n",
      "validation roc= 0.94883 validation ap= 0.96019\n",
      "Epoch: 0179 training loss= 0.00071 time= 0.54741\n",
      "validation roc= 0.95076 validation ap= 0.96118\n",
      "Epoch: 0180 training loss= 0.00071 time= 0.60830\n",
      "validation roc= 0.95136 validation ap= 0.96185\n",
      "Epoch: 0181 training loss= 0.00071 time= 0.48425\n",
      "validation roc= 0.94911 validation ap= 0.96047\n",
      "Epoch: 0182 training loss= 0.00070 time= 0.47760\n",
      "validation roc= 0.95019 validation ap= 0.96088\n",
      "Epoch: 0183 training loss= 0.00070 time= 0.46296\n",
      "validation roc= 0.95134 validation ap= 0.96204\n",
      "Epoch: 0184 training loss= 0.00070 time= 0.49994\n",
      "validation roc= 0.94920 validation ap= 0.96058\n",
      "Epoch: 0185 training loss= 0.00070 time= 0.49688\n",
      "validation roc= 0.94936 validation ap= 0.96046\n",
      "Epoch: 0186 training loss= 0.00070 time= 0.57357\n",
      "validation roc= 0.95064 validation ap= 0.96146\n",
      "Epoch: 0187 training loss= 0.00070 time= 0.62294\n",
      "validation roc= 0.94967 validation ap= 0.96096\n",
      "Epoch: 0188 training loss= 0.00070 time= 0.51584\n",
      "validation roc= 0.94821 validation ap= 0.95983\n",
      "Epoch: 0189 training loss= 0.00070 time= 0.49158\n",
      "validation roc= 0.94887 validation ap= 0.96023\n",
      "Epoch: 0190 training loss= 0.00070 time= 0.46916\n",
      "validation roc= 0.94913 validation ap= 0.96064\n",
      "Epoch: 0191 training loss= 0.00070 time= 0.48170\n",
      "validation roc= 0.94816 validation ap= 0.95995\n",
      "Epoch: 0192 training loss= 0.00070 time= 0.50075\n",
      "validation roc= 0.94819 validation ap= 0.95984\n",
      "Epoch: 0193 training loss= 0.00070 time= 0.51254\n",
      "validation roc= 0.94858 validation ap= 0.96019\n",
      "Epoch: 0194 training loss= 0.00070 time= 0.45195\n",
      "validation roc= 0.94827 validation ap= 0.96006\n",
      "Epoch: 0195 training loss= 0.00070 time= 0.48095\n",
      "validation roc= 0.94788 validation ap= 0.95964\n",
      "Epoch: 0196 training loss= 0.00070 time= 0.47502\n",
      "validation roc= 0.94835 validation ap= 0.96005\n",
      "Epoch: 0197 training loss= 0.00070 time= 0.48317\n",
      "validation roc= 0.94827 validation ap= 0.96015\n",
      "Epoch: 0198 training loss= 0.00070 time= 0.47911\n",
      "validation roc= 0.94784 validation ap= 0.95976\n",
      "Epoch: 0199 training loss= 0.00070 time= 0.47275\n",
      "validation roc= 0.94806 validation ap= 0.95986\n",
      "Epoch: 0200 training loss= 0.00070 time= 0.55853\n",
      "validation roc= 0.94821 validation ap= 0.96012\n",
      "testing roc= 0.93285 testing ap= 0.94429\n",
      "Epoch: 0001 training loss= 0.00125 time= 2.23520\n",
      "validation roc= 0.69064 validation ap= 0.71713\n",
      "Epoch: 0002 training loss= 0.00124 time= 0.54914\n",
      "validation roc= 0.73708 validation ap= 0.74096\n",
      "Epoch: 0003 training loss= 0.00121 time= 0.59771\n",
      "validation roc= 0.65658 validation ap= 0.67550\n",
      "Epoch: 0004 training loss= 0.00119 time= 0.52472\n",
      "validation roc= 0.72646 validation ap= 0.74770\n",
      "Epoch: 0005 training loss= 0.00116 time= 0.52491\n",
      "validation roc= 0.81766 validation ap= 0.83229\n",
      "Epoch: 0006 training loss= 0.00110 time= 0.50716\n",
      "validation roc= 0.85170 validation ap= 0.86374\n",
      "Epoch: 0007 training loss= 0.00105 time= 0.46989\n",
      "validation roc= 0.85709 validation ap= 0.86199\n",
      "Epoch: 0008 training loss= 0.00101 time= 0.51399\n",
      "validation roc= 0.85967 validation ap= 0.86490\n",
      "Epoch: 0009 training loss= 0.00099 time= 0.50669\n",
      "validation roc= 0.86330 validation ap= 0.86956\n",
      "Epoch: 0010 training loss= 0.00099 time= 0.49332\n",
      "validation roc= 0.86901 validation ap= 0.87453\n",
      "Epoch: 0011 training loss= 0.00096 time= 0.47655\n",
      "validation roc= 0.87688 validation ap= 0.88177\n",
      "Epoch: 0012 training loss= 0.00094 time= 0.53416\n",
      "validation roc= 0.88094 validation ap= 0.88530\n",
      "Epoch: 0013 training loss= 0.00092 time= 0.48828\n",
      "validation roc= 0.88119 validation ap= 0.88429\n",
      "Epoch: 0014 training loss= 0.00092 time= 0.51891\n",
      "validation roc= 0.87869 validation ap= 0.87909\n",
      "Epoch: 0015 training loss= 0.00092 time= 0.53245\n",
      "validation roc= 0.87694 validation ap= 0.87448\n",
      "Epoch: 0016 training loss= 0.00091 time= 0.53777\n",
      "validation roc= 0.87830 validation ap= 0.87502\n",
      "Epoch: 0017 training loss= 0.00091 time= 0.54711\n",
      "validation roc= 0.88484 validation ap= 0.88288\n",
      "Epoch: 0018 training loss= 0.00090 time= 0.52597\n",
      "validation roc= 0.89229 validation ap= 0.89254\n",
      "Epoch: 0019 training loss= 0.00089 time= 0.53188\n",
      "validation roc= 0.89798 validation ap= 0.90035\n",
      "Epoch: 0020 training loss= 0.00089 time= 0.45821\n",
      "validation roc= 0.90120 validation ap= 0.90436\n",
      "Epoch: 0021 training loss= 0.00088 time= 0.47122\n",
      "validation roc= 0.90213 validation ap= 0.90492\n",
      "Epoch: 0022 training loss= 0.00088 time= 0.44162\n",
      "validation roc= 0.90223 validation ap= 0.90510\n",
      "Epoch: 0023 training loss= 0.00087 time= 0.45122\n",
      "validation roc= 0.90386 validation ap= 0.90757\n",
      "Epoch: 0024 training loss= 0.00087 time= 0.43859\n",
      "validation roc= 0.90565 validation ap= 0.91056\n",
      "Epoch: 0025 training loss= 0.00087 time= 0.43291\n",
      "validation roc= 0.90795 validation ap= 0.91347\n",
      "Epoch: 0026 training loss= 0.00086 time= 0.44201\n",
      "validation roc= 0.90939 validation ap= 0.91545\n",
      "Epoch: 0027 training loss= 0.00086 time= 0.40962\n",
      "validation roc= 0.91104 validation ap= 0.91714\n",
      "Epoch: 0028 training loss= 0.00085 time= 0.44944\n",
      "validation roc= 0.91226 validation ap= 0.91864\n",
      "Epoch: 0029 training loss= 0.00085 time= 0.44069\n",
      "validation roc= 0.91576 validation ap= 0.92232\n",
      "Epoch: 0030 training loss= 0.00085 time= 0.45485\n",
      "validation roc= 0.91898 validation ap= 0.92542\n",
      "Epoch: 0031 training loss= 0.00084 time= 0.45022\n",
      "validation roc= 0.92102 validation ap= 0.92738\n",
      "Epoch: 0032 training loss= 0.00084 time= 0.38477\n",
      "validation roc= 0.92385 validation ap= 0.92987\n",
      "Epoch: 0033 training loss= 0.00084 time= 0.43134\n",
      "validation roc= 0.92548 validation ap= 0.93058\n",
      "Epoch: 0034 training loss= 0.00083 time= 0.43309\n",
      "validation roc= 0.92569 validation ap= 0.93025\n",
      "Epoch: 0035 training loss= 0.00083 time= 0.43346\n",
      "validation roc= 0.92554 validation ap= 0.92919\n",
      "Epoch: 0036 training loss= 0.00083 time= 0.42874\n",
      "validation roc= 0.92645 validation ap= 0.92946\n",
      "Epoch: 0037 training loss= 0.00083 time= 0.44514\n",
      "validation roc= 0.92769 validation ap= 0.93072\n",
      "Epoch: 0038 training loss= 0.00082 time= 0.42261\n",
      "validation roc= 0.92907 validation ap= 0.93175\n",
      "Epoch: 0039 training loss= 0.00082 time= 0.43151\n",
      "validation roc= 0.92988 validation ap= 0.93218\n",
      "Epoch: 0040 training loss= 0.00082 time= 0.43095\n",
      "validation roc= 0.93120 validation ap= 0.93288\n",
      "Epoch: 0041 training loss= 0.00082 time= 0.41881\n",
      "validation roc= 0.93256 validation ap= 0.93365\n",
      "Epoch: 0042 training loss= 0.00081 time= 0.43093\n",
      "validation roc= 0.93378 validation ap= 0.93443\n",
      "Epoch: 0043 training loss= 0.00081 time= 0.47913\n",
      "validation roc= 0.93565 validation ap= 0.93598\n",
      "Epoch: 0044 training loss= 0.00081 time= 0.44356\n",
      "validation roc= 0.93708 validation ap= 0.93712\n",
      "Epoch: 0045 training loss= 0.00081 time= 0.42575\n",
      "validation roc= 0.93852 validation ap= 0.93862\n",
      "Epoch: 0046 training loss= 0.00081 time= 0.43771\n",
      "validation roc= 0.93951 validation ap= 0.93951\n",
      "Epoch: 0047 training loss= 0.00080 time= 0.45071\n",
      "validation roc= 0.94067 validation ap= 0.94050\n",
      "Epoch: 0048 training loss= 0.00080 time= 0.42983\n",
      "validation roc= 0.94170 validation ap= 0.94152\n",
      "Epoch: 0049 training loss= 0.00080 time= 0.42950\n",
      "validation roc= 0.94296 validation ap= 0.94265\n",
      "Epoch: 0050 training loss= 0.00080 time= 0.42184\n",
      "validation roc= 0.94438 validation ap= 0.94406\n",
      "Epoch: 0051 training loss= 0.00080 time= 0.42670\n",
      "validation roc= 0.94487 validation ap= 0.94452\n",
      "Epoch: 0052 training loss= 0.00080 time= 0.42695\n",
      "validation roc= 0.94576 validation ap= 0.94544\n",
      "Epoch: 0053 training loss= 0.00080 time= 0.44408\n",
      "validation roc= 0.94657 validation ap= 0.94617\n",
      "Epoch: 0054 training loss= 0.00079 time= 0.42942\n",
      "validation roc= 0.94762 validation ap= 0.94695\n",
      "Epoch: 0055 training loss= 0.00079 time= 0.44614\n",
      "validation roc= 0.94828 validation ap= 0.94751\n",
      "Epoch: 0056 training loss= 0.00079 time= 0.44602\n",
      "validation roc= 0.94933 validation ap= 0.94862\n",
      "Epoch: 0057 training loss= 0.00079 time= 0.47801\n",
      "validation roc= 0.94987 validation ap= 0.94930\n",
      "Epoch: 0058 training loss= 0.00079 time= 0.45057\n",
      "validation roc= 0.95071 validation ap= 0.95006\n",
      "Epoch: 0059 training loss= 0.00079 time= 0.43482\n",
      "validation roc= 0.95166 validation ap= 0.95077\n",
      "Epoch: 0060 training loss= 0.00079 time= 0.43266\n",
      "validation roc= 0.95261 validation ap= 0.95148\n",
      "Epoch: 0061 training loss= 0.00078 time= 0.44289\n",
      "validation roc= 0.95317 validation ap= 0.95200\n",
      "Epoch: 0062 training loss= 0.00078 time= 0.45448\n",
      "validation roc= 0.95383 validation ap= 0.95261\n",
      "Epoch: 0063 training loss= 0.00078 time= 0.45063\n",
      "validation roc= 0.95428 validation ap= 0.95309\n",
      "Epoch: 0064 training loss= 0.00078 time= 0.46222\n",
      "validation roc= 0.95455 validation ap= 0.95327\n",
      "Epoch: 0065 training loss= 0.00078 time= 0.46619\n",
      "validation roc= 0.95521 validation ap= 0.95404\n",
      "Epoch: 0066 training loss= 0.00078 time= 0.41771\n",
      "validation roc= 0.95610 validation ap= 0.95491\n",
      "Epoch: 0067 training loss= 0.00078 time= 0.41713\n",
      "validation roc= 0.95635 validation ap= 0.95551\n",
      "Epoch: 0068 training loss= 0.00077 time= 0.40083\n",
      "validation roc= 0.95661 validation ap= 0.95594\n",
      "Epoch: 0069 training loss= 0.00077 time= 0.42524\n",
      "validation roc= 0.95686 validation ap= 0.95647\n",
      "Epoch: 0070 training loss= 0.00077 time= 0.41800\n",
      "validation roc= 0.95744 validation ap= 0.95720\n",
      "Epoch: 0071 training loss= 0.00077 time= 0.43405\n",
      "validation roc= 0.95787 validation ap= 0.95782\n",
      "Epoch: 0072 training loss= 0.00077 time= 0.41060\n",
      "validation roc= 0.95833 validation ap= 0.95852\n",
      "Epoch: 0073 training loss= 0.00077 time= 0.45096\n",
      "validation roc= 0.95874 validation ap= 0.95908\n",
      "Epoch: 0074 training loss= 0.00077 time= 0.45254\n",
      "validation roc= 0.95913 validation ap= 0.95945\n",
      "Epoch: 0075 training loss= 0.00077 time= 0.45457\n",
      "validation roc= 0.95960 validation ap= 0.96003\n",
      "Epoch: 0076 training loss= 0.00076 time= 0.45630\n",
      "validation roc= 0.96000 validation ap= 0.96048\n",
      "Epoch: 0077 training loss= 0.00076 time= 0.43629\n",
      "validation roc= 0.96055 validation ap= 0.96112\n",
      "Epoch: 0078 training loss= 0.00076 time= 0.45771\n",
      "validation roc= 0.96070 validation ap= 0.96134\n",
      "Epoch: 0079 training loss= 0.00076 time= 0.43918\n",
      "validation roc= 0.96101 validation ap= 0.96166\n",
      "Epoch: 0080 training loss= 0.00076 time= 0.47292\n",
      "validation roc= 0.96121 validation ap= 0.96182\n",
      "Epoch: 0081 training loss= 0.00076 time= 0.43187\n",
      "validation roc= 0.96163 validation ap= 0.96233\n",
      "Epoch: 0082 training loss= 0.00076 time= 0.43026\n",
      "validation roc= 0.96185 validation ap= 0.96245\n",
      "Epoch: 0083 training loss= 0.00076 time= 0.45728\n",
      "validation roc= 0.96179 validation ap= 0.96246\n",
      "Epoch: 0084 training loss= 0.00076 time= 0.44212\n",
      "validation roc= 0.96167 validation ap= 0.96245\n",
      "Epoch: 0085 training loss= 0.00075 time= 0.41200\n",
      "validation roc= 0.96136 validation ap= 0.96218\n",
      "Epoch: 0086 training loss= 0.00075 time= 0.45447\n",
      "validation roc= 0.96132 validation ap= 0.96218\n",
      "Epoch: 0087 training loss= 0.00075 time= 0.43060\n",
      "validation roc= 0.96148 validation ap= 0.96225\n",
      "Epoch: 0088 training loss= 0.00075 time= 0.45843\n",
      "validation roc= 0.96121 validation ap= 0.96206\n",
      "Epoch: 0089 training loss= 0.00075 time= 0.44767\n",
      "validation roc= 0.96105 validation ap= 0.96199\n",
      "Epoch: 0090 training loss= 0.00075 time= 0.44985\n",
      "validation roc= 0.96086 validation ap= 0.96175\n",
      "Epoch: 0091 training loss= 0.00075 time= 0.44455\n",
      "validation roc= 0.96060 validation ap= 0.96156\n",
      "Epoch: 0092 training loss= 0.00075 time= 0.44050\n",
      "validation roc= 0.96016 validation ap= 0.96117\n",
      "Epoch: 0093 training loss= 0.00075 time= 0.45491\n",
      "validation roc= 0.95981 validation ap= 0.96074\n",
      "Epoch: 0094 training loss= 0.00075 time= 0.43925\n",
      "validation roc= 0.95940 validation ap= 0.96041\n",
      "Epoch: 0095 training loss= 0.00075 time= 0.46648\n",
      "validation roc= 0.95929 validation ap= 0.96031\n",
      "Epoch: 0096 training loss= 0.00074 time= 0.45692\n",
      "validation roc= 0.95907 validation ap= 0.95997\n",
      "Epoch: 0097 training loss= 0.00074 time= 0.43287\n",
      "validation roc= 0.95903 validation ap= 0.95974\n",
      "Epoch: 0098 training loss= 0.00074 time= 0.44368\n",
      "validation roc= 0.95872 validation ap= 0.95933\n",
      "Epoch: 0099 training loss= 0.00074 time= 0.43902\n",
      "validation roc= 0.95864 validation ap= 0.95926\n",
      "Epoch: 0100 training loss= 0.00074 time= 0.45582\n",
      "validation roc= 0.95853 validation ap= 0.95917\n",
      "Epoch: 0101 training loss= 0.00074 time= 0.43491\n",
      "validation roc= 0.95831 validation ap= 0.95895\n",
      "Epoch: 0102 training loss= 0.00074 time= 0.43039\n",
      "validation roc= 0.95837 validation ap= 0.95889\n",
      "Epoch: 0103 training loss= 0.00074 time= 0.45058\n",
      "validation roc= 0.95837 validation ap= 0.95886\n",
      "Epoch: 0104 training loss= 0.00074 time= 0.42841\n",
      "validation roc= 0.95814 validation ap= 0.95851\n",
      "Epoch: 0105 training loss= 0.00074 time= 0.44546\n",
      "validation roc= 0.95798 validation ap= 0.95813\n",
      "Epoch: 0106 training loss= 0.00074 time= 0.42899\n",
      "validation roc= 0.95806 validation ap= 0.95813\n",
      "Epoch: 0107 training loss= 0.00074 time= 0.46372\n",
      "validation roc= 0.95787 validation ap= 0.95786\n",
      "Epoch: 0108 training loss= 0.00073 time= 0.44412\n",
      "validation roc= 0.95765 validation ap= 0.95757\n",
      "Epoch: 0109 training loss= 0.00073 time= 0.45352\n",
      "validation roc= 0.95773 validation ap= 0.95747\n",
      "Epoch: 0110 training loss= 0.00073 time= 0.44005\n",
      "validation roc= 0.95769 validation ap= 0.95749\n",
      "Epoch: 0111 training loss= 0.00073 time= 0.44478\n",
      "validation roc= 0.95797 validation ap= 0.95770\n",
      "Epoch: 0112 training loss= 0.00073 time= 0.45307\n",
      "validation roc= 0.95795 validation ap= 0.95772\n",
      "Epoch: 0113 training loss= 0.00073 time= 0.44663\n",
      "validation roc= 0.95789 validation ap= 0.95777\n",
      "Epoch: 0114 training loss= 0.00073 time= 0.42987\n",
      "validation roc= 0.95773 validation ap= 0.95768\n",
      "Epoch: 0115 training loss= 0.00073 time= 0.47195\n",
      "validation roc= 0.95787 validation ap= 0.95768\n",
      "Epoch: 0116 training loss= 0.00073 time= 0.45537\n",
      "validation roc= 0.95760 validation ap= 0.95749\n",
      "Epoch: 0117 training loss= 0.00073 time= 0.45937\n",
      "validation roc= 0.95781 validation ap= 0.95774\n",
      "Epoch: 0118 training loss= 0.00073 time= 0.43354\n",
      "validation roc= 0.95703 validation ap= 0.95706\n",
      "Epoch: 0119 training loss= 0.00073 time= 0.41491\n",
      "validation roc= 0.95851 validation ap= 0.95834\n",
      "Epoch: 0120 training loss= 0.00073 time= 0.44601\n",
      "validation roc= 0.95634 validation ap= 0.95648\n",
      "Epoch: 0121 training loss= 0.00073 time= 0.36411\n",
      "validation roc= 0.95874 validation ap= 0.95861\n",
      "Epoch: 0122 training loss= 0.00073 time= 0.38623\n",
      "validation roc= 0.95595 validation ap= 0.95639\n",
      "Epoch: 0123 training loss= 0.00073 time= 0.35926\n",
      "validation roc= 0.95779 validation ap= 0.95781\n",
      "Epoch: 0124 training loss= 0.00073 time= 0.38823\n",
      "validation roc= 0.95769 validation ap= 0.95823\n",
      "Epoch: 0125 training loss= 0.00072 time= 0.36282\n",
      "validation roc= 0.95628 validation ap= 0.95663\n",
      "Epoch: 0126 training loss= 0.00072 time= 0.35580\n",
      "validation roc= 0.95781 validation ap= 0.95826\n",
      "Epoch: 0127 training loss= 0.00072 time= 0.35106\n",
      "validation roc= 0.95698 validation ap= 0.95779\n",
      "Epoch: 0128 training loss= 0.00072 time= 0.35442\n",
      "validation roc= 0.95626 validation ap= 0.95698\n",
      "Epoch: 0129 training loss= 0.00072 time= 0.35850\n",
      "validation roc= 0.95744 validation ap= 0.95829\n",
      "Epoch: 0130 training loss= 0.00072 time= 0.37269\n",
      "validation roc= 0.95620 validation ap= 0.95725\n",
      "Epoch: 0131 training loss= 0.00072 time= 0.36696\n",
      "validation roc= 0.95595 validation ap= 0.95701\n",
      "Epoch: 0132 training loss= 0.00072 time= 0.35297\n",
      "validation roc= 0.95676 validation ap= 0.95780\n",
      "Epoch: 0133 training loss= 0.00072 time= 0.35307\n",
      "validation roc= 0.95558 validation ap= 0.95688\n",
      "Epoch: 0134 training loss= 0.00072 time= 0.39372\n",
      "validation roc= 0.95577 validation ap= 0.95728\n",
      "Epoch: 0135 training loss= 0.00072 time= 0.37342\n",
      "validation roc= 0.95583 validation ap= 0.95720\n",
      "Epoch: 0136 training loss= 0.00072 time= 0.44398\n",
      "validation roc= 0.95480 validation ap= 0.95653\n",
      "Epoch: 0137 training loss= 0.00072 time= 0.42344\n",
      "validation roc= 0.95529 validation ap= 0.95701\n",
      "Epoch: 0138 training loss= 0.00072 time= 0.44599\n",
      "validation roc= 0.95542 validation ap= 0.95721\n",
      "Epoch: 0139 training loss= 0.00072 time= 0.41535\n",
      "validation roc= 0.95432 validation ap= 0.95643\n",
      "Epoch: 0140 training loss= 0.00072 time= 0.42814\n",
      "validation roc= 0.95476 validation ap= 0.95686\n",
      "Epoch: 0141 training loss= 0.00072 time= 0.42745\n",
      "validation roc= 0.95469 validation ap= 0.95681\n",
      "Epoch: 0142 training loss= 0.00072 time= 0.41675\n",
      "validation roc= 0.95412 validation ap= 0.95647\n",
      "Epoch: 0143 training loss= 0.00072 time= 0.42632\n",
      "validation roc= 0.95412 validation ap= 0.95649\n",
      "Epoch: 0144 training loss= 0.00072 time= 0.44566\n",
      "validation roc= 0.95408 validation ap= 0.95649\n",
      "Epoch: 0145 training loss= 0.00071 time= 0.43335\n",
      "validation roc= 0.95362 validation ap= 0.95629\n",
      "Epoch: 0146 training loss= 0.00071 time= 0.43409\n",
      "validation roc= 0.95389 validation ap= 0.95641\n",
      "Epoch: 0147 training loss= 0.00071 time= 0.41666\n",
      "validation roc= 0.95346 validation ap= 0.95621\n",
      "Epoch: 0148 training loss= 0.00071 time= 0.42506\n",
      "validation roc= 0.95304 validation ap= 0.95592\n",
      "Epoch: 0149 training loss= 0.00071 time= 0.43944\n",
      "validation roc= 0.95276 validation ap= 0.95566\n",
      "Epoch: 0150 training loss= 0.00071 time= 0.45219\n",
      "validation roc= 0.95271 validation ap= 0.95559\n",
      "Epoch: 0151 training loss= 0.00071 time= 0.44588\n",
      "validation roc= 0.95224 validation ap= 0.95533\n",
      "Epoch: 0152 training loss= 0.00071 time= 0.42722\n",
      "validation roc= 0.95242 validation ap= 0.95526\n",
      "Epoch: 0153 training loss= 0.00071 time= 0.41086\n",
      "validation roc= 0.95197 validation ap= 0.95522\n",
      "Epoch: 0154 training loss= 0.00071 time= 0.42694\n",
      "validation roc= 0.95249 validation ap= 0.95534\n",
      "Epoch: 0155 training loss= 0.00071 time= 0.44345\n",
      "validation roc= 0.95228 validation ap= 0.95547\n",
      "Epoch: 0156 training loss= 0.00071 time= 0.43103\n",
      "validation roc= 0.95177 validation ap= 0.95493\n",
      "Epoch: 0157 training loss= 0.00071 time= 0.43142\n",
      "validation roc= 0.95228 validation ap= 0.95553\n",
      "Epoch: 0158 training loss= 0.00071 time= 0.42369\n",
      "validation roc= 0.95172 validation ap= 0.95497\n",
      "Epoch: 0159 training loss= 0.00071 time= 0.42200\n",
      "validation roc= 0.95193 validation ap= 0.95512\n",
      "Epoch: 0160 training loss= 0.00071 time= 0.41939\n",
      "validation roc= 0.95197 validation ap= 0.95534\n",
      "Epoch: 0161 training loss= 0.00071 time= 0.43322\n",
      "validation roc= 0.95183 validation ap= 0.95505\n",
      "Epoch: 0162 training loss= 0.00071 time= 0.41801\n",
      "validation roc= 0.95199 validation ap= 0.95539\n",
      "Epoch: 0163 training loss= 0.00071 time= 0.39543\n",
      "validation roc= 0.95181 validation ap= 0.95500\n",
      "Epoch: 0164 training loss= 0.00071 time= 0.43416\n",
      "validation roc= 0.95207 validation ap= 0.95539\n",
      "Epoch: 0165 training loss= 0.00071 time= 0.43480\n",
      "validation roc= 0.95220 validation ap= 0.95534\n",
      "Epoch: 0166 training loss= 0.00071 time= 0.42470\n",
      "validation roc= 0.95191 validation ap= 0.95514\n",
      "Epoch: 0167 training loss= 0.00071 time= 0.42235\n",
      "validation roc= 0.95255 validation ap= 0.95572\n",
      "Epoch: 0168 training loss= 0.00071 time= 0.41913\n",
      "validation roc= 0.95226 validation ap= 0.95545\n",
      "Epoch: 0169 training loss= 0.00071 time= 0.45216\n",
      "validation roc= 0.95245 validation ap= 0.95553\n",
      "Epoch: 0170 training loss= 0.00071 time= 0.42781\n",
      "validation roc= 0.95278 validation ap= 0.95588\n",
      "Epoch: 0171 training loss= 0.00071 time= 0.41328\n",
      "validation roc= 0.95294 validation ap= 0.95605\n",
      "Epoch: 0172 training loss= 0.00071 time= 0.44466\n",
      "validation roc= 0.95302 validation ap= 0.95607\n",
      "Epoch: 0173 training loss= 0.00071 time= 0.41644\n",
      "validation roc= 0.95342 validation ap= 0.95647\n",
      "Epoch: 0174 training loss= 0.00071 time= 0.42301\n",
      "validation roc= 0.95278 validation ap= 0.95573\n",
      "Epoch: 0175 training loss= 0.00071 time= 0.44889\n",
      "validation roc= 0.95416 validation ap= 0.95706\n",
      "Epoch: 0176 training loss= 0.00070 time= 0.41457\n",
      "validation roc= 0.95306 validation ap= 0.95595\n",
      "Epoch: 0177 training loss= 0.00070 time= 0.47183\n",
      "validation roc= 0.95439 validation ap= 0.95711\n",
      "Epoch: 0178 training loss= 0.00070 time= 0.44639\n",
      "validation roc= 0.95403 validation ap= 0.95689\n",
      "Epoch: 0179 training loss= 0.00070 time= 0.47411\n",
      "validation roc= 0.95370 validation ap= 0.95655\n",
      "Epoch: 0180 training loss= 0.00070 time= 0.43862\n",
      "validation roc= 0.95476 validation ap= 0.95753\n",
      "Epoch: 0181 training loss= 0.00070 time= 0.44582\n",
      "validation roc= 0.95418 validation ap= 0.95675\n",
      "Epoch: 0182 training loss= 0.00070 time= 0.41585\n",
      "validation roc= 0.95443 validation ap= 0.95735\n",
      "Epoch: 0183 training loss= 0.00070 time= 0.46180\n",
      "validation roc= 0.95494 validation ap= 0.95741\n",
      "Epoch: 0184 training loss= 0.00070 time= 0.43310\n",
      "validation roc= 0.95391 validation ap= 0.95702\n",
      "Epoch: 0185 training loss= 0.00070 time= 0.43330\n",
      "validation roc= 0.95517 validation ap= 0.95760\n",
      "Epoch: 0186 training loss= 0.00070 time= 0.43583\n",
      "validation roc= 0.95370 validation ap= 0.95660\n",
      "Epoch: 0187 training loss= 0.00070 time= 0.41092\n",
      "validation roc= 0.95482 validation ap= 0.95732\n",
      "Epoch: 0188 training loss= 0.00070 time= 0.41183\n",
      "validation roc= 0.95447 validation ap= 0.95726\n",
      "Epoch: 0189 training loss= 0.00070 time= 0.43675\n",
      "validation roc= 0.95406 validation ap= 0.95671\n",
      "Epoch: 0190 training loss= 0.00070 time= 0.40391\n",
      "validation roc= 0.95469 validation ap= 0.95737\n",
      "Epoch: 0191 training loss= 0.00070 time= 0.38791\n",
      "validation roc= 0.95410 validation ap= 0.95684\n",
      "Epoch: 0192 training loss= 0.00070 time= 0.41946\n",
      "validation roc= 0.95471 validation ap= 0.95722\n",
      "Epoch: 0193 training loss= 0.00070 time= 0.41553\n",
      "validation roc= 0.95406 validation ap= 0.95694\n",
      "Epoch: 0194 training loss= 0.00070 time= 0.42656\n",
      "validation roc= 0.95459 validation ap= 0.95717\n",
      "Epoch: 0195 training loss= 0.00070 time= 0.40996\n",
      "validation roc= 0.95472 validation ap= 0.95746\n",
      "Epoch: 0196 training loss= 0.00070 time= 0.38995\n",
      "validation roc= 0.95375 validation ap= 0.95646\n",
      "Epoch: 0197 training loss= 0.00070 time= 0.43791\n",
      "validation roc= 0.95472 validation ap= 0.95731\n",
      "Epoch: 0198 training loss= 0.00070 time= 0.42388\n",
      "validation roc= 0.95395 validation ap= 0.95687\n",
      "Epoch: 0199 training loss= 0.00070 time= 0.39580\n",
      "validation roc= 0.95391 validation ap= 0.95657\n",
      "Epoch: 0200 training loss= 0.00070 time= 0.40650\n",
      "validation roc= 0.95439 validation ap= 0.95729\n",
      "testing roc= 0.93293 testing ap= 0.93759\n",
      "Epoch: 0001 training loss= 0.00125 time= 1.80542\n",
      "validation roc= 0.72390 validation ap= 0.73356\n",
      "Epoch: 0002 training loss= 0.00124 time= 0.39877\n",
      "validation roc= 0.78505 validation ap= 0.79680\n",
      "Epoch: 0003 training loss= 0.00121 time= 0.41202\n",
      "validation roc= 0.69716 validation ap= 0.71924\n",
      "Epoch: 0004 training loss= 0.00119 time= 0.42560\n",
      "validation roc= 0.76446 validation ap= 0.77036\n",
      "Epoch: 0005 training loss= 0.00116 time= 0.38822\n",
      "validation roc= 0.84878 validation ap= 0.84672\n",
      "Epoch: 0006 training loss= 0.00109 time= 0.42502\n",
      "validation roc= 0.86573 validation ap= 0.86986\n",
      "Epoch: 0007 training loss= 0.00104 time= 0.43501\n",
      "validation roc= 0.86245 validation ap= 0.86709\n",
      "Epoch: 0008 training loss= 0.00100 time= 0.41123\n",
      "validation roc= 0.85878 validation ap= 0.86221\n",
      "Epoch: 0009 training loss= 0.00099 time= 0.43554\n",
      "validation roc= 0.85930 validation ap= 0.86160\n",
      "Epoch: 0010 training loss= 0.00098 time= 0.40476\n",
      "validation roc= 0.86833 validation ap= 0.87160\n",
      "Epoch: 0011 training loss= 0.00096 time= 0.42712\n",
      "validation roc= 0.88034 validation ap= 0.88451\n",
      "Epoch: 0012 training loss= 0.00093 time= 0.40037\n",
      "validation roc= 0.88985 validation ap= 0.89348\n",
      "Epoch: 0013 training loss= 0.00092 time= 0.39021\n",
      "validation roc= 0.89406 validation ap= 0.89635\n",
      "Epoch: 0014 training loss= 0.00092 time= 0.44547\n",
      "validation roc= 0.89239 validation ap= 0.89276\n",
      "Epoch: 0015 training loss= 0.00091 time= 0.41045\n",
      "validation roc= 0.89049 validation ap= 0.88873\n",
      "Epoch: 0016 training loss= 0.00091 time= 0.41160\n",
      "validation roc= 0.89251 validation ap= 0.89067\n",
      "Epoch: 0017 training loss= 0.00090 time= 0.43478\n",
      "validation roc= 0.89676 validation ap= 0.89535\n",
      "Epoch: 0018 training loss= 0.00090 time= 0.44531\n",
      "validation roc= 0.89911 validation ap= 0.89758\n",
      "Epoch: 0019 training loss= 0.00089 time= 0.44366\n",
      "validation roc= 0.90023 validation ap= 0.89755\n",
      "Epoch: 0020 training loss= 0.00088 time= 0.44037\n",
      "validation roc= 0.90027 validation ap= 0.89629\n",
      "Epoch: 0021 training loss= 0.00088 time= 0.39521\n",
      "validation roc= 0.89986 validation ap= 0.89535\n",
      "Epoch: 0022 training loss= 0.00088 time= 0.40382\n",
      "validation roc= 0.90008 validation ap= 0.89613\n",
      "Epoch: 0023 training loss= 0.00087 time= 0.41808\n",
      "validation roc= 0.90095 validation ap= 0.89767\n",
      "Epoch: 0024 training loss= 0.00087 time= 0.41135\n",
      "validation roc= 0.90107 validation ap= 0.89881\n",
      "Epoch: 0025 training loss= 0.00087 time= 0.42409\n",
      "validation roc= 0.90136 validation ap= 0.89941\n",
      "Epoch: 0026 training loss= 0.00086 time= 0.42654\n",
      "validation roc= 0.90202 validation ap= 0.90067\n",
      "Epoch: 0027 training loss= 0.00086 time= 0.42594\n",
      "validation roc= 0.90277 validation ap= 0.90098\n",
      "Epoch: 0028 training loss= 0.00085 time= 0.41919\n",
      "validation roc= 0.90403 validation ap= 0.90249\n",
      "Epoch: 0029 training loss= 0.00085 time= 0.43778\n",
      "validation roc= 0.90582 validation ap= 0.90519\n",
      "Epoch: 0030 training loss= 0.00085 time= 0.43151\n",
      "validation roc= 0.90774 validation ap= 0.90689\n",
      "Epoch: 0031 training loss= 0.00084 time= 0.43037\n",
      "validation roc= 0.90968 validation ap= 0.90963\n",
      "Epoch: 0032 training loss= 0.00084 time= 0.42294\n",
      "validation roc= 0.91193 validation ap= 0.91184\n",
      "Epoch: 0033 training loss= 0.00084 time= 0.42222\n",
      "validation roc= 0.91430 validation ap= 0.91378\n",
      "Epoch: 0034 training loss= 0.00083 time= 0.42191\n",
      "validation roc= 0.91657 validation ap= 0.91619\n",
      "Epoch: 0035 training loss= 0.00083 time= 0.40992\n",
      "validation roc= 0.91822 validation ap= 0.91737\n",
      "Epoch: 0036 training loss= 0.00083 time= 0.42567\n",
      "validation roc= 0.91906 validation ap= 0.91815\n",
      "Epoch: 0037 training loss= 0.00083 time= 0.41187\n",
      "validation roc= 0.91983 validation ap= 0.91849\n",
      "Epoch: 0038 training loss= 0.00082 time= 0.42896\n",
      "validation roc= 0.92070 validation ap= 0.91883\n",
      "Epoch: 0039 training loss= 0.00082 time= 0.43344\n",
      "validation roc= 0.92129 validation ap= 0.91919\n",
      "Epoch: 0040 training loss= 0.00082 time= 0.41715\n",
      "validation roc= 0.92191 validation ap= 0.91963\n",
      "Epoch: 0041 training loss= 0.00082 time= 0.41292\n",
      "validation roc= 0.92323 validation ap= 0.92137\n",
      "Epoch: 0042 training loss= 0.00081 time= 0.41166\n",
      "validation roc= 0.92468 validation ap= 0.92390\n",
      "Epoch: 0043 training loss= 0.00081 time= 0.40137\n",
      "validation roc= 0.92593 validation ap= 0.92544\n",
      "Epoch: 0044 training loss= 0.00081 time= 0.42116\n",
      "validation roc= 0.92723 validation ap= 0.92669\n",
      "Epoch: 0045 training loss= 0.00081 time= 0.41929\n",
      "validation roc= 0.92816 validation ap= 0.92747\n",
      "Epoch: 0046 training loss= 0.00081 time= 0.42334\n",
      "validation roc= 0.92905 validation ap= 0.92879\n",
      "Epoch: 0047 training loss= 0.00080 time= 0.44475\n",
      "validation roc= 0.92992 validation ap= 0.92982\n",
      "Epoch: 0048 training loss= 0.00080 time= 0.39803\n",
      "validation roc= 0.93115 validation ap= 0.93132\n",
      "Epoch: 0049 training loss= 0.00080 time= 0.43625\n",
      "validation roc= 0.93225 validation ap= 0.93262\n",
      "Epoch: 0050 training loss= 0.00080 time= 0.42519\n",
      "validation roc= 0.93340 validation ap= 0.93398\n",
      "Epoch: 0051 training loss= 0.00080 time= 0.42684\n",
      "validation roc= 0.93431 validation ap= 0.93491\n",
      "Epoch: 0052 training loss= 0.00080 time= 0.42336\n",
      "validation roc= 0.93557 validation ap= 0.93648\n",
      "Epoch: 0053 training loss= 0.00079 time= 0.45184\n",
      "validation roc= 0.93675 validation ap= 0.93761\n",
      "Epoch: 0054 training loss= 0.00079 time= 0.43502\n",
      "validation roc= 0.93786 validation ap= 0.93886\n",
      "Epoch: 0055 training loss= 0.00079 time= 0.42200\n",
      "validation roc= 0.93883 validation ap= 0.93966\n",
      "Epoch: 0056 training loss= 0.00079 time= 0.43897\n",
      "validation roc= 0.93976 validation ap= 0.94090\n",
      "Epoch: 0057 training loss= 0.00079 time= 0.45866\n",
      "validation roc= 0.94040 validation ap= 0.94168\n",
      "Epoch: 0058 training loss= 0.00079 time= 0.43757\n",
      "validation roc= 0.94116 validation ap= 0.94262\n",
      "Epoch: 0059 training loss= 0.00079 time= 0.41866\n",
      "validation roc= 0.94188 validation ap= 0.94328\n",
      "Epoch: 0060 training loss= 0.00078 time= 0.43385\n",
      "validation roc= 0.94248 validation ap= 0.94413\n",
      "Epoch: 0061 training loss= 0.00078 time= 0.43941\n",
      "validation roc= 0.94304 validation ap= 0.94474\n",
      "Epoch: 0062 training loss= 0.00078 time= 0.43920\n",
      "validation roc= 0.94380 validation ap= 0.94549\n",
      "Epoch: 0063 training loss= 0.00078 time= 0.42861\n",
      "validation roc= 0.94467 validation ap= 0.94656\n",
      "Epoch: 0064 training loss= 0.00078 time= 0.43417\n",
      "validation roc= 0.94518 validation ap= 0.94709\n",
      "Epoch: 0065 training loss= 0.00078 time= 0.43461\n",
      "validation roc= 0.94551 validation ap= 0.94763\n",
      "Epoch: 0066 training loss= 0.00078 time= 0.42961\n",
      "validation roc= 0.94570 validation ap= 0.94784\n",
      "Epoch: 0067 training loss= 0.00077 time= 0.45762\n",
      "validation roc= 0.94584 validation ap= 0.94819\n",
      "Epoch: 0068 training loss= 0.00077 time= 0.42256\n",
      "validation roc= 0.94634 validation ap= 0.94913\n",
      "Epoch: 0069 training loss= 0.00077 time= 0.42777\n",
      "validation roc= 0.94667 validation ap= 0.94978\n",
      "Epoch: 0070 training loss= 0.00077 time= 0.41684\n",
      "validation roc= 0.94712 validation ap= 0.95029\n",
      "Epoch: 0071 training loss= 0.00077 time= 0.44519\n",
      "validation roc= 0.94743 validation ap= 0.95079\n",
      "Epoch: 0072 training loss= 0.00077 time= 0.45216\n",
      "validation roc= 0.94791 validation ap= 0.95137\n",
      "Epoch: 0073 training loss= 0.00077 time= 0.42848\n",
      "validation roc= 0.94803 validation ap= 0.95156\n",
      "Epoch: 0074 training loss= 0.00077 time= 0.43133\n",
      "validation roc= 0.94836 validation ap= 0.95213\n",
      "Epoch: 0075 training loss= 0.00077 time= 0.41763\n",
      "validation roc= 0.94871 validation ap= 0.95252\n",
      "Epoch: 0076 training loss= 0.00076 time= 0.44759\n",
      "validation roc= 0.94884 validation ap= 0.95251\n",
      "Epoch: 0077 training loss= 0.00076 time= 0.42970\n",
      "validation roc= 0.94894 validation ap= 0.95248\n",
      "Epoch: 0078 training loss= 0.00076 time= 0.42785\n",
      "validation roc= 0.94958 validation ap= 0.95307\n",
      "Epoch: 0079 training loss= 0.00076 time= 0.41168\n",
      "validation roc= 0.94989 validation ap= 0.95354\n",
      "Epoch: 0080 training loss= 0.00076 time= 0.43795\n",
      "validation roc= 0.95059 validation ap= 0.95426\n",
      "Epoch: 0081 training loss= 0.00076 time= 0.41532\n",
      "validation roc= 0.95047 validation ap= 0.95412\n",
      "Epoch: 0082 training loss= 0.00076 time= 0.41870\n",
      "validation roc= 0.95057 validation ap= 0.95417\n",
      "Epoch: 0083 training loss= 0.00076 time= 0.44527\n",
      "validation roc= 0.95092 validation ap= 0.95453\n",
      "Epoch: 0084 training loss= 0.00076 time= 0.43650\n",
      "validation roc= 0.95131 validation ap= 0.95488\n",
      "Epoch: 0085 training loss= 0.00075 time= 0.42358\n",
      "validation roc= 0.95177 validation ap= 0.95525\n",
      "Epoch: 0086 training loss= 0.00075 time= 0.41075\n",
      "validation roc= 0.95193 validation ap= 0.95545\n",
      "Epoch: 0087 training loss= 0.00075 time= 0.43343\n",
      "validation roc= 0.95197 validation ap= 0.95543\n",
      "Epoch: 0088 training loss= 0.00075 time= 0.42492\n",
      "validation roc= 0.95224 validation ap= 0.95563\n",
      "Epoch: 0089 training loss= 0.00075 time= 0.42692\n",
      "validation roc= 0.95278 validation ap= 0.95607\n",
      "Epoch: 0090 training loss= 0.00075 time= 0.42841\n",
      "validation roc= 0.95323 validation ap= 0.95647\n",
      "Epoch: 0091 training loss= 0.00075 time= 0.43429\n",
      "validation roc= 0.95344 validation ap= 0.95662\n",
      "Epoch: 0092 training loss= 0.00075 time= 0.42847\n",
      "validation roc= 0.95381 validation ap= 0.95694\n",
      "Epoch: 0093 training loss= 0.00075 time= 0.41582\n",
      "validation roc= 0.95438 validation ap= 0.95726\n",
      "Epoch: 0094 training loss= 0.00075 time= 0.44499\n",
      "validation roc= 0.95484 validation ap= 0.95789\n",
      "Epoch: 0095 training loss= 0.00075 time= 0.41454\n",
      "validation roc= 0.95544 validation ap= 0.95847\n",
      "Epoch: 0096 training loss= 0.00074 time= 0.39460\n",
      "validation roc= 0.95581 validation ap= 0.95877\n",
      "Epoch: 0097 training loss= 0.00074 time= 0.39942\n",
      "validation roc= 0.95618 validation ap= 0.95895\n",
      "Epoch: 0098 training loss= 0.00074 time= 0.41107\n",
      "validation roc= 0.95661 validation ap= 0.95946\n",
      "Epoch: 0099 training loss= 0.00074 time= 0.37168\n",
      "validation roc= 0.95663 validation ap= 0.95950\n",
      "Epoch: 0100 training loss= 0.00074 time= 0.40875\n",
      "validation roc= 0.95715 validation ap= 0.95984\n",
      "Epoch: 0101 training loss= 0.00074 time= 0.41243\n",
      "validation roc= 0.95748 validation ap= 0.96000\n",
      "Epoch: 0102 training loss= 0.00074 time= 0.39761\n",
      "validation roc= 0.95783 validation ap= 0.96042\n",
      "Epoch: 0103 training loss= 0.00074 time= 0.40701\n",
      "validation roc= 0.95802 validation ap= 0.96059\n",
      "Epoch: 0104 training loss= 0.00074 time= 0.44315\n",
      "validation roc= 0.95841 validation ap= 0.96105\n",
      "Epoch: 0105 training loss= 0.00074 time= 0.41976\n",
      "validation roc= 0.95857 validation ap= 0.96110\n",
      "Epoch: 0106 training loss= 0.00074 time= 0.41394\n",
      "validation roc= 0.95868 validation ap= 0.96111\n",
      "Epoch: 0107 training loss= 0.00074 time= 0.38891\n",
      "validation roc= 0.95882 validation ap= 0.96118\n",
      "Epoch: 0108 training loss= 0.00074 time= 0.42663\n",
      "validation roc= 0.95903 validation ap= 0.96129\n",
      "Epoch: 0109 training loss= 0.00073 time= 0.43316\n",
      "validation roc= 0.95913 validation ap= 0.96132\n",
      "Epoch: 0110 training loss= 0.00073 time= 0.44260\n",
      "validation roc= 0.95911 validation ap= 0.96132\n",
      "Epoch: 0111 training loss= 0.00073 time= 0.42527\n",
      "validation roc= 0.95911 validation ap= 0.96137\n",
      "Epoch: 0112 training loss= 0.00073 time= 0.43842\n",
      "validation roc= 0.95927 validation ap= 0.96154\n",
      "Epoch: 0113 training loss= 0.00073 time= 0.39678\n",
      "validation roc= 0.95991 validation ap= 0.96189\n",
      "Epoch: 0114 training loss= 0.00073 time= 0.42246\n",
      "validation roc= 0.96010 validation ap= 0.96206\n",
      "Epoch: 0115 training loss= 0.00073 time= 0.42207\n",
      "validation roc= 0.96031 validation ap= 0.96221\n",
      "Epoch: 0116 training loss= 0.00073 time= 0.41169\n",
      "validation roc= 0.96026 validation ap= 0.96224\n",
      "Epoch: 0117 training loss= 0.00073 time= 0.42425\n",
      "validation roc= 0.96057 validation ap= 0.96237\n",
      "Epoch: 0118 training loss= 0.00073 time= 0.34911\n",
      "validation roc= 0.96051 validation ap= 0.96239\n",
      "Epoch: 0119 training loss= 0.00073 time= 0.34578\n",
      "validation roc= 0.96076 validation ap= 0.96254\n",
      "Epoch: 0120 training loss= 0.00073 time= 0.35324\n",
      "validation roc= 0.96080 validation ap= 0.96265\n",
      "Epoch: 0121 training loss= 0.00073 time= 0.35936\n",
      "validation roc= 0.96125 validation ap= 0.96282\n",
      "Epoch: 0122 training loss= 0.00073 time= 0.35600\n",
      "validation roc= 0.96041 validation ap= 0.96232\n",
      "Epoch: 0123 training loss= 0.00073 time= 0.34148\n",
      "validation roc= 0.96142 validation ap= 0.96291\n",
      "Epoch: 0124 training loss= 0.00073 time= 0.34694\n",
      "validation roc= 0.96078 validation ap= 0.96280\n",
      "Epoch: 0125 training loss= 0.00073 time= 0.35347\n",
      "validation roc= 0.96138 validation ap= 0.96299\n",
      "Epoch: 0126 training loss= 0.00073 time= 0.35513\n",
      "validation roc= 0.96165 validation ap= 0.96364\n",
      "Epoch: 0127 training loss= 0.00072 time= 0.34097\n",
      "validation roc= 0.96154 validation ap= 0.96357\n",
      "Epoch: 0128 training loss= 0.00072 time= 0.35245\n",
      "validation roc= 0.96167 validation ap= 0.96332\n",
      "Epoch: 0129 training loss= 0.00072 time= 0.35500\n",
      "validation roc= 0.96189 validation ap= 0.96394\n",
      "Epoch: 0130 training loss= 0.00072 time= 0.34698\n",
      "validation roc= 0.96194 validation ap= 0.96387\n",
      "Epoch: 0131 training loss= 0.00072 time= 0.35289\n",
      "validation roc= 0.96220 validation ap= 0.96398\n",
      "Epoch: 0132 training loss= 0.00072 time= 0.42509\n",
      "validation roc= 0.96204 validation ap= 0.96416\n",
      "Epoch: 0133 training loss= 0.00072 time= 0.36473\n",
      "validation roc= 0.96241 validation ap= 0.96427\n",
      "Epoch: 0134 training loss= 0.00072 time= 0.40927\n",
      "validation roc= 0.96229 validation ap= 0.96426\n",
      "Epoch: 0135 training loss= 0.00072 time= 0.40560\n",
      "validation roc= 0.96190 validation ap= 0.96385\n",
      "Epoch: 0136 training loss= 0.00072 time= 0.43078\n",
      "validation roc= 0.96235 validation ap= 0.96425\n",
      "Epoch: 0137 training loss= 0.00072 time= 0.40749\n",
      "validation roc= 0.96183 validation ap= 0.96393\n",
      "Epoch: 0138 training loss= 0.00072 time= 0.42090\n",
      "validation roc= 0.96194 validation ap= 0.96374\n",
      "Epoch: 0139 training loss= 0.00072 time= 0.38720\n",
      "validation roc= 0.96204 validation ap= 0.96406\n",
      "Epoch: 0140 training loss= 0.00072 time= 0.49024\n",
      "validation roc= 0.96185 validation ap= 0.96371\n",
      "Epoch: 0141 training loss= 0.00072 time= 0.40229\n",
      "validation roc= 0.96158 validation ap= 0.96355\n",
      "Epoch: 0142 training loss= 0.00072 time= 0.37327\n",
      "validation roc= 0.96189 validation ap= 0.96389\n",
      "Epoch: 0143 training loss= 0.00072 time= 0.37913\n",
      "validation roc= 0.96154 validation ap= 0.96357\n",
      "Epoch: 0144 training loss= 0.00072 time= 0.42086\n",
      "validation roc= 0.96161 validation ap= 0.96371\n",
      "Epoch: 0145 training loss= 0.00072 time= 0.43918\n",
      "validation roc= 0.96171 validation ap= 0.96369\n",
      "Epoch: 0146 training loss= 0.00072 time= 0.41088\n",
      "validation roc= 0.96097 validation ap= 0.96313\n",
      "Epoch: 0147 training loss= 0.00072 time= 0.41898\n",
      "validation roc= 0.96115 validation ap= 0.96330\n",
      "Epoch: 0148 training loss= 0.00071 time= 0.43862\n",
      "validation roc= 0.96111 validation ap= 0.96324\n",
      "Epoch: 0149 training loss= 0.00071 time= 0.43327\n",
      "validation roc= 0.96076 validation ap= 0.96310\n",
      "Epoch: 0150 training loss= 0.00071 time= 0.41224\n",
      "validation roc= 0.96084 validation ap= 0.96302\n",
      "Epoch: 0151 training loss= 0.00071 time= 0.43294\n",
      "validation roc= 0.96076 validation ap= 0.96313\n",
      "Epoch: 0152 training loss= 0.00071 time= 0.44420\n",
      "validation roc= 0.96041 validation ap= 0.96274\n",
      "Epoch: 0153 training loss= 0.00071 time= 0.41329\n",
      "validation roc= 0.96057 validation ap= 0.96305\n",
      "Epoch: 0154 training loss= 0.00071 time= 0.41843\n",
      "validation roc= 0.96022 validation ap= 0.96263\n",
      "Epoch: 0155 training loss= 0.00071 time= 0.40863\n",
      "validation roc= 0.96064 validation ap= 0.96319\n",
      "Epoch: 0156 training loss= 0.00071 time= 0.41978\n",
      "validation roc= 0.96027 validation ap= 0.96267\n",
      "Epoch: 0157 training loss= 0.00071 time= 0.41822\n",
      "validation roc= 0.96006 validation ap= 0.96270\n",
      "Epoch: 0158 training loss= 0.00071 time= 0.43026\n",
      "validation roc= 0.96014 validation ap= 0.96246\n",
      "Epoch: 0159 training loss= 0.00071 time= 0.42377\n",
      "validation roc= 0.95991 validation ap= 0.96260\n",
      "Epoch: 0160 training loss= 0.00071 time= 0.42565\n",
      "validation roc= 0.95996 validation ap= 0.96226\n",
      "Epoch: 0161 training loss= 0.00071 time= 0.44742\n",
      "validation roc= 0.95981 validation ap= 0.96252\n",
      "Epoch: 0162 training loss= 0.00071 time= 0.42475\n",
      "validation roc= 0.95969 validation ap= 0.96186\n",
      "Epoch: 0163 training loss= 0.00071 time= 0.40170\n",
      "validation roc= 0.95958 validation ap= 0.96237\n",
      "Epoch: 0164 training loss= 0.00071 time= 0.42275\n",
      "validation roc= 0.95983 validation ap= 0.96206\n",
      "Epoch: 0165 training loss= 0.00071 time= 0.43947\n",
      "validation roc= 0.95938 validation ap= 0.96222\n",
      "Epoch: 0166 training loss= 0.00071 time= 0.41149\n",
      "validation roc= 0.96010 validation ap= 0.96228\n",
      "Epoch: 0167 training loss= 0.00071 time= 0.37872\n",
      "validation roc= 0.95940 validation ap= 0.96196\n",
      "Epoch: 0168 training loss= 0.00071 time= 0.39001\n",
      "validation roc= 0.95981 validation ap= 0.96238\n",
      "Epoch: 0169 training loss= 0.00071 time= 0.43297\n",
      "validation roc= 0.96008 validation ap= 0.96244\n",
      "Epoch: 0170 training loss= 0.00071 time= 0.42248\n",
      "validation roc= 0.95963 validation ap= 0.96222\n",
      "Epoch: 0171 training loss= 0.00071 time= 0.34416\n",
      "validation roc= 0.96029 validation ap= 0.96260\n",
      "Epoch: 0172 training loss= 0.00071 time= 0.40837\n",
      "validation roc= 0.95946 validation ap= 0.96207\n",
      "Epoch: 0173 training loss= 0.00071 time= 0.40554\n",
      "validation roc= 0.96012 validation ap= 0.96252\n",
      "Epoch: 0174 training loss= 0.00071 time= 0.42587\n",
      "validation roc= 0.95971 validation ap= 0.96214\n",
      "Epoch: 0175 training loss= 0.00070 time= 0.45233\n",
      "validation roc= 0.95979 validation ap= 0.96234\n",
      "Epoch: 0176 training loss= 0.00070 time= 0.43815\n",
      "validation roc= 0.96014 validation ap= 0.96263\n",
      "Epoch: 0177 training loss= 0.00070 time= 0.41657\n",
      "validation roc= 0.95932 validation ap= 0.96206\n",
      "Epoch: 0178 training loss= 0.00070 time= 0.41405\n",
      "validation roc= 0.96026 validation ap= 0.96284\n",
      "Epoch: 0179 training loss= 0.00070 time= 0.43561\n",
      "validation roc= 0.95952 validation ap= 0.96230\n",
      "Epoch: 0180 training loss= 0.00070 time= 0.44879\n",
      "validation roc= 0.96035 validation ap= 0.96307\n",
      "Epoch: 0181 training loss= 0.00070 time= 0.43181\n",
      "validation roc= 0.95996 validation ap= 0.96266\n",
      "Epoch: 0182 training loss= 0.00070 time= 0.43183\n",
      "validation roc= 0.95989 validation ap= 0.96278\n",
      "Epoch: 0183 training loss= 0.00070 time= 0.44097\n",
      "validation roc= 0.96026 validation ap= 0.96275\n",
      "Epoch: 0184 training loss= 0.00070 time= 0.42269\n",
      "validation roc= 0.95907 validation ap= 0.96240\n",
      "Epoch: 0185 training loss= 0.00070 time= 0.41510\n",
      "validation roc= 0.96070 validation ap= 0.96294\n",
      "Epoch: 0186 training loss= 0.00070 time= 0.40438\n",
      "validation roc= 0.95936 validation ap= 0.96280\n",
      "Epoch: 0187 training loss= 0.00070 time= 0.40921\n",
      "validation roc= 0.96029 validation ap= 0.96292\n",
      "Epoch: 0188 training loss= 0.00070 time= 0.42418\n",
      "validation roc= 0.96041 validation ap= 0.96318\n",
      "Epoch: 0189 training loss= 0.00070 time= 0.42637\n",
      "validation roc= 0.95950 validation ap= 0.96270\n",
      "Epoch: 0190 training loss= 0.00070 time= 0.41561\n",
      "validation roc= 0.96062 validation ap= 0.96331\n",
      "Epoch: 0191 training loss= 0.00070 time= 0.41634\n",
      "validation roc= 0.96008 validation ap= 0.96293\n",
      "Epoch: 0192 training loss= 0.00070 time= 0.39382\n",
      "validation roc= 0.95991 validation ap= 0.96299\n",
      "Epoch: 0193 training loss= 0.00070 time= 0.43552\n",
      "validation roc= 0.96033 validation ap= 0.96305\n",
      "Epoch: 0194 training loss= 0.00070 time= 0.43267\n",
      "validation roc= 0.96014 validation ap= 0.96304\n",
      "Epoch: 0195 training loss= 0.00070 time= 0.41288\n",
      "validation roc= 0.96000 validation ap= 0.96312\n",
      "Epoch: 0196 training loss= 0.00070 time= 0.40551\n",
      "validation roc= 0.95994 validation ap= 0.96265\n",
      "Epoch: 0197 training loss= 0.00070 time= 0.41362\n",
      "validation roc= 0.95994 validation ap= 0.96308\n",
      "Epoch: 0198 training loss= 0.00070 time= 0.42991\n",
      "validation roc= 0.95979 validation ap= 0.96300\n",
      "Epoch: 0199 training loss= 0.00070 time= 0.44066\n",
      "validation roc= 0.95963 validation ap= 0.96249\n",
      "Epoch: 0200 training loss= 0.00070 time= 0.41590\n",
      "validation roc= 0.95987 validation ap= 0.96316\n",
      "testing roc= 0.93964 testing ap= 0.94608\n",
      "Epoch: 0001 training loss= 0.00125 time= 1.89210\n",
      "validation roc= 0.69186 validation ap= 0.72117\n",
      "Epoch: 0002 training loss= 0.00124 time= 0.40742\n",
      "validation roc= 0.76815 validation ap= 0.78313\n",
      "Epoch: 0003 training loss= 0.00121 time= 0.44032\n",
      "validation roc= 0.70106 validation ap= 0.73800\n",
      "Epoch: 0004 training loss= 0.00119 time= 0.42902\n",
      "validation roc= 0.74436 validation ap= 0.78321\n",
      "Epoch: 0005 training loss= 0.00116 time= 0.41511\n",
      "validation roc= 0.80958 validation ap= 0.82859\n",
      "Epoch: 0006 training loss= 0.00110 time= 0.41876\n",
      "validation roc= 0.83504 validation ap= 0.83519\n",
      "Epoch: 0007 training loss= 0.00104 time= 0.43343\n",
      "validation roc= 0.84151 validation ap= 0.83311\n",
      "Epoch: 0008 training loss= 0.00101 time= 0.42871\n",
      "validation roc= 0.85032 validation ap= 0.84162\n",
      "Epoch: 0009 training loss= 0.00099 time= 0.41532\n",
      "validation roc= 0.85831 validation ap= 0.85089\n",
      "Epoch: 0010 training loss= 0.00099 time= 0.40324\n",
      "validation roc= 0.86621 validation ap= 0.85946\n",
      "Epoch: 0011 training loss= 0.00096 time= 0.39803\n",
      "validation roc= 0.87690 validation ap= 0.87062\n",
      "Epoch: 0012 training loss= 0.00094 time= 0.41594\n",
      "validation roc= 0.88436 validation ap= 0.87936\n",
      "Epoch: 0013 training loss= 0.00092 time= 0.40740\n",
      "validation roc= 0.88779 validation ap= 0.88440\n",
      "Epoch: 0014 training loss= 0.00092 time= 0.40539\n",
      "validation roc= 0.88824 validation ap= 0.88496\n",
      "Epoch: 0015 training loss= 0.00091 time= 0.41290\n",
      "validation roc= 0.88826 validation ap= 0.88493\n",
      "Epoch: 0016 training loss= 0.00091 time= 0.42574\n",
      "validation roc= 0.88991 validation ap= 0.88719\n",
      "Epoch: 0017 training loss= 0.00091 time= 0.44101\n",
      "validation roc= 0.89476 validation ap= 0.89336\n",
      "Epoch: 0018 training loss= 0.00090 time= 0.43788\n",
      "validation roc= 0.89912 validation ap= 0.89967\n",
      "Epoch: 0019 training loss= 0.00089 time= 0.42011\n",
      "validation roc= 0.90206 validation ap= 0.90291\n",
      "Epoch: 0020 training loss= 0.00088 time= 0.44542\n",
      "validation roc= 0.90248 validation ap= 0.90262\n",
      "Epoch: 0021 training loss= 0.00088 time= 0.42576\n",
      "validation roc= 0.90112 validation ap= 0.90032\n",
      "Epoch: 0022 training loss= 0.00088 time= 0.41172\n",
      "validation roc= 0.90074 validation ap= 0.89964\n",
      "Epoch: 0023 training loss= 0.00087 time= 0.42842\n",
      "validation roc= 0.90077 validation ap= 0.90094\n",
      "Epoch: 0024 training loss= 0.00087 time= 0.39003\n",
      "validation roc= 0.90079 validation ap= 0.90209\n",
      "Epoch: 0025 training loss= 0.00087 time= 0.40152\n",
      "validation roc= 0.90165 validation ap= 0.90328\n",
      "Epoch: 0026 training loss= 0.00086 time= 0.42663\n",
      "validation roc= 0.90353 validation ap= 0.90562\n",
      "Epoch: 0027 training loss= 0.00086 time= 0.42551\n",
      "validation roc= 0.90450 validation ap= 0.90772\n",
      "Epoch: 0028 training loss= 0.00085 time= 0.41689\n",
      "validation roc= 0.90596 validation ap= 0.91032\n",
      "Epoch: 0029 training loss= 0.00085 time= 0.43073\n",
      "validation roc= 0.90607 validation ap= 0.91036\n",
      "Epoch: 0030 training loss= 0.00084 time= 0.39960\n",
      "validation roc= 0.90648 validation ap= 0.91091\n",
      "Epoch: 0031 training loss= 0.00084 time= 0.43852\n",
      "validation roc= 0.90669 validation ap= 0.91102\n",
      "Epoch: 0032 training loss= 0.00084 time= 0.42463\n",
      "validation roc= 0.90739 validation ap= 0.91130\n",
      "Epoch: 0033 training loss= 0.00084 time= 0.44557\n",
      "validation roc= 0.90782 validation ap= 0.91147\n",
      "Epoch: 0034 training loss= 0.00083 time= 0.41193\n",
      "validation roc= 0.90939 validation ap= 0.91270\n",
      "Epoch: 0035 training loss= 0.00083 time= 0.44602\n",
      "validation roc= 0.91050 validation ap= 0.91421\n",
      "Epoch: 0036 training loss= 0.00083 time= 0.39852\n",
      "validation roc= 0.91089 validation ap= 0.91490\n",
      "Epoch: 0037 training loss= 0.00083 time= 0.41506\n",
      "validation roc= 0.91193 validation ap= 0.91614\n",
      "Epoch: 0038 training loss= 0.00082 time= 0.45392\n",
      "validation roc= 0.91263 validation ap= 0.91672\n",
      "Epoch: 0039 training loss= 0.00082 time= 0.41969\n",
      "validation roc= 0.91288 validation ap= 0.91672\n",
      "Epoch: 0040 training loss= 0.00082 time= 0.41685\n",
      "validation roc= 0.91411 validation ap= 0.91746\n",
      "Epoch: 0041 training loss= 0.00082 time= 0.41981\n",
      "validation roc= 0.91496 validation ap= 0.91800\n",
      "Epoch: 0042 training loss= 0.00081 time= 0.42443\n",
      "validation roc= 0.91576 validation ap= 0.91844\n",
      "Epoch: 0043 training loss= 0.00081 time= 0.41441\n",
      "validation roc= 0.91585 validation ap= 0.91807\n",
      "Epoch: 0044 training loss= 0.00081 time= 0.45665\n",
      "validation roc= 0.91688 validation ap= 0.91898\n",
      "Epoch: 0045 training loss= 0.00081 time= 0.41450\n",
      "validation roc= 0.91741 validation ap= 0.91960\n",
      "Epoch: 0046 training loss= 0.00081 time= 0.41123\n",
      "validation roc= 0.91824 validation ap= 0.92031\n",
      "Epoch: 0047 training loss= 0.00080 time= 0.42632\n",
      "validation roc= 0.91958 validation ap= 0.92154\n",
      "Epoch: 0048 training loss= 0.00080 time= 0.42660\n",
      "validation roc= 0.92063 validation ap= 0.92224\n",
      "Epoch: 0049 training loss= 0.00080 time= 0.42300\n",
      "validation roc= 0.92121 validation ap= 0.92268\n",
      "Epoch: 0050 training loss= 0.00080 time= 0.42830\n",
      "validation roc= 0.92173 validation ap= 0.92342\n",
      "Epoch: 0051 training loss= 0.00080 time= 0.40406\n",
      "validation roc= 0.92268 validation ap= 0.92440\n",
      "Epoch: 0052 training loss= 0.00080 time= 0.42458\n",
      "validation roc= 0.92348 validation ap= 0.92535\n",
      "Epoch: 0053 training loss= 0.00079 time= 0.44230\n",
      "validation roc= 0.92395 validation ap= 0.92623\n",
      "Epoch: 0054 training loss= 0.00079 time= 0.44119\n",
      "validation roc= 0.92503 validation ap= 0.92785\n",
      "Epoch: 0055 training loss= 0.00079 time= 0.41677\n",
      "validation roc= 0.92567 validation ap= 0.92868\n",
      "Epoch: 0056 training loss= 0.00079 time= 0.43019\n",
      "validation roc= 0.92680 validation ap= 0.92962\n",
      "Epoch: 0057 training loss= 0.00079 time= 0.43016\n",
      "validation roc= 0.92812 validation ap= 0.93074\n",
      "Epoch: 0058 training loss= 0.00079 time= 0.40881\n",
      "validation roc= 0.92936 validation ap= 0.93208\n",
      "Epoch: 0059 training loss= 0.00079 time= 0.42759\n",
      "validation roc= 0.93041 validation ap= 0.93326\n",
      "Epoch: 0060 training loss= 0.00078 time= 0.43755\n",
      "validation roc= 0.93124 validation ap= 0.93440\n",
      "Epoch: 0061 training loss= 0.00078 time= 0.39883\n",
      "validation roc= 0.93237 validation ap= 0.93568\n",
      "Epoch: 0062 training loss= 0.00078 time= 0.42582\n",
      "validation roc= 0.93353 validation ap= 0.93688\n",
      "Epoch: 0063 training loss= 0.00078 time= 0.43582\n",
      "validation roc= 0.93450 validation ap= 0.93776\n",
      "Epoch: 0064 training loss= 0.00078 time= 0.42877\n",
      "validation roc= 0.93538 validation ap= 0.93859\n",
      "Epoch: 0065 training loss= 0.00078 time= 0.41576\n",
      "validation roc= 0.93586 validation ap= 0.93900\n",
      "Epoch: 0066 training loss= 0.00078 time= 0.41449\n",
      "validation roc= 0.93617 validation ap= 0.93936\n",
      "Epoch: 0067 training loss= 0.00078 time= 0.42633\n",
      "validation roc= 0.93679 validation ap= 0.93999\n",
      "Epoch: 0068 training loss= 0.00077 time= 0.43036\n",
      "validation roc= 0.93703 validation ap= 0.94073\n",
      "Epoch: 0069 training loss= 0.00077 time= 0.42374\n",
      "validation roc= 0.93757 validation ap= 0.94178\n",
      "Epoch: 0070 training loss= 0.00077 time= 0.41522\n",
      "validation roc= 0.93803 validation ap= 0.94257\n",
      "Epoch: 0071 training loss= 0.00077 time= 0.43222\n",
      "validation roc= 0.93805 validation ap= 0.94265\n",
      "Epoch: 0072 training loss= 0.00077 time= 0.43450\n",
      "validation roc= 0.93854 validation ap= 0.94323\n",
      "Epoch: 0073 training loss= 0.00077 time= 0.43725\n",
      "validation roc= 0.93889 validation ap= 0.94356\n",
      "Epoch: 0074 training loss= 0.00077 time= 0.42862\n",
      "validation roc= 0.93906 validation ap= 0.94396\n",
      "Epoch: 0075 training loss= 0.00077 time= 0.44341\n",
      "validation roc= 0.93910 validation ap= 0.94420\n",
      "Epoch: 0076 training loss= 0.00076 time= 0.39726\n",
      "validation roc= 0.93906 validation ap= 0.94446\n",
      "Epoch: 0077 training loss= 0.00076 time= 0.39282\n",
      "validation roc= 0.93920 validation ap= 0.94481\n",
      "Epoch: 0078 training loss= 0.00076 time= 0.40039\n",
      "validation roc= 0.93918 validation ap= 0.94492\n",
      "Epoch: 0079 training loss= 0.00076 time= 0.37493\n",
      "validation roc= 0.93945 validation ap= 0.94534\n",
      "Epoch: 0080 training loss= 0.00076 time= 0.40328\n",
      "validation roc= 0.93943 validation ap= 0.94560\n",
      "Epoch: 0081 training loss= 0.00076 time= 0.40086\n",
      "validation roc= 0.93968 validation ap= 0.94616\n",
      "Epoch: 0082 training loss= 0.00076 time= 0.39916\n",
      "validation roc= 0.93968 validation ap= 0.94642\n",
      "Epoch: 0083 training loss= 0.00076 time= 0.41800\n",
      "validation roc= 0.93988 validation ap= 0.94667\n",
      "Epoch: 0084 training loss= 0.00075 time= 0.39833\n",
      "validation roc= 0.93968 validation ap= 0.94655\n",
      "Epoch: 0085 training loss= 0.00075 time= 0.43038\n",
      "validation roc= 0.93947 validation ap= 0.94660\n",
      "Epoch: 0086 training loss= 0.00075 time= 0.41909\n",
      "validation roc= 0.93897 validation ap= 0.94639\n",
      "Epoch: 0087 training loss= 0.00075 time= 0.36573\n",
      "validation roc= 0.93887 validation ap= 0.94649\n",
      "Epoch: 0088 training loss= 0.00075 time= 0.44777\n",
      "validation roc= 0.93871 validation ap= 0.94638\n",
      "Epoch: 0089 training loss= 0.00075 time= 0.38855\n",
      "validation roc= 0.93850 validation ap= 0.94628\n",
      "Epoch: 0090 training loss= 0.00075 time= 0.44694\n",
      "validation roc= 0.93854 validation ap= 0.94645\n",
      "Epoch: 0091 training loss= 0.00075 time= 0.41208\n",
      "validation roc= 0.93848 validation ap= 0.94639\n",
      "Epoch: 0092 training loss= 0.00075 time= 0.43811\n",
      "validation roc= 0.93856 validation ap= 0.94654\n",
      "Epoch: 0093 training loss= 0.00075 time= 0.42875\n",
      "validation roc= 0.93881 validation ap= 0.94682\n",
      "Epoch: 0094 training loss= 0.00075 time= 0.42873\n",
      "validation roc= 0.93875 validation ap= 0.94651\n",
      "Epoch: 0095 training loss= 0.00074 time= 0.43975\n",
      "validation roc= 0.93866 validation ap= 0.94651\n",
      "Epoch: 0096 training loss= 0.00074 time= 0.44764\n",
      "validation roc= 0.93862 validation ap= 0.94660\n",
      "Epoch: 0097 training loss= 0.00074 time= 0.41735\n",
      "validation roc= 0.93877 validation ap= 0.94677\n",
      "Epoch: 0098 training loss= 0.00074 time= 0.41559\n",
      "validation roc= 0.93869 validation ap= 0.94682\n",
      "Epoch: 0099 training loss= 0.00074 time= 0.43432\n",
      "validation roc= 0.93866 validation ap= 0.94699\n",
      "Epoch: 0100 training loss= 0.00074 time= 0.39918\n",
      "validation roc= 0.93868 validation ap= 0.94708\n",
      "Epoch: 0101 training loss= 0.00074 time= 0.42470\n",
      "validation roc= 0.93891 validation ap= 0.94728\n",
      "Epoch: 0102 training loss= 0.00074 time= 0.41388\n",
      "validation roc= 0.93914 validation ap= 0.94743\n",
      "Epoch: 0103 training loss= 0.00074 time= 0.44082\n",
      "validation roc= 0.93908 validation ap= 0.94741\n",
      "Epoch: 0104 training loss= 0.00074 time= 0.44323\n",
      "validation roc= 0.93932 validation ap= 0.94771\n",
      "Epoch: 0105 training loss= 0.00074 time= 0.42587\n",
      "validation roc= 0.93930 validation ap= 0.94773\n",
      "Epoch: 0106 training loss= 0.00074 time= 0.39771\n",
      "validation roc= 0.93928 validation ap= 0.94774\n",
      "Epoch: 0107 training loss= 0.00073 time= 0.34511\n",
      "validation roc= 0.93937 validation ap= 0.94794\n",
      "Epoch: 0108 training loss= 0.00073 time= 0.42595\n",
      "validation roc= 0.93945 validation ap= 0.94809\n",
      "Epoch: 0109 training loss= 0.00073 time= 0.43841\n",
      "validation roc= 0.93984 validation ap= 0.94827\n",
      "Epoch: 0110 training loss= 0.00073 time= 0.42979\n",
      "validation roc= 0.93994 validation ap= 0.94836\n",
      "Epoch: 0111 training loss= 0.00073 time= 0.39783\n",
      "validation roc= 0.93994 validation ap= 0.94848\n",
      "Epoch: 0112 training loss= 0.00073 time= 0.41378\n",
      "validation roc= 0.94015 validation ap= 0.94857\n",
      "Epoch: 0113 training loss= 0.00073 time= 0.41205\n",
      "validation roc= 0.94001 validation ap= 0.94842\n",
      "Epoch: 0114 training loss= 0.00073 time= 0.35235\n",
      "validation roc= 0.93998 validation ap= 0.94840\n",
      "Epoch: 0115 training loss= 0.00073 time= 0.33529\n",
      "validation roc= 0.94015 validation ap= 0.94858\n",
      "Epoch: 0116 training loss= 0.00073 time= 0.34396\n",
      "validation roc= 0.94031 validation ap= 0.94880\n",
      "Epoch: 0117 training loss= 0.00073 time= 0.34077\n",
      "validation roc= 0.94025 validation ap= 0.94867\n",
      "Epoch: 0118 training loss= 0.00073 time= 0.34047\n",
      "validation roc= 0.94029 validation ap= 0.94883\n",
      "Epoch: 0119 training loss= 0.00073 time= 0.40982\n",
      "validation roc= 0.94032 validation ap= 0.94875\n",
      "Epoch: 0120 training loss= 0.00073 time= 0.33916\n",
      "validation roc= 0.94005 validation ap= 0.94883\n",
      "Epoch: 0121 training loss= 0.00073 time= 0.34777\n",
      "validation roc= 0.94038 validation ap= 0.94880\n",
      "Epoch: 0122 training loss= 0.00073 time= 0.35141\n",
      "validation roc= 0.93984 validation ap= 0.94853\n",
      "Epoch: 0123 training loss= 0.00073 time= 0.35792\n",
      "validation roc= 0.94087 validation ap= 0.94950\n",
      "Epoch: 0124 training loss= 0.00072 time= 0.35004\n",
      "validation roc= 0.94009 validation ap= 0.94846\n",
      "Epoch: 0125 training loss= 0.00072 time= 0.36750\n",
      "validation roc= 0.94038 validation ap= 0.94942\n",
      "Epoch: 0126 training loss= 0.00072 time= 0.34664\n",
      "validation roc= 0.94038 validation ap= 0.94862\n",
      "Epoch: 0127 training loss= 0.00072 time= 0.35244\n",
      "validation roc= 0.94046 validation ap= 0.94930\n",
      "Epoch: 0128 training loss= 0.00072 time= 0.34466\n",
      "validation roc= 0.94046 validation ap= 0.94915\n",
      "Epoch: 0129 training loss= 0.00072 time= 0.40124\n",
      "validation roc= 0.94060 validation ap= 0.94884\n",
      "Epoch: 0130 training loss= 0.00072 time= 0.35811\n",
      "validation roc= 0.94067 validation ap= 0.94953\n",
      "Epoch: 0131 training loss= 0.00072 time= 0.41221\n",
      "validation roc= 0.94050 validation ap= 0.94890\n",
      "Epoch: 0132 training loss= 0.00072 time= 0.40576\n",
      "validation roc= 0.94062 validation ap= 0.94908\n",
      "Epoch: 0133 training loss= 0.00072 time= 0.41920\n",
      "validation roc= 0.94013 validation ap= 0.94895\n",
      "Epoch: 0134 training loss= 0.00072 time= 0.43102\n",
      "validation roc= 0.94040 validation ap= 0.94887\n",
      "Epoch: 0135 training loss= 0.00072 time= 0.40569\n",
      "validation roc= 0.93996 validation ap= 0.94877\n",
      "Epoch: 0136 training loss= 0.00072 time= 0.45891\n",
      "validation roc= 0.94013 validation ap= 0.94864\n",
      "Epoch: 0137 training loss= 0.00072 time= 0.42617\n",
      "validation roc= 0.94017 validation ap= 0.94883\n",
      "Epoch: 0138 training loss= 0.00072 time= 0.42623\n",
      "validation roc= 0.93957 validation ap= 0.94832\n",
      "Epoch: 0139 training loss= 0.00072 time= 0.45223\n",
      "validation roc= 0.93976 validation ap= 0.94853\n",
      "Epoch: 0140 training loss= 0.00072 time= 0.40744\n",
      "validation roc= 0.93963 validation ap= 0.94824\n",
      "Epoch: 0141 training loss= 0.00072 time= 0.40732\n",
      "validation roc= 0.93937 validation ap= 0.94833\n",
      "Epoch: 0142 training loss= 0.00071 time= 0.39111\n",
      "validation roc= 0.93941 validation ap= 0.94798\n",
      "Epoch: 0143 training loss= 0.00071 time= 0.37712\n",
      "validation roc= 0.93943 validation ap= 0.94837\n",
      "Epoch: 0144 training loss= 0.00071 time= 0.42209\n",
      "validation roc= 0.93934 validation ap= 0.94799\n",
      "Epoch: 0145 training loss= 0.00071 time= 0.41329\n",
      "validation roc= 0.93916 validation ap= 0.94809\n",
      "Epoch: 0146 training loss= 0.00071 time= 0.41791\n",
      "validation roc= 0.93897 validation ap= 0.94770\n",
      "Epoch: 0147 training loss= 0.00071 time= 0.40005\n",
      "validation roc= 0.93906 validation ap= 0.94792\n",
      "Epoch: 0148 training loss= 0.00071 time= 0.38159\n",
      "validation roc= 0.93860 validation ap= 0.94745\n",
      "Epoch: 0149 training loss= 0.00071 time= 0.39182\n",
      "validation roc= 0.93897 validation ap= 0.94777\n",
      "Epoch: 0150 training loss= 0.00071 time= 0.43323\n",
      "validation roc= 0.93856 validation ap= 0.94747\n",
      "Epoch: 0151 training loss= 0.00071 time= 0.42700\n",
      "validation roc= 0.93838 validation ap= 0.94719\n",
      "Epoch: 0152 training loss= 0.00071 time= 0.36025\n",
      "validation roc= 0.93852 validation ap= 0.94728\n",
      "Epoch: 0153 training loss= 0.00071 time= 0.44403\n",
      "validation roc= 0.93805 validation ap= 0.94675\n",
      "Epoch: 0154 training loss= 0.00071 time= 0.41667\n",
      "validation roc= 0.93803 validation ap= 0.94704\n",
      "Epoch: 0155 training loss= 0.00071 time= 0.42735\n",
      "validation roc= 0.93769 validation ap= 0.94644\n",
      "Epoch: 0156 training loss= 0.00071 time= 0.42679\n",
      "validation roc= 0.93734 validation ap= 0.94669\n",
      "Epoch: 0157 training loss= 0.00071 time= 0.42687\n",
      "validation roc= 0.93751 validation ap= 0.94647\n",
      "Epoch: 0158 training loss= 0.00071 time= 0.41600\n",
      "validation roc= 0.93720 validation ap= 0.94647\n",
      "Epoch: 0159 training loss= 0.00071 time= 0.43939\n",
      "validation roc= 0.93726 validation ap= 0.94633\n",
      "Epoch: 0160 training loss= 0.00071 time= 0.39717\n",
      "validation roc= 0.93675 validation ap= 0.94593\n",
      "Epoch: 0161 training loss= 0.00071 time= 0.40295\n",
      "validation roc= 0.93681 validation ap= 0.94608\n",
      "Epoch: 0162 training loss= 0.00071 time= 0.41343\n",
      "validation roc= 0.93695 validation ap= 0.94616\n",
      "Epoch: 0163 training loss= 0.00071 time= 0.43058\n",
      "validation roc= 0.93658 validation ap= 0.94599\n",
      "Epoch: 0164 training loss= 0.00071 time= 0.42327\n",
      "validation roc= 0.93705 validation ap= 0.94616\n",
      "Epoch: 0165 training loss= 0.00071 time= 0.46159\n",
      "validation roc= 0.93629 validation ap= 0.94592\n",
      "Epoch: 0166 training loss= 0.00070 time= 0.39944\n",
      "validation roc= 0.93728 validation ap= 0.94635\n",
      "Epoch: 0167 training loss= 0.00070 time= 0.43144\n",
      "validation roc= 0.93627 validation ap= 0.94572\n",
      "Epoch: 0168 training loss= 0.00070 time= 0.44862\n",
      "validation roc= 0.93677 validation ap= 0.94603\n",
      "Epoch: 0169 training loss= 0.00070 time= 0.43679\n",
      "validation roc= 0.93637 validation ap= 0.94578\n",
      "Epoch: 0170 training loss= 0.00070 time= 0.41199\n",
      "validation roc= 0.93677 validation ap= 0.94604\n",
      "Epoch: 0171 training loss= 0.00070 time= 0.42222\n",
      "validation roc= 0.93623 validation ap= 0.94562\n",
      "Epoch: 0172 training loss= 0.00070 time= 0.43394\n",
      "validation roc= 0.93629 validation ap= 0.94567\n",
      "Epoch: 0173 training loss= 0.00070 time= 0.42806\n",
      "validation roc= 0.93635 validation ap= 0.94564\n",
      "Epoch: 0174 training loss= 0.00070 time= 0.42661\n",
      "validation roc= 0.93571 validation ap= 0.94522\n",
      "Epoch: 0175 training loss= 0.00070 time= 0.43961\n",
      "validation roc= 0.93673 validation ap= 0.94586\n",
      "Epoch: 0176 training loss= 0.00070 time= 0.41571\n",
      "validation roc= 0.93518 validation ap= 0.94482\n",
      "Epoch: 0177 training loss= 0.00070 time= 0.41314\n",
      "validation roc= 0.93691 validation ap= 0.94600\n",
      "Epoch: 0178 training loss= 0.00070 time= 0.41283\n",
      "validation roc= 0.93489 validation ap= 0.94456\n",
      "Epoch: 0179 training loss= 0.00070 time= 0.40927\n",
      "validation roc= 0.93652 validation ap= 0.94571\n",
      "Epoch: 0180 training loss= 0.00070 time= 0.41063\n",
      "validation roc= 0.93557 validation ap= 0.94510\n",
      "Epoch: 0181 training loss= 0.00070 time= 0.38539\n",
      "validation roc= 0.93536 validation ap= 0.94498\n",
      "Epoch: 0182 training loss= 0.00070 time= 0.41603\n",
      "validation roc= 0.93619 validation ap= 0.94556\n",
      "Epoch: 0183 training loss= 0.00070 time= 0.41353\n",
      "validation roc= 0.93532 validation ap= 0.94508\n",
      "Epoch: 0184 training loss= 0.00070 time= 0.36420\n",
      "validation roc= 0.93613 validation ap= 0.94538\n",
      "Epoch: 0185 training loss= 0.00070 time= 0.42783\n",
      "validation roc= 0.93524 validation ap= 0.94527\n",
      "Epoch: 0186 training loss= 0.00070 time= 0.42436\n",
      "validation roc= 0.93580 validation ap= 0.94509\n",
      "Epoch: 0187 training loss= 0.00070 time= 0.40763\n",
      "validation roc= 0.93538 validation ap= 0.94533\n",
      "Epoch: 0188 training loss= 0.00070 time= 0.40076\n",
      "validation roc= 0.93536 validation ap= 0.94471\n",
      "Epoch: 0189 training loss= 0.00070 time= 0.42258\n",
      "validation roc= 0.93483 validation ap= 0.94521\n",
      "Epoch: 0190 training loss= 0.00070 time= 0.44039\n",
      "validation roc= 0.93563 validation ap= 0.94509\n",
      "Epoch: 0191 training loss= 0.00070 time= 0.41679\n",
      "validation roc= 0.93468 validation ap= 0.94476\n",
      "Epoch: 0192 training loss= 0.00070 time= 0.41127\n",
      "validation roc= 0.93528 validation ap= 0.94513\n",
      "Epoch: 0193 training loss= 0.00070 time= 0.40954\n",
      "validation roc= 0.93522 validation ap= 0.94479\n",
      "Epoch: 0194 training loss= 0.00070 time= 0.42396\n",
      "validation roc= 0.93509 validation ap= 0.94515\n",
      "Epoch: 0195 training loss= 0.00070 time= 0.41745\n",
      "validation roc= 0.93561 validation ap= 0.94509\n",
      "Epoch: 0196 training loss= 0.00070 time= 0.40791\n",
      "validation roc= 0.93540 validation ap= 0.94500\n",
      "Epoch: 0197 training loss= 0.00070 time= 0.41949\n",
      "validation roc= 0.93516 validation ap= 0.94506\n",
      "Epoch: 0198 training loss= 0.00070 time= 0.36986\n",
      "validation roc= 0.93596 validation ap= 0.94535\n",
      "Epoch: 0199 training loss= 0.00070 time= 0.37991\n",
      "validation roc= 0.93518 validation ap= 0.94496\n",
      "Epoch: 0200 training loss= 0.00070 time= 0.39051\n",
      "validation roc= 0.93530 validation ap= 0.94507\n",
      "testing roc= 0.94066 testing ap= 0.94896\n",
      "Epoch: 0001 training loss= 0.00125 time= 1.98707\n",
      "validation roc= 0.67106 validation ap= 0.68864\n",
      "Epoch: 0002 training loss= 0.00124 time= 0.41969\n",
      "validation roc= 0.77816 validation ap= 0.79568\n",
      "Epoch: 0003 training loss= 0.00121 time= 0.39631\n",
      "validation roc= 0.69334 validation ap= 0.73478\n",
      "Epoch: 0004 training loss= 0.00119 time= 0.42040\n",
      "validation roc= 0.75922 validation ap= 0.79567\n",
      "Epoch: 0005 training loss= 0.00116 time= 0.44070\n",
      "validation roc= 0.83206 validation ap= 0.85065\n",
      "Epoch: 0006 training loss= 0.00110 time= 0.40796\n",
      "validation roc= 0.84760 validation ap= 0.86094\n",
      "Epoch: 0007 training loss= 0.00105 time= 0.43462\n",
      "validation roc= 0.85713 validation ap= 0.86318\n",
      "Epoch: 0008 training loss= 0.00101 time= 0.41186\n",
      "validation roc= 0.86485 validation ap= 0.87000\n",
      "Epoch: 0009 training loss= 0.00099 time= 0.42199\n",
      "validation roc= 0.87114 validation ap= 0.87639\n",
      "Epoch: 0010 training loss= 0.00099 time= 0.41723\n",
      "validation roc= 0.88075 validation ap= 0.88458\n",
      "Epoch: 0011 training loss= 0.00096 time= 0.42790\n",
      "validation roc= 0.89280 validation ap= 0.89578\n",
      "Epoch: 0012 training loss= 0.00094 time= 0.40425\n",
      "validation roc= 0.90064 validation ap= 0.90424\n",
      "Epoch: 0013 training loss= 0.00092 time= 0.44086\n",
      "validation roc= 0.90425 validation ap= 0.90793\n",
      "Epoch: 0014 training loss= 0.00092 time= 0.41339\n",
      "validation roc= 0.90648 validation ap= 0.90888\n",
      "Epoch: 0015 training loss= 0.00092 time= 0.40538\n",
      "validation roc= 0.90920 validation ap= 0.91126\n",
      "Epoch: 0016 training loss= 0.00091 time= 0.41357\n",
      "validation roc= 0.91376 validation ap= 0.91602\n",
      "Epoch: 0017 training loss= 0.00091 time= 0.41289\n",
      "validation roc= 0.91871 validation ap= 0.92060\n",
      "Epoch: 0018 training loss= 0.00090 time= 0.38070\n",
      "validation roc= 0.92241 validation ap= 0.92340\n",
      "Epoch: 0019 training loss= 0.00089 time= 0.41047\n",
      "validation roc= 0.92352 validation ap= 0.92308\n",
      "Epoch: 0020 training loss= 0.00089 time= 0.43567\n",
      "validation roc= 0.92072 validation ap= 0.91862\n",
      "Epoch: 0021 training loss= 0.00088 time= 0.40366\n",
      "validation roc= 0.91711 validation ap= 0.91366\n",
      "Epoch: 0022 training loss= 0.00088 time= 0.43178\n",
      "validation roc= 0.91467 validation ap= 0.91095\n",
      "Epoch: 0023 training loss= 0.00088 time= 0.42892\n",
      "validation roc= 0.91416 validation ap= 0.91203\n",
      "Epoch: 0024 training loss= 0.00087 time= 0.42719\n",
      "validation roc= 0.91479 validation ap= 0.91399\n",
      "Epoch: 0025 training loss= 0.00087 time= 0.41993\n",
      "validation roc= 0.91682 validation ap= 0.91731\n",
      "Epoch: 0026 training loss= 0.00086 time= 0.43021\n",
      "validation roc= 0.91909 validation ap= 0.92068\n",
      "Epoch: 0027 training loss= 0.00086 time= 0.42380\n",
      "validation roc= 0.92160 validation ap= 0.92363\n",
      "Epoch: 0028 training loss= 0.00086 time= 0.41401\n",
      "validation roc= 0.92383 validation ap= 0.92666\n",
      "Epoch: 0029 training loss= 0.00085 time= 0.40750\n",
      "validation roc= 0.92556 validation ap= 0.92904\n",
      "Epoch: 0030 training loss= 0.00085 time= 0.41083\n",
      "validation roc= 0.92719 validation ap= 0.93118\n",
      "Epoch: 0031 training loss= 0.00084 time= 0.42369\n",
      "validation roc= 0.92822 validation ap= 0.93249\n",
      "Epoch: 0032 training loss= 0.00084 time= 0.42093\n",
      "validation roc= 0.92878 validation ap= 0.93352\n",
      "Epoch: 0033 training loss= 0.00084 time= 0.42779\n",
      "validation roc= 0.92940 validation ap= 0.93465\n",
      "Epoch: 0034 training loss= 0.00084 time= 0.39201\n",
      "validation roc= 0.92917 validation ap= 0.93476\n",
      "Epoch: 0035 training loss= 0.00083 time= 0.42169\n",
      "validation roc= 0.92886 validation ap= 0.93444\n",
      "Epoch: 0036 training loss= 0.00083 time= 0.42319\n",
      "validation roc= 0.92862 validation ap= 0.93450\n",
      "Epoch: 0037 training loss= 0.00083 time= 0.43500\n",
      "validation roc= 0.92858 validation ap= 0.93432\n",
      "Epoch: 0038 training loss= 0.00083 time= 0.41727\n",
      "validation roc= 0.92864 validation ap= 0.93469\n",
      "Epoch: 0039 training loss= 0.00082 time= 0.42236\n",
      "validation roc= 0.92833 validation ap= 0.93452\n",
      "Epoch: 0040 training loss= 0.00082 time= 0.42193\n",
      "validation roc= 0.92833 validation ap= 0.93478\n",
      "Epoch: 0041 training loss= 0.00082 time= 0.41797\n",
      "validation roc= 0.92884 validation ap= 0.93540\n",
      "Epoch: 0042 training loss= 0.00082 time= 0.41566\n",
      "validation roc= 0.92967 validation ap= 0.93621\n",
      "Epoch: 0043 training loss= 0.00081 time= 0.41512\n",
      "validation roc= 0.93076 validation ap= 0.93724\n",
      "Epoch: 0044 training loss= 0.00081 time= 0.42558\n",
      "validation roc= 0.93184 validation ap= 0.93827\n",
      "Epoch: 0045 training loss= 0.00081 time= 0.40826\n",
      "validation roc= 0.93239 validation ap= 0.93858\n",
      "Epoch: 0046 training loss= 0.00081 time= 0.40907\n",
      "validation roc= 0.93283 validation ap= 0.93920\n",
      "Epoch: 0047 training loss= 0.00080 time= 0.40751\n",
      "validation roc= 0.93318 validation ap= 0.93954\n",
      "Epoch: 0048 training loss= 0.00080 time= 0.39670\n",
      "validation roc= 0.93345 validation ap= 0.93990\n",
      "Epoch: 0049 training loss= 0.00080 time= 0.41150\n",
      "validation roc= 0.93408 validation ap= 0.94073\n",
      "Epoch: 0050 training loss= 0.00080 time= 0.38543\n",
      "validation roc= 0.93448 validation ap= 0.94128\n",
      "Epoch: 0051 training loss= 0.00080 time= 0.43054\n",
      "validation roc= 0.93474 validation ap= 0.94184\n",
      "Epoch: 0052 training loss= 0.00080 time= 0.44648\n",
      "validation roc= 0.93503 validation ap= 0.94224\n",
      "Epoch: 0053 training loss= 0.00079 time= 0.42826\n",
      "validation roc= 0.93545 validation ap= 0.94276\n",
      "Epoch: 0054 training loss= 0.00079 time= 0.40684\n",
      "validation roc= 0.93586 validation ap= 0.94328\n",
      "Epoch: 0055 training loss= 0.00079 time= 0.40657\n",
      "validation roc= 0.93635 validation ap= 0.94383\n",
      "Epoch: 0056 training loss= 0.00079 time= 0.42428\n",
      "validation roc= 0.93677 validation ap= 0.94421\n",
      "Epoch: 0057 training loss= 0.00079 time= 0.42001\n",
      "validation roc= 0.93720 validation ap= 0.94463\n",
      "Epoch: 0058 training loss= 0.00079 time= 0.43062\n",
      "validation roc= 0.93745 validation ap= 0.94482\n",
      "Epoch: 0059 training loss= 0.00079 time= 0.40235\n",
      "validation roc= 0.93792 validation ap= 0.94525\n",
      "Epoch: 0060 training loss= 0.00078 time= 0.40562\n",
      "validation roc= 0.93817 validation ap= 0.94527\n",
      "Epoch: 0061 training loss= 0.00078 time= 0.44017\n",
      "validation roc= 0.93871 validation ap= 0.94567\n",
      "Epoch: 0062 training loss= 0.00078 time= 0.41770\n",
      "validation roc= 0.93937 validation ap= 0.94641\n",
      "Epoch: 0063 training loss= 0.00078 time= 0.42333\n",
      "validation roc= 0.93976 validation ap= 0.94678\n",
      "Epoch: 0064 training loss= 0.00078 time= 0.41240\n",
      "validation roc= 0.94019 validation ap= 0.94705\n",
      "Epoch: 0065 training loss= 0.00078 time= 0.40911\n",
      "validation roc= 0.94116 validation ap= 0.94784\n",
      "Epoch: 0066 training loss= 0.00078 time= 0.41569\n",
      "validation roc= 0.94174 validation ap= 0.94814\n",
      "Epoch: 0067 training loss= 0.00077 time= 0.40877\n",
      "validation roc= 0.94240 validation ap= 0.94850\n",
      "Epoch: 0068 training loss= 0.00077 time= 0.40996\n",
      "validation roc= 0.94339 validation ap= 0.94920\n",
      "Epoch: 0069 training loss= 0.00077 time= 0.41656\n",
      "validation roc= 0.94409 validation ap= 0.94993\n",
      "Epoch: 0070 training loss= 0.00077 time= 0.41210\n",
      "validation roc= 0.94444 validation ap= 0.95024\n",
      "Epoch: 0071 training loss= 0.00077 time= 0.42425\n",
      "validation roc= 0.94494 validation ap= 0.95075\n",
      "Epoch: 0072 training loss= 0.00077 time= 0.41465\n",
      "validation roc= 0.94525 validation ap= 0.95114\n",
      "Epoch: 0073 training loss= 0.00077 time= 0.42166\n",
      "validation roc= 0.94593 validation ap= 0.95172\n",
      "Epoch: 0074 training loss= 0.00077 time= 0.41240\n",
      "validation roc= 0.94673 validation ap= 0.95249\n",
      "Epoch: 0075 training loss= 0.00077 time= 0.42125\n",
      "validation roc= 0.94752 validation ap= 0.95333\n",
      "Epoch: 0076 training loss= 0.00076 time= 0.43386\n",
      "validation roc= 0.94789 validation ap= 0.95380\n",
      "Epoch: 0077 training loss= 0.00076 time= 0.43655\n",
      "validation roc= 0.94848 validation ap= 0.95431\n",
      "Epoch: 0078 training loss= 0.00076 time= 0.39766\n",
      "validation roc= 0.94875 validation ap= 0.95460\n",
      "Epoch: 0079 training loss= 0.00076 time= 0.39009\n",
      "validation roc= 0.94925 validation ap= 0.95503\n",
      "Epoch: 0080 training loss= 0.00076 time= 0.42604\n",
      "validation roc= 0.94978 validation ap= 0.95560\n",
      "Epoch: 0081 training loss= 0.00076 time= 0.45352\n",
      "validation roc= 0.95016 validation ap= 0.95597\n",
      "Epoch: 0082 training loss= 0.00076 time= 0.39773\n",
      "validation roc= 0.95051 validation ap= 0.95641\n",
      "Epoch: 0083 training loss= 0.00076 time= 0.40491\n",
      "validation roc= 0.95084 validation ap= 0.95669\n",
      "Epoch: 0084 training loss= 0.00076 time= 0.40848\n",
      "validation roc= 0.95125 validation ap= 0.95705\n",
      "Epoch: 0085 training loss= 0.00075 time= 0.42676\n",
      "validation roc= 0.95166 validation ap= 0.95747\n",
      "Epoch: 0086 training loss= 0.00075 time= 0.38537\n",
      "validation roc= 0.95193 validation ap= 0.95761\n",
      "Epoch: 0087 training loss= 0.00075 time= 0.41904\n",
      "validation roc= 0.95230 validation ap= 0.95794\n",
      "Epoch: 0088 training loss= 0.00075 time= 0.40104\n",
      "validation roc= 0.95273 validation ap= 0.95829\n",
      "Epoch: 0089 training loss= 0.00075 time= 0.44526\n",
      "validation roc= 0.95337 validation ap= 0.95882\n",
      "Epoch: 0090 training loss= 0.00075 time= 0.42525\n",
      "validation roc= 0.95360 validation ap= 0.95901\n",
      "Epoch: 0091 training loss= 0.00075 time= 0.42172\n",
      "validation roc= 0.95368 validation ap= 0.95907\n",
      "Epoch: 0092 training loss= 0.00075 time= 0.43646\n",
      "validation roc= 0.95406 validation ap= 0.95934\n",
      "Epoch: 0093 training loss= 0.00075 time= 0.40706\n",
      "validation roc= 0.95453 validation ap= 0.95978\n",
      "Epoch: 0094 training loss= 0.00075 time= 0.42045\n",
      "validation roc= 0.95474 validation ap= 0.95983\n",
      "Epoch: 0095 training loss= 0.00074 time= 0.42902\n",
      "validation roc= 0.95502 validation ap= 0.96010\n",
      "Epoch: 0096 training loss= 0.00074 time= 0.41551\n",
      "validation roc= 0.95521 validation ap= 0.96012\n",
      "Epoch: 0097 training loss= 0.00074 time= 0.43547\n",
      "validation roc= 0.95533 validation ap= 0.96025\n",
      "Epoch: 0098 training loss= 0.00074 time= 0.42970\n",
      "validation roc= 0.95577 validation ap= 0.96068\n",
      "Epoch: 0099 training loss= 0.00074 time= 0.42140\n",
      "validation roc= 0.95566 validation ap= 0.96077\n",
      "Epoch: 0100 training loss= 0.00074 time= 0.41469\n",
      "validation roc= 0.95569 validation ap= 0.96089\n",
      "Epoch: 0101 training loss= 0.00074 time= 0.39454\n",
      "validation roc= 0.95579 validation ap= 0.96101\n",
      "Epoch: 0102 training loss= 0.00074 time= 0.40592\n",
      "validation roc= 0.95571 validation ap= 0.96105\n",
      "Epoch: 0103 training loss= 0.00074 time= 0.39241\n",
      "validation roc= 0.95566 validation ap= 0.96112\n",
      "Epoch: 0104 training loss= 0.00074 time= 0.37052\n",
      "validation roc= 0.95593 validation ap= 0.96143\n",
      "Epoch: 0105 training loss= 0.00074 time= 0.40042\n",
      "validation roc= 0.95602 validation ap= 0.96159\n",
      "Epoch: 0106 training loss= 0.00074 time= 0.39914\n",
      "validation roc= 0.95632 validation ap= 0.96203\n",
      "Epoch: 0107 training loss= 0.00074 time= 0.41739\n",
      "validation roc= 0.95676 validation ap= 0.96254\n",
      "Epoch: 0108 training loss= 0.00073 time= 0.35280\n",
      "validation roc= 0.95678 validation ap= 0.96261\n",
      "Epoch: 0109 training loss= 0.00073 time= 0.34673\n",
      "validation roc= 0.95676 validation ap= 0.96260\n",
      "Epoch: 0110 training loss= 0.00073 time= 0.33819\n",
      "validation roc= 0.95703 validation ap= 0.96291\n",
      "Epoch: 0111 training loss= 0.00073 time= 0.34278\n",
      "validation roc= 0.95719 validation ap= 0.96310\n",
      "Epoch: 0112 training loss= 0.00073 time= 0.35508\n",
      "validation roc= 0.95742 validation ap= 0.96333\n",
      "Epoch: 0113 training loss= 0.00073 time= 0.34314\n",
      "validation roc= 0.95777 validation ap= 0.96370\n",
      "Epoch: 0114 training loss= 0.00073 time= 0.33947\n",
      "validation roc= 0.95830 validation ap= 0.96416\n",
      "Epoch: 0115 training loss= 0.00073 time= 0.34725\n",
      "validation roc= 0.95831 validation ap= 0.96416\n",
      "Epoch: 0116 training loss= 0.00073 time= 0.35902\n",
      "validation roc= 0.95882 validation ap= 0.96458\n",
      "Epoch: 0117 training loss= 0.00073 time= 0.33565\n",
      "validation roc= 0.95845 validation ap= 0.96427\n",
      "Epoch: 0118 training loss= 0.00073 time= 0.35516\n",
      "validation roc= 0.95994 validation ap= 0.96546\n",
      "Epoch: 0119 training loss= 0.00073 time= 0.34657\n",
      "validation roc= 0.95878 validation ap= 0.96454\n",
      "Epoch: 0120 training loss= 0.00073 time= 0.35152\n",
      "validation roc= 0.96134 validation ap= 0.96646\n",
      "Epoch: 0121 training loss= 0.00073 time= 0.35893\n",
      "validation roc= 0.95913 validation ap= 0.96464\n",
      "Epoch: 0122 training loss= 0.00073 time= 0.33798\n",
      "validation roc= 0.96154 validation ap= 0.96674\n",
      "Epoch: 0123 training loss= 0.00072 time= 0.33453\n",
      "validation roc= 0.96132 validation ap= 0.96638\n",
      "Epoch: 0124 training loss= 0.00072 time= 0.40421\n",
      "validation roc= 0.96105 validation ap= 0.96637\n",
      "Epoch: 0125 training loss= 0.00072 time= 0.33455\n",
      "validation roc= 0.96231 validation ap= 0.96731\n",
      "Epoch: 0126 training loss= 0.00072 time= 0.39840\n",
      "validation roc= 0.96251 validation ap= 0.96758\n",
      "Epoch: 0127 training loss= 0.00072 time= 0.42468\n",
      "validation roc= 0.96229 validation ap= 0.96742\n",
      "Epoch: 0128 training loss= 0.00072 time= 0.42285\n",
      "validation roc= 0.96390 validation ap= 0.96864\n",
      "Epoch: 0129 training loss= 0.00072 time= 0.40966\n",
      "validation roc= 0.96338 validation ap= 0.96841\n",
      "Epoch: 0130 training loss= 0.00072 time= 0.43964\n",
      "validation roc= 0.96373 validation ap= 0.96864\n",
      "Epoch: 0131 training loss= 0.00072 time= 0.41397\n",
      "validation roc= 0.96482 validation ap= 0.96950\n",
      "Epoch: 0132 training loss= 0.00072 time= 0.41155\n",
      "validation roc= 0.96406 validation ap= 0.96906\n",
      "Epoch: 0133 training loss= 0.00072 time= 0.40413\n",
      "validation roc= 0.96530 validation ap= 0.97007\n",
      "Epoch: 0134 training loss= 0.00072 time= 0.41584\n",
      "validation roc= 0.96573 validation ap= 0.97046\n",
      "Epoch: 0135 training loss= 0.00072 time= 0.40950\n",
      "validation roc= 0.96511 validation ap= 0.96997\n",
      "Epoch: 0136 training loss= 0.00072 time= 0.43003\n",
      "validation roc= 0.96648 validation ap= 0.97116\n",
      "Epoch: 0137 training loss= 0.00072 time= 0.40772\n",
      "validation roc= 0.96614 validation ap= 0.97092\n",
      "Epoch: 0138 training loss= 0.00072 time= 0.40551\n",
      "validation roc= 0.96656 validation ap= 0.97131\n",
      "Epoch: 0139 training loss= 0.00072 time= 0.42097\n",
      "validation roc= 0.96732 validation ap= 0.97189\n",
      "Epoch: 0140 training loss= 0.00072 time= 0.38654\n",
      "validation roc= 0.96697 validation ap= 0.97165\n",
      "Epoch: 0141 training loss= 0.00072 time= 0.40173\n",
      "validation roc= 0.96773 validation ap= 0.97228\n",
      "Epoch: 0142 training loss= 0.00072 time= 0.42948\n",
      "validation roc= 0.96777 validation ap= 0.97237\n",
      "Epoch: 0143 training loss= 0.00072 time= 0.42272\n",
      "validation roc= 0.96755 validation ap= 0.97214\n",
      "Epoch: 0144 training loss= 0.00071 time= 0.42869\n",
      "validation roc= 0.96844 validation ap= 0.97295\n",
      "Epoch: 0145 training loss= 0.00071 time= 0.42887\n",
      "validation roc= 0.96835 validation ap= 0.97280\n",
      "Epoch: 0146 training loss= 0.00071 time= 0.42735\n",
      "validation roc= 0.96833 validation ap= 0.97286\n",
      "Epoch: 0147 training loss= 0.00071 time= 0.43955\n",
      "validation roc= 0.96905 validation ap= 0.97346\n",
      "Epoch: 0148 training loss= 0.00071 time= 0.39879\n",
      "validation roc= 0.96837 validation ap= 0.97282\n",
      "Epoch: 0149 training loss= 0.00071 time= 0.43369\n",
      "validation roc= 0.96899 validation ap= 0.97335\n",
      "Epoch: 0150 training loss= 0.00071 time= 0.43756\n",
      "validation roc= 0.96868 validation ap= 0.97307\n",
      "Epoch: 0151 training loss= 0.00071 time= 0.43260\n",
      "validation roc= 0.96903 validation ap= 0.97336\n",
      "Epoch: 0152 training loss= 0.00071 time= 0.43002\n",
      "validation roc= 0.96897 validation ap= 0.97324\n",
      "Epoch: 0153 training loss= 0.00071 time= 0.41776\n",
      "validation roc= 0.96922 validation ap= 0.97365\n",
      "Epoch: 0154 training loss= 0.00071 time= 0.41786\n",
      "validation roc= 0.96889 validation ap= 0.97312\n",
      "Epoch: 0155 training loss= 0.00071 time= 0.42027\n",
      "validation roc= 0.96953 validation ap= 0.97385\n",
      "Epoch: 0156 training loss= 0.00071 time= 0.40568\n",
      "validation roc= 0.96893 validation ap= 0.97308\n",
      "Epoch: 0157 training loss= 0.00071 time= 0.43249\n",
      "validation roc= 0.96971 validation ap= 0.97389\n",
      "Epoch: 0158 training loss= 0.00071 time= 0.42126\n",
      "validation roc= 0.96938 validation ap= 0.97358\n",
      "Epoch: 0159 training loss= 0.00071 time= 0.37706\n",
      "validation roc= 0.96963 validation ap= 0.97368\n",
      "Epoch: 0160 training loss= 0.00071 time= 0.40286\n",
      "validation roc= 0.96992 validation ap= 0.97410\n",
      "Epoch: 0161 training loss= 0.00071 time= 0.39705\n",
      "validation roc= 0.96943 validation ap= 0.97356\n",
      "Epoch: 0162 training loss= 0.00071 time= 0.41085\n",
      "validation roc= 0.97021 validation ap= 0.97430\n",
      "Epoch: 0163 training loss= 0.00071 time= 0.39006\n",
      "validation roc= 0.97008 validation ap= 0.97412\n",
      "Epoch: 0164 training loss= 0.00071 time= 0.40540\n",
      "validation roc= 0.97035 validation ap= 0.97438\n",
      "Epoch: 0165 training loss= 0.00071 time= 0.41522\n",
      "validation roc= 0.97027 validation ap= 0.97433\n",
      "Epoch: 0166 training loss= 0.00071 time= 0.41790\n",
      "validation roc= 0.97019 validation ap= 0.97420\n",
      "Epoch: 0167 training loss= 0.00071 time= 0.42992\n",
      "validation roc= 0.97066 validation ap= 0.97474\n",
      "Epoch: 0168 training loss= 0.00071 time= 0.39095\n",
      "validation roc= 0.97060 validation ap= 0.97457\n",
      "Epoch: 0169 training loss= 0.00071 time= 0.41367\n",
      "validation roc= 0.97070 validation ap= 0.97465\n",
      "Epoch: 0170 training loss= 0.00071 time= 0.38334\n",
      "validation roc= 0.97066 validation ap= 0.97471\n",
      "Epoch: 0171 training loss= 0.00071 time= 0.42241\n",
      "validation roc= 0.97070 validation ap= 0.97457\n",
      "Epoch: 0172 training loss= 0.00071 time= 0.41265\n",
      "validation roc= 0.97095 validation ap= 0.97497\n",
      "Epoch: 0173 training loss= 0.00071 time= 0.41548\n",
      "validation roc= 0.97054 validation ap= 0.97455\n",
      "Epoch: 0174 training loss= 0.00070 time= 0.41771\n",
      "validation roc= 0.97097 validation ap= 0.97487\n",
      "Epoch: 0175 training loss= 0.00070 time= 0.39348\n",
      "validation roc= 0.97058 validation ap= 0.97459\n",
      "Epoch: 0176 training loss= 0.00070 time= 0.40592\n",
      "validation roc= 0.97095 validation ap= 0.97484\n",
      "Epoch: 0177 training loss= 0.00070 time= 0.41161\n",
      "validation roc= 0.97079 validation ap= 0.97476\n",
      "Epoch: 0178 training loss= 0.00070 time= 0.42553\n",
      "validation roc= 0.97112 validation ap= 0.97502\n",
      "Epoch: 0179 training loss= 0.00070 time= 0.42482\n",
      "validation roc= 0.97103 validation ap= 0.97495\n",
      "Epoch: 0180 training loss= 0.00070 time= 0.42735\n",
      "validation roc= 0.97116 validation ap= 0.97507\n",
      "Epoch: 0181 training loss= 0.00070 time= 0.40704\n",
      "validation roc= 0.97079 validation ap= 0.97464\n",
      "Epoch: 0182 training loss= 0.00070 time= 0.41984\n",
      "validation roc= 0.97112 validation ap= 0.97494\n",
      "Epoch: 0183 training loss= 0.00070 time= 0.42332\n",
      "validation roc= 0.97039 validation ap= 0.97430\n",
      "Epoch: 0184 training loss= 0.00070 time= 0.44955\n",
      "validation roc= 0.97145 validation ap= 0.97524\n",
      "Epoch: 0185 training loss= 0.00070 time= 0.42524\n",
      "validation roc= 0.97072 validation ap= 0.97453\n",
      "Epoch: 0186 training loss= 0.00070 time= 0.44065\n",
      "validation roc= 0.97167 validation ap= 0.97536\n",
      "Epoch: 0187 training loss= 0.00070 time= 0.45379\n",
      "validation roc= 0.97112 validation ap= 0.97504\n",
      "Epoch: 0188 training loss= 0.00070 time= 0.39116\n",
      "validation roc= 0.97134 validation ap= 0.97515\n",
      "Epoch: 0189 training loss= 0.00070 time= 0.39734\n",
      "validation roc= 0.97153 validation ap= 0.97520\n",
      "Epoch: 0190 training loss= 0.00070 time= 0.40738\n",
      "validation roc= 0.97106 validation ap= 0.97499\n",
      "Epoch: 0191 training loss= 0.00070 time= 0.40219\n",
      "validation roc= 0.97153 validation ap= 0.97522\n",
      "Epoch: 0192 training loss= 0.00070 time= 0.39697\n",
      "validation roc= 0.97143 validation ap= 0.97519\n",
      "Epoch: 0193 training loss= 0.00070 time= 0.41028\n",
      "validation roc= 0.97087 validation ap= 0.97478\n",
      "Epoch: 0194 training loss= 0.00070 time= 0.41091\n",
      "validation roc= 0.97120 validation ap= 0.97497\n",
      "Epoch: 0195 training loss= 0.00070 time= 0.42433\n",
      "validation roc= 0.97124 validation ap= 0.97509\n",
      "Epoch: 0196 training loss= 0.00070 time= 0.41896\n",
      "validation roc= 0.97099 validation ap= 0.97494\n",
      "Epoch: 0197 training loss= 0.00070 time= 0.39415\n",
      "validation roc= 0.97112 validation ap= 0.97495\n",
      "Epoch: 0198 training loss= 0.00070 time= 0.39656\n",
      "validation roc= 0.97122 validation ap= 0.97510\n",
      "Epoch: 0199 training loss= 0.00070 time= 0.40539\n",
      "validation roc= 0.97101 validation ap= 0.97493\n",
      "Epoch: 0200 training loss= 0.00070 time= 0.40539\n",
      "validation roc= 0.97093 validation ap= 0.97483\n",
      "testing roc= 0.93741 testing ap= 0.94922\n",
      "Epoch: 0001 training loss= 0.00125 time= 2.20755\n",
      "validation roc= 0.67118 validation ap= 0.69505\n",
      "Epoch: 0002 training loss= 0.00124 time= 0.43835\n",
      "validation roc= 0.74678 validation ap= 0.74255\n",
      "Epoch: 0003 training loss= 0.00121 time= 0.42474\n",
      "validation roc= 0.67030 validation ap= 0.67816\n",
      "Epoch: 0004 training loss= 0.00119 time= 0.45726\n",
      "validation roc= 0.73475 validation ap= 0.75435\n",
      "Epoch: 0005 training loss= 0.00116 time= 0.44563\n",
      "validation roc= 0.81810 validation ap= 0.83062\n",
      "Epoch: 0006 training loss= 0.00109 time= 0.42884\n",
      "validation roc= 0.84974 validation ap= 0.85967\n",
      "Epoch: 0007 training loss= 0.00104 time= 0.41604\n",
      "validation roc= 0.85899 validation ap= 0.86395\n",
      "Epoch: 0008 training loss= 0.00100 time= 0.39989\n",
      "validation roc= 0.86435 validation ap= 0.86689\n",
      "Epoch: 0009 training loss= 0.00099 time= 0.40326\n",
      "validation roc= 0.86856 validation ap= 0.87041\n",
      "Epoch: 0010 training loss= 0.00098 time= 0.41826\n",
      "validation roc= 0.87611 validation ap= 0.87600\n",
      "Epoch: 0011 training loss= 0.00096 time= 0.41315\n",
      "validation roc= 0.88506 validation ap= 0.88308\n",
      "Epoch: 0012 training loss= 0.00093 time= 0.40362\n",
      "validation roc= 0.89156 validation ap= 0.88890\n",
      "Epoch: 0013 training loss= 0.00092 time= 0.41574\n",
      "validation roc= 0.89336 validation ap= 0.88991\n",
      "Epoch: 0014 training loss= 0.00092 time= 0.41053\n",
      "validation roc= 0.89208 validation ap= 0.88815\n",
      "Epoch: 0015 training loss= 0.00091 time= 0.40708\n",
      "validation roc= 0.89128 validation ap= 0.88718\n",
      "Epoch: 0016 training loss= 0.00091 time= 0.42390\n",
      "validation roc= 0.89348 validation ap= 0.88925\n",
      "Epoch: 0017 training loss= 0.00090 time= 0.40850\n",
      "validation roc= 0.89806 validation ap= 0.89521\n",
      "Epoch: 0018 training loss= 0.00090 time= 0.40591\n",
      "validation roc= 0.90188 validation ap= 0.90054\n",
      "Epoch: 0019 training loss= 0.00089 time= 0.44954\n",
      "validation roc= 0.90409 validation ap= 0.90463\n",
      "Epoch: 0020 training loss= 0.00088 time= 0.40341\n",
      "validation roc= 0.90473 validation ap= 0.90730\n",
      "Epoch: 0021 training loss= 0.00088 time= 0.40507\n",
      "validation roc= 0.90392 validation ap= 0.90782\n",
      "Epoch: 0022 training loss= 0.00087 time= 0.42382\n",
      "validation roc= 0.90206 validation ap= 0.90594\n",
      "Epoch: 0023 training loss= 0.00087 time= 0.41648\n",
      "validation roc= 0.90011 validation ap= 0.90391\n",
      "Epoch: 0024 training loss= 0.00087 time= 0.38570\n",
      "validation roc= 0.89942 validation ap= 0.90299\n",
      "Epoch: 0025 training loss= 0.00086 time= 0.42307\n",
      "validation roc= 0.90062 validation ap= 0.90450\n",
      "Epoch: 0026 training loss= 0.00086 time= 0.41772\n",
      "validation roc= 0.90262 validation ap= 0.90688\n",
      "Epoch: 0027 training loss= 0.00085 time= 0.39554\n",
      "validation roc= 0.90446 validation ap= 0.90924\n",
      "Epoch: 0028 training loss= 0.00085 time= 0.41595\n",
      "validation roc= 0.90535 validation ap= 0.91054\n",
      "Epoch: 0029 training loss= 0.00085 time= 0.44381\n",
      "validation roc= 0.90625 validation ap= 0.91167\n",
      "Epoch: 0030 training loss= 0.00084 time= 0.39733\n",
      "validation roc= 0.90625 validation ap= 0.91145\n",
      "Epoch: 0031 training loss= 0.00084 time= 0.42533\n",
      "validation roc= 0.90572 validation ap= 0.91109\n",
      "Epoch: 0032 training loss= 0.00084 time= 0.42082\n",
      "validation roc= 0.90714 validation ap= 0.91219\n",
      "Epoch: 0033 training loss= 0.00083 time= 0.39678\n",
      "validation roc= 0.91001 validation ap= 0.91407\n",
      "Epoch: 0034 training loss= 0.00083 time= 0.40340\n",
      "validation roc= 0.91255 validation ap= 0.91584\n",
      "Epoch: 0035 training loss= 0.00083 time= 0.38962\n",
      "validation roc= 0.91434 validation ap= 0.91674\n",
      "Epoch: 0036 training loss= 0.00083 time= 0.41119\n",
      "validation roc= 0.91492 validation ap= 0.91670\n",
      "Epoch: 0037 training loss= 0.00082 time= 0.41510\n",
      "validation roc= 0.91490 validation ap= 0.91589\n",
      "Epoch: 0038 training loss= 0.00082 time= 0.40447\n",
      "validation roc= 0.91570 validation ap= 0.91648\n",
      "Epoch: 0039 training loss= 0.00082 time= 0.43572\n",
      "validation roc= 0.91678 validation ap= 0.91726\n",
      "Epoch: 0040 training loss= 0.00082 time= 0.39396\n",
      "validation roc= 0.91799 validation ap= 0.91817\n",
      "Epoch: 0041 training loss= 0.00081 time= 0.41291\n",
      "validation roc= 0.91935 validation ap= 0.91990\n",
      "Epoch: 0042 training loss= 0.00081 time= 0.40758\n",
      "validation roc= 0.92078 validation ap= 0.92172\n",
      "Epoch: 0043 training loss= 0.00081 time= 0.39246\n",
      "validation roc= 0.92142 validation ap= 0.92254\n",
      "Epoch: 0044 training loss= 0.00081 time= 0.42467\n",
      "validation roc= 0.92214 validation ap= 0.92344\n",
      "Epoch: 0045 training loss= 0.00081 time= 0.39456\n",
      "validation roc= 0.92255 validation ap= 0.92402\n",
      "Epoch: 0046 training loss= 0.00080 time= 0.42853\n",
      "validation roc= 0.92395 validation ap= 0.92533\n",
      "Epoch: 0047 training loss= 0.00080 time= 0.39497\n",
      "validation roc= 0.92488 validation ap= 0.92624\n",
      "Epoch: 0048 training loss= 0.00080 time= 0.42132\n",
      "validation roc= 0.92598 validation ap= 0.92729\n",
      "Epoch: 0049 training loss= 0.00080 time= 0.44589\n",
      "validation roc= 0.92705 validation ap= 0.92849\n",
      "Epoch: 0050 training loss= 0.00080 time= 0.39606\n",
      "validation roc= 0.92757 validation ap= 0.92926\n",
      "Epoch: 0051 training loss= 0.00079 time= 0.40014\n",
      "validation roc= 0.92783 validation ap= 0.93017\n",
      "Epoch: 0052 training loss= 0.00079 time= 0.39383\n",
      "validation roc= 0.92847 validation ap= 0.93103\n",
      "Epoch: 0053 training loss= 0.00079 time= 0.39763\n",
      "validation roc= 0.92909 validation ap= 0.93181\n",
      "Epoch: 0054 training loss= 0.00079 time= 0.39801\n",
      "validation roc= 0.93006 validation ap= 0.93267\n",
      "Epoch: 0055 training loss= 0.00079 time= 0.42040\n",
      "validation roc= 0.93072 validation ap= 0.93343\n",
      "Epoch: 0056 training loss= 0.00079 time= 0.42470\n",
      "validation roc= 0.93167 validation ap= 0.93428\n",
      "Epoch: 0057 training loss= 0.00079 time= 0.41791\n",
      "validation roc= 0.93231 validation ap= 0.93506\n",
      "Epoch: 0058 training loss= 0.00078 time= 0.40504\n",
      "validation roc= 0.93289 validation ap= 0.93581\n",
      "Epoch: 0059 training loss= 0.00078 time= 0.42035\n",
      "validation roc= 0.93326 validation ap= 0.93648\n",
      "Epoch: 0060 training loss= 0.00078 time= 0.42459\n",
      "validation roc= 0.93351 validation ap= 0.93724\n",
      "Epoch: 0061 training loss= 0.00078 time= 0.40075\n",
      "validation roc= 0.93433 validation ap= 0.93829\n",
      "Epoch: 0062 training loss= 0.00078 time= 0.41353\n",
      "validation roc= 0.93477 validation ap= 0.93900\n",
      "Epoch: 0063 training loss= 0.00078 time= 0.39579\n",
      "validation roc= 0.93518 validation ap= 0.93965\n",
      "Epoch: 0064 training loss= 0.00078 time= 0.40527\n",
      "validation roc= 0.93534 validation ap= 0.94016\n",
      "Epoch: 0065 training loss= 0.00077 time= 0.40279\n",
      "validation roc= 0.93563 validation ap= 0.94092\n",
      "Epoch: 0066 training loss= 0.00077 time= 0.41680\n",
      "validation roc= 0.93594 validation ap= 0.94168\n",
      "Epoch: 0067 training loss= 0.00077 time= 0.40295\n",
      "validation roc= 0.93637 validation ap= 0.94243\n",
      "Epoch: 0068 training loss= 0.00077 time= 0.40081\n",
      "validation roc= 0.93656 validation ap= 0.94297\n",
      "Epoch: 0069 training loss= 0.00077 time= 0.41997\n",
      "validation roc= 0.93689 validation ap= 0.94364\n",
      "Epoch: 0070 training loss= 0.00077 time= 0.40786\n",
      "validation roc= 0.93706 validation ap= 0.94403\n",
      "Epoch: 0071 training loss= 0.00077 time= 0.41790\n",
      "validation roc= 0.93708 validation ap= 0.94418\n",
      "Epoch: 0072 training loss= 0.00077 time= 0.41908\n",
      "validation roc= 0.93741 validation ap= 0.94446\n",
      "Epoch: 0073 training loss= 0.00076 time= 0.41881\n",
      "validation roc= 0.93774 validation ap= 0.94497\n",
      "Epoch: 0074 training loss= 0.00076 time= 0.42622\n",
      "validation roc= 0.93782 validation ap= 0.94522\n",
      "Epoch: 0075 training loss= 0.00076 time= 0.39559\n",
      "validation roc= 0.93807 validation ap= 0.94546\n",
      "Epoch: 0076 training loss= 0.00076 time= 0.40453\n",
      "validation roc= 0.93829 validation ap= 0.94578\n",
      "Epoch: 0077 training loss= 0.00076 time= 0.43132\n",
      "validation roc= 0.93825 validation ap= 0.94562\n",
      "Epoch: 0078 training loss= 0.00076 time= 0.40800\n",
      "validation roc= 0.93813 validation ap= 0.94549\n",
      "Epoch: 0079 training loss= 0.00076 time= 0.42666\n",
      "validation roc= 0.93821 validation ap= 0.94556\n",
      "Epoch: 0080 training loss= 0.00076 time= 0.39909\n",
      "validation roc= 0.93835 validation ap= 0.94574\n",
      "Epoch: 0081 training loss= 0.00076 time= 0.41498\n",
      "validation roc= 0.93836 validation ap= 0.94582\n",
      "Epoch: 0082 training loss= 0.00075 time= 0.41611\n",
      "validation roc= 0.93825 validation ap= 0.94568\n",
      "Epoch: 0083 training loss= 0.00075 time= 0.41456\n",
      "validation roc= 0.93825 validation ap= 0.94574\n",
      "Epoch: 0084 training loss= 0.00075 time= 0.41270\n",
      "validation roc= 0.93800 validation ap= 0.94567\n",
      "Epoch: 0085 training loss= 0.00075 time= 0.41999\n",
      "validation roc= 0.93842 validation ap= 0.94608\n",
      "Epoch: 0086 training loss= 0.00075 time= 0.42192\n",
      "validation roc= 0.93854 validation ap= 0.94624\n",
      "Epoch: 0087 training loss= 0.00075 time= 0.38433\n",
      "validation roc= 0.93838 validation ap= 0.94626\n",
      "Epoch: 0088 training loss= 0.00075 time= 0.41732\n",
      "validation roc= 0.93829 validation ap= 0.94630\n",
      "Epoch: 0089 training loss= 0.00075 time= 0.43400\n",
      "validation roc= 0.93846 validation ap= 0.94643\n",
      "Epoch: 0090 training loss= 0.00075 time= 0.42384\n",
      "validation roc= 0.93840 validation ap= 0.94637\n",
      "Epoch: 0091 training loss= 0.00075 time= 0.41800\n",
      "validation roc= 0.93819 validation ap= 0.94618\n",
      "Epoch: 0092 training loss= 0.00074 time= 0.45382\n",
      "validation roc= 0.93823 validation ap= 0.94628\n",
      "Epoch: 0093 training loss= 0.00074 time= 0.42204\n",
      "validation roc= 0.93869 validation ap= 0.94654\n",
      "Epoch: 0094 training loss= 0.00074 time= 0.41411\n",
      "validation roc= 0.93889 validation ap= 0.94669\n",
      "Epoch: 0095 training loss= 0.00074 time= 0.44511\n",
      "validation roc= 0.93924 validation ap= 0.94708\n",
      "Epoch: 0096 training loss= 0.00074 time= 0.41666\n",
      "validation roc= 0.93939 validation ap= 0.94716\n",
      "Epoch: 0097 training loss= 0.00074 time= 0.41760\n",
      "validation roc= 0.93972 validation ap= 0.94736\n",
      "Epoch: 0098 training loss= 0.00074 time= 0.41250\n",
      "validation roc= 0.93996 validation ap= 0.94759\n",
      "Epoch: 0099 training loss= 0.00074 time= 0.35315\n",
      "validation roc= 0.94003 validation ap= 0.94768\n",
      "Epoch: 0100 training loss= 0.00074 time= 0.33463\n",
      "validation roc= 0.94065 validation ap= 0.94818\n",
      "Epoch: 0101 training loss= 0.00074 time= 0.34604\n",
      "validation roc= 0.94102 validation ap= 0.94860\n",
      "Epoch: 0102 training loss= 0.00074 time= 0.33187\n",
      "validation roc= 0.94139 validation ap= 0.94893\n",
      "Epoch: 0103 training loss= 0.00074 time= 0.34621\n",
      "validation roc= 0.94126 validation ap= 0.94873\n",
      "Epoch: 0104 training loss= 0.00074 time= 0.34467\n",
      "validation roc= 0.94149 validation ap= 0.94899\n",
      "Epoch: 0105 training loss= 0.00073 time= 0.33742\n",
      "validation roc= 0.94131 validation ap= 0.94890\n",
      "Epoch: 0106 training loss= 0.00073 time= 0.35110\n",
      "validation roc= 0.94135 validation ap= 0.94889\n",
      "Epoch: 0107 training loss= 0.00073 time= 0.33695\n",
      "validation roc= 0.94122 validation ap= 0.94869\n",
      "Epoch: 0108 training loss= 0.00073 time= 0.33620\n",
      "validation roc= 0.94108 validation ap= 0.94859\n",
      "Epoch: 0109 training loss= 0.00073 time= 0.33859\n",
      "validation roc= 0.94075 validation ap= 0.94827\n",
      "Epoch: 0110 training loss= 0.00073 time= 0.41264\n",
      "validation roc= 0.94073 validation ap= 0.94833\n",
      "Epoch: 0111 training loss= 0.00073 time= 0.32886\n",
      "validation roc= 0.94027 validation ap= 0.94805\n",
      "Epoch: 0112 training loss= 0.00073 time= 0.34345\n",
      "validation roc= 0.94038 validation ap= 0.94825\n",
      "Epoch: 0113 training loss= 0.00073 time= 0.33768\n",
      "validation roc= 0.94046 validation ap= 0.94839\n",
      "Epoch: 0114 training loss= 0.00073 time= 0.35209\n",
      "validation roc= 0.94040 validation ap= 0.94857\n",
      "Epoch: 0115 training loss= 0.00073 time= 0.33675\n",
      "validation roc= 0.94015 validation ap= 0.94839\n",
      "Epoch: 0116 training loss= 0.00073 time= 0.37559\n",
      "validation roc= 0.94031 validation ap= 0.94866\n",
      "Epoch: 0117 training loss= 0.00073 time= 0.35064\n",
      "validation roc= 0.94025 validation ap= 0.94881\n",
      "Epoch: 0118 training loss= 0.00073 time= 0.33846\n",
      "validation roc= 0.94036 validation ap= 0.94911\n",
      "Epoch: 0119 training loss= 0.00072 time= 0.33616\n",
      "validation roc= 0.94046 validation ap= 0.94935\n",
      "Epoch: 0120 training loss= 0.00072 time= 0.44124\n",
      "validation roc= 0.94048 validation ap= 0.94951\n",
      "Epoch: 0121 training loss= 0.00072 time= 0.40748\n",
      "validation roc= 0.94065 validation ap= 0.94992\n",
      "Epoch: 0122 training loss= 0.00072 time= 0.57940\n",
      "validation roc= 0.94079 validation ap= 0.95000\n",
      "Epoch: 0123 training loss= 0.00072 time= 0.51268\n",
      "validation roc= 0.94077 validation ap= 0.95048\n",
      "Epoch: 0124 training loss= 0.00072 time= 0.48309\n",
      "validation roc= 0.94149 validation ap= 0.95065\n",
      "Epoch: 0125 training loss= 0.00072 time= 0.46300\n",
      "validation roc= 0.94052 validation ap= 0.95060\n",
      "Epoch: 0126 training loss= 0.00072 time= 0.46350\n",
      "validation roc= 0.94213 validation ap= 0.95126\n",
      "Epoch: 0127 training loss= 0.00072 time= 0.45147\n",
      "validation roc= 0.94124 validation ap= 0.95142\n",
      "Epoch: 0128 training loss= 0.00072 time= 0.45582\n",
      "validation roc= 0.94197 validation ap= 0.95201\n",
      "Epoch: 0129 training loss= 0.00072 time= 0.46334\n",
      "validation roc= 0.94254 validation ap= 0.95219\n",
      "Epoch: 0130 training loss= 0.00072 time= 0.47508\n",
      "validation roc= 0.94164 validation ap= 0.95179\n",
      "Epoch: 0131 training loss= 0.00072 time= 0.46201\n",
      "validation roc= 0.94275 validation ap= 0.95290\n",
      "Epoch: 0132 training loss= 0.00072 time= 0.46384\n",
      "validation roc= 0.94275 validation ap= 0.95276\n",
      "Epoch: 0133 training loss= 0.00072 time= 0.45584\n",
      "validation roc= 0.94219 validation ap= 0.95266\n",
      "Epoch: 0134 training loss= 0.00072 time= 0.45312\n",
      "validation roc= 0.94298 validation ap= 0.95315\n",
      "Epoch: 0135 training loss= 0.00072 time= 0.44617\n",
      "validation roc= 0.94285 validation ap= 0.95316\n",
      "Epoch: 0136 training loss= 0.00072 time= 0.47357\n",
      "validation roc= 0.94260 validation ap= 0.95327\n",
      "Epoch: 0137 training loss= 0.00072 time= 0.45481\n",
      "validation roc= 0.94318 validation ap= 0.95354\n",
      "Epoch: 0138 training loss= 0.00071 time= 0.46814\n",
      "validation roc= 0.94310 validation ap= 0.95363\n",
      "Epoch: 0139 training loss= 0.00071 time= 0.47549\n",
      "validation roc= 0.94285 validation ap= 0.95362\n",
      "Epoch: 0140 training loss= 0.00071 time= 0.46398\n",
      "validation roc= 0.94345 validation ap= 0.95403\n",
      "Epoch: 0141 training loss= 0.00071 time= 0.47537\n",
      "validation roc= 0.94327 validation ap= 0.95408\n",
      "Epoch: 0142 training loss= 0.00071 time= 0.46335\n",
      "validation roc= 0.94339 validation ap= 0.95407\n",
      "Epoch: 0143 training loss= 0.00071 time= 0.46241\n",
      "validation roc= 0.94372 validation ap= 0.95433\n",
      "Epoch: 0144 training loss= 0.00071 time= 0.48482\n",
      "validation roc= 0.94360 validation ap= 0.95437\n",
      "Epoch: 0145 training loss= 0.00071 time= 0.47499\n",
      "validation roc= 0.94386 validation ap= 0.95464\n",
      "Epoch: 0146 training loss= 0.00071 time= 0.45926\n",
      "validation roc= 0.94395 validation ap= 0.95474\n",
      "Epoch: 0147 training loss= 0.00071 time= 0.47820\n",
      "validation roc= 0.94424 validation ap= 0.95495\n",
      "Epoch: 0148 training loss= 0.00071 time= 0.46884\n",
      "validation roc= 0.94407 validation ap= 0.95485\n",
      "Epoch: 0149 training loss= 0.00071 time= 0.46002\n",
      "validation roc= 0.94423 validation ap= 0.95502\n",
      "Epoch: 0150 training loss= 0.00071 time= 0.45918\n",
      "validation roc= 0.94432 validation ap= 0.95503\n",
      "Epoch: 0151 training loss= 0.00071 time= 0.46227\n",
      "validation roc= 0.94442 validation ap= 0.95518\n",
      "Epoch: 0152 training loss= 0.00071 time= 0.45618\n",
      "validation roc= 0.94442 validation ap= 0.95517\n",
      "Epoch: 0153 training loss= 0.00071 time= 0.46202\n",
      "validation roc= 0.94428 validation ap= 0.95511\n",
      "Epoch: 0154 training loss= 0.00071 time= 0.46599\n",
      "validation roc= 0.94444 validation ap= 0.95515\n",
      "Epoch: 0155 training loss= 0.00071 time= 0.48632\n",
      "validation roc= 0.94405 validation ap= 0.95502\n",
      "Epoch: 0156 training loss= 0.00071 time= 0.46918\n",
      "validation roc= 0.94450 validation ap= 0.95525\n",
      "Epoch: 0157 training loss= 0.00071 time= 0.45772\n",
      "validation roc= 0.94409 validation ap= 0.95516\n",
      "Epoch: 0158 training loss= 0.00071 time= 0.44480\n",
      "validation roc= 0.94407 validation ap= 0.95477\n",
      "Epoch: 0159 training loss= 0.00071 time= 0.45173\n",
      "validation roc= 0.94405 validation ap= 0.95505\n",
      "Epoch: 0160 training loss= 0.00071 time= 0.46587\n",
      "validation roc= 0.94395 validation ap= 0.95454\n",
      "Epoch: 0161 training loss= 0.00071 time= 0.43246\n",
      "validation roc= 0.94403 validation ap= 0.95509\n",
      "Epoch: 0162 training loss= 0.00071 time= 0.43849\n",
      "validation roc= 0.94448 validation ap= 0.95540\n",
      "Epoch: 0163 training loss= 0.00070 time= 0.47385\n",
      "validation roc= 0.94413 validation ap= 0.95486\n",
      "Epoch: 0164 training loss= 0.00070 time= 0.46312\n",
      "validation roc= 0.94411 validation ap= 0.95526\n",
      "Epoch: 0165 training loss= 0.00070 time= 0.46366\n",
      "validation roc= 0.94421 validation ap= 0.95516\n",
      "Epoch: 0166 training loss= 0.00070 time= 0.47407\n",
      "validation roc= 0.94411 validation ap= 0.95497\n",
      "Epoch: 0167 training loss= 0.00070 time= 0.45398\n",
      "validation roc= 0.94430 validation ap= 0.95531\n",
      "Epoch: 0168 training loss= 0.00070 time= 0.46421\n",
      "validation roc= 0.94438 validation ap= 0.95533\n",
      "Epoch: 0169 training loss= 0.00070 time= 0.46479\n",
      "validation roc= 0.94444 validation ap= 0.95542\n",
      "Epoch: 0170 training loss= 0.00070 time= 0.45890\n",
      "validation roc= 0.94446 validation ap= 0.95549\n",
      "Epoch: 0171 training loss= 0.00070 time= 0.46245\n",
      "validation roc= 0.94421 validation ap= 0.95526\n",
      "Epoch: 0172 training loss= 0.00070 time= 0.46229\n",
      "validation roc= 0.94419 validation ap= 0.95535\n",
      "Epoch: 0173 training loss= 0.00070 time= 0.45195\n",
      "validation roc= 0.94456 validation ap= 0.95558\n",
      "Epoch: 0174 training loss= 0.00070 time= 0.45290\n",
      "validation roc= 0.94415 validation ap= 0.95530\n",
      "Epoch: 0175 training loss= 0.00070 time= 0.46823\n",
      "validation roc= 0.94415 validation ap= 0.95525\n",
      "Epoch: 0176 training loss= 0.00070 time= 0.49196\n",
      "validation roc= 0.94421 validation ap= 0.95535\n",
      "Epoch: 0177 training loss= 0.00070 time= 0.45272\n",
      "validation roc= 0.94395 validation ap= 0.95526\n",
      "Epoch: 0178 training loss= 0.00070 time= 0.42109\n",
      "validation roc= 0.94423 validation ap= 0.95539\n",
      "Epoch: 0179 training loss= 0.00070 time= 0.46035\n",
      "validation roc= 0.94403 validation ap= 0.95522\n",
      "Epoch: 0180 training loss= 0.00070 time= 0.47332\n",
      "validation roc= 0.94421 validation ap= 0.95534\n",
      "Epoch: 0181 training loss= 0.00070 time= 0.46803\n",
      "validation roc= 0.94411 validation ap= 0.95534\n",
      "Epoch: 0182 training loss= 0.00070 time= 0.47416\n",
      "validation roc= 0.94413 validation ap= 0.95533\n",
      "Epoch: 0183 training loss= 0.00070 time= 0.44885\n",
      "validation roc= 0.94395 validation ap= 0.95519\n",
      "Epoch: 0184 training loss= 0.00070 time= 0.45509\n",
      "validation roc= 0.94403 validation ap= 0.95521\n",
      "Epoch: 0185 training loss= 0.00070 time= 0.45870\n",
      "validation roc= 0.94419 validation ap= 0.95538\n",
      "Epoch: 0186 training loss= 0.00070 time= 0.47350\n",
      "validation roc= 0.94359 validation ap= 0.95492\n",
      "Epoch: 0187 training loss= 0.00070 time= 0.45622\n",
      "validation roc= 0.94419 validation ap= 0.95519\n",
      "Epoch: 0188 training loss= 0.00070 time= 0.47500\n",
      "validation roc= 0.94401 validation ap= 0.95530\n",
      "Epoch: 0189 training loss= 0.00070 time= 0.45699\n",
      "validation roc= 0.94384 validation ap= 0.95480\n",
      "Epoch: 0190 training loss= 0.00070 time= 0.43676\n",
      "validation roc= 0.94403 validation ap= 0.95542\n",
      "Epoch: 0191 training loss= 0.00070 time= 0.45760\n",
      "validation roc= 0.94411 validation ap= 0.95460\n",
      "Epoch: 0192 training loss= 0.00070 time= 0.45957\n",
      "validation roc= 0.94380 validation ap= 0.95539\n",
      "Epoch: 0193 training loss= 0.00070 time= 0.46791\n",
      "validation roc= 0.94374 validation ap= 0.95385\n",
      "Epoch: 0194 training loss= 0.00070 time= 0.46578\n",
      "validation roc= 0.94407 validation ap= 0.95552\n",
      "Epoch: 0195 training loss= 0.00070 time= 0.48591\n",
      "validation roc= 0.94362 validation ap= 0.95433\n",
      "Epoch: 0196 training loss= 0.00070 time= 0.46533\n",
      "validation roc= 0.94419 validation ap= 0.95475\n",
      "Epoch: 0197 training loss= 0.00069 time= 0.45467\n",
      "validation roc= 0.94452 validation ap= 0.95559\n",
      "Epoch: 0198 training loss= 0.00070 time= 0.45601\n",
      "validation roc= 0.94382 validation ap= 0.95436\n",
      "Epoch: 0199 training loss= 0.00070 time= 0.45186\n",
      "validation roc= 0.94430 validation ap= 0.95490\n",
      "Epoch: 0200 training loss= 0.00069 time= 0.45934\n",
      "validation roc= 0.94465 validation ap= 0.95545\n",
      "testing roc= 0.95319 testing ap= 0.95877\n",
      "Epoch: 0001 training loss= 0.00125 time= 2.19643\n",
      "validation roc= 0.62883 validation ap= 0.62714\n",
      "Epoch: 0002 training loss= 0.00124 time= 0.44414\n",
      "validation roc= 0.70415 validation ap= 0.71980\n",
      "Epoch: 0003 training loss= 0.00121 time= 0.41951\n",
      "validation roc= 0.63306 validation ap= 0.66116\n",
      "Epoch: 0004 training loss= 0.00119 time= 0.40693\n",
      "validation roc= 0.68070 validation ap= 0.70993\n",
      "Epoch: 0005 training loss= 0.00116 time= 0.41455\n",
      "validation roc= 0.75730 validation ap= 0.77027\n",
      "Epoch: 0006 training loss= 0.00110 time= 0.42271\n",
      "validation roc= 0.78488 validation ap= 0.79597\n",
      "Epoch: 0007 training loss= 0.00104 time= 0.41328\n",
      "validation roc= 0.78946 validation ap= 0.79859\n",
      "Epoch: 0008 training loss= 0.00100 time= 0.43222\n",
      "validation roc= 0.79534 validation ap= 0.80307\n",
      "Epoch: 0009 training loss= 0.00099 time= 0.48257\n",
      "validation roc= 0.79903 validation ap= 0.80502\n",
      "Epoch: 0010 training loss= 0.00098 time= 0.44577\n",
      "validation roc= 0.81067 validation ap= 0.81664\n",
      "Epoch: 0011 training loss= 0.00096 time= 0.45349\n",
      "validation roc= 0.82652 validation ap= 0.83252\n",
      "Epoch: 0012 training loss= 0.00093 time= 0.47395\n",
      "validation roc= 0.84137 validation ap= 0.84729\n",
      "Epoch: 0013 training loss= 0.00092 time= 0.47167\n",
      "validation roc= 0.84793 validation ap= 0.85276\n",
      "Epoch: 0014 training loss= 0.00092 time= 0.43890\n",
      "validation roc= 0.85078 validation ap= 0.85356\n",
      "Epoch: 0015 training loss= 0.00091 time= 0.47523\n",
      "validation roc= 0.85404 validation ap= 0.85462\n",
      "Epoch: 0016 training loss= 0.00091 time= 0.45083\n",
      "validation roc= 0.85905 validation ap= 0.85742\n",
      "Epoch: 0017 training loss= 0.00090 time= 0.46293\n",
      "validation roc= 0.86252 validation ap= 0.86093\n",
      "Epoch: 0018 training loss= 0.00090 time= 0.45312\n",
      "validation roc= 0.86518 validation ap= 0.86265\n",
      "Epoch: 0019 training loss= 0.00089 time= 0.44843\n",
      "validation roc= 0.86594 validation ap= 0.86032\n",
      "Epoch: 0020 training loss= 0.00088 time= 0.46348\n",
      "validation roc= 0.86670 validation ap= 0.85746\n",
      "Epoch: 0021 training loss= 0.00088 time= 0.44793\n",
      "validation roc= 0.86429 validation ap= 0.85144\n",
      "Epoch: 0022 training loss= 0.00088 time= 0.48260\n",
      "validation roc= 0.86313 validation ap= 0.84927\n",
      "Epoch: 0023 training loss= 0.00087 time= 0.46933\n",
      "validation roc= 0.86313 validation ap= 0.85154\n",
      "Epoch: 0024 training loss= 0.00087 time= 0.48331\n",
      "validation roc= 0.86332 validation ap= 0.85346\n",
      "Epoch: 0025 training loss= 0.00087 time= 0.43699\n",
      "validation roc= 0.86478 validation ap= 0.85777\n",
      "Epoch: 0026 training loss= 0.00086 time= 0.46302\n",
      "validation roc= 0.86660 validation ap= 0.86054\n",
      "Epoch: 0027 training loss= 0.00086 time= 0.46438\n",
      "validation roc= 0.86788 validation ap= 0.86330\n",
      "Epoch: 0028 training loss= 0.00086 time= 0.46617\n",
      "validation roc= 0.87079 validation ap= 0.86741\n",
      "Epoch: 0029 training loss= 0.00085 time= 0.46339\n",
      "validation roc= 0.87238 validation ap= 0.86827\n",
      "Epoch: 0030 training loss= 0.00085 time= 0.46123\n",
      "validation roc= 0.87492 validation ap= 0.87149\n",
      "Epoch: 0031 training loss= 0.00084 time= 0.47606\n",
      "validation roc= 0.87685 validation ap= 0.87298\n",
      "Epoch: 0032 training loss= 0.00084 time= 0.49221\n",
      "validation roc= 0.87917 validation ap= 0.87552\n",
      "Epoch: 0033 training loss= 0.00084 time= 0.44138\n",
      "validation roc= 0.88110 validation ap= 0.87717\n",
      "Epoch: 0034 training loss= 0.00084 time= 0.45988\n",
      "validation roc= 0.88261 validation ap= 0.87975\n",
      "Epoch: 0035 training loss= 0.00083 time= 0.46809\n",
      "validation roc= 0.88424 validation ap= 0.88162\n",
      "Epoch: 0036 training loss= 0.00083 time= 0.44922\n",
      "validation roc= 0.88601 validation ap= 0.88310\n",
      "Epoch: 0037 training loss= 0.00083 time= 0.46298\n",
      "validation roc= 0.88767 validation ap= 0.88526\n",
      "Epoch: 0038 training loss= 0.00082 time= 0.45445\n",
      "validation roc= 0.88921 validation ap= 0.88775\n",
      "Epoch: 0039 training loss= 0.00082 time= 0.46031\n",
      "validation roc= 0.89051 validation ap= 0.88923\n",
      "Epoch: 0040 training loss= 0.00082 time= 0.49246\n",
      "validation roc= 0.89192 validation ap= 0.89081\n",
      "Epoch: 0041 training loss= 0.00082 time= 0.43268\n",
      "validation roc= 0.89251 validation ap= 0.89212\n",
      "Epoch: 0042 training loss= 0.00082 time= 0.45466\n",
      "validation roc= 0.89348 validation ap= 0.89349\n",
      "Epoch: 0043 training loss= 0.00081 time= 0.45366\n",
      "validation roc= 0.89418 validation ap= 0.89472\n",
      "Epoch: 0044 training loss= 0.00081 time= 0.47283\n",
      "validation roc= 0.89513 validation ap= 0.89617\n",
      "Epoch: 0045 training loss= 0.00081 time= 0.46815\n",
      "validation roc= 0.89635 validation ap= 0.89761\n",
      "Epoch: 0046 training loss= 0.00081 time= 0.44664\n",
      "validation roc= 0.89693 validation ap= 0.89862\n",
      "Epoch: 0047 training loss= 0.00081 time= 0.46037\n",
      "validation roc= 0.89812 validation ap= 0.89970\n",
      "Epoch: 0048 training loss= 0.00080 time= 0.46675\n",
      "validation roc= 0.89876 validation ap= 0.90047\n",
      "Epoch: 0049 training loss= 0.00080 time= 0.42889\n",
      "validation roc= 0.89955 validation ap= 0.90148\n",
      "Epoch: 0050 training loss= 0.00080 time= 0.45387\n",
      "validation roc= 0.90031 validation ap= 0.90181\n",
      "Epoch: 0051 training loss= 0.00080 time= 0.48193\n",
      "validation roc= 0.90091 validation ap= 0.90205\n",
      "Epoch: 0052 training loss= 0.00080 time= 0.46414\n",
      "validation roc= 0.90143 validation ap= 0.90200\n",
      "Epoch: 0053 training loss= 0.00080 time= 0.46926\n",
      "validation roc= 0.90198 validation ap= 0.90199\n",
      "Epoch: 0054 training loss= 0.00079 time= 0.46882\n",
      "validation roc= 0.90252 validation ap= 0.90216\n",
      "Epoch: 0055 training loss= 0.00079 time= 0.46683\n",
      "validation roc= 0.90291 validation ap= 0.90214\n",
      "Epoch: 0056 training loss= 0.00079 time= 0.48795\n",
      "validation roc= 0.90363 validation ap= 0.90270\n",
      "Epoch: 0057 training loss= 0.00079 time= 0.47784\n",
      "validation roc= 0.90407 validation ap= 0.90303\n",
      "Epoch: 0058 training loss= 0.00079 time= 0.41104\n",
      "validation roc= 0.90450 validation ap= 0.90346\n",
      "Epoch: 0059 training loss= 0.00079 time= 0.44961\n",
      "validation roc= 0.90510 validation ap= 0.90392\n",
      "Epoch: 0060 training loss= 0.00079 time= 0.41725\n",
      "validation roc= 0.90537 validation ap= 0.90446\n",
      "Epoch: 0061 training loss= 0.00078 time= 0.44703\n",
      "validation roc= 0.90627 validation ap= 0.90543\n",
      "Epoch: 0062 training loss= 0.00078 time= 0.43033\n",
      "validation roc= 0.90695 validation ap= 0.90638\n",
      "Epoch: 0063 training loss= 0.00078 time= 0.43329\n",
      "validation roc= 0.90749 validation ap= 0.90748\n",
      "Epoch: 0064 training loss= 0.00078 time= 0.50972\n",
      "validation roc= 0.90776 validation ap= 0.90791\n",
      "Epoch: 0065 training loss= 0.00078 time= 0.41558\n",
      "validation roc= 0.90813 validation ap= 0.90827\n",
      "Epoch: 0066 training loss= 0.00078 time= 0.44678\n",
      "validation roc= 0.90935 validation ap= 0.90980\n",
      "Epoch: 0067 training loss= 0.00078 time= 0.41744\n",
      "validation roc= 0.91028 validation ap= 0.91137\n",
      "Epoch: 0068 training loss= 0.00077 time= 0.43500\n",
      "validation roc= 0.91106 validation ap= 0.91252\n",
      "Epoch: 0069 training loss= 0.00077 time= 0.41412\n",
      "validation roc= 0.91122 validation ap= 0.91293\n",
      "Epoch: 0070 training loss= 0.00077 time= 0.42472\n",
      "validation roc= 0.91174 validation ap= 0.91366\n",
      "Epoch: 0071 training loss= 0.00077 time= 0.45242\n",
      "validation roc= 0.91193 validation ap= 0.91410\n",
      "Epoch: 0072 training loss= 0.00077 time= 0.43617\n",
      "validation roc= 0.91252 validation ap= 0.91465\n",
      "Epoch: 0073 training loss= 0.00077 time= 0.44843\n",
      "validation roc= 0.91316 validation ap= 0.91542\n",
      "Epoch: 0074 training loss= 0.00077 time= 0.43519\n",
      "validation roc= 0.91352 validation ap= 0.91627\n",
      "Epoch: 0075 training loss= 0.00077 time= 0.38990\n",
      "validation roc= 0.91411 validation ap= 0.91684\n",
      "Epoch: 0076 training loss= 0.00077 time= 0.46726\n",
      "validation roc= 0.91510 validation ap= 0.91808\n",
      "Epoch: 0077 training loss= 0.00076 time= 0.43570\n",
      "validation roc= 0.91514 validation ap= 0.91818\n",
      "Epoch: 0078 training loss= 0.00076 time= 0.47789\n",
      "validation roc= 0.91611 validation ap= 0.91917\n",
      "Epoch: 0079 training loss= 0.00076 time= 0.43127\n",
      "validation roc= 0.91684 validation ap= 0.91993\n",
      "Epoch: 0080 training loss= 0.00076 time= 0.47083\n",
      "validation roc= 0.91731 validation ap= 0.92065\n",
      "Epoch: 0081 training loss= 0.00076 time= 0.46228\n",
      "validation roc= 0.91781 validation ap= 0.92142\n",
      "Epoch: 0082 training loss= 0.00076 time= 0.45857\n",
      "validation roc= 0.91851 validation ap= 0.92228\n",
      "Epoch: 0083 training loss= 0.00076 time= 0.48977\n",
      "validation roc= 0.91896 validation ap= 0.92313\n",
      "Epoch: 0084 training loss= 0.00076 time= 0.47699\n",
      "validation roc= 0.91931 validation ap= 0.92369\n",
      "Epoch: 0085 training loss= 0.00076 time= 0.41608\n",
      "validation roc= 0.91966 validation ap= 0.92405\n",
      "Epoch: 0086 training loss= 0.00075 time= 0.46456\n",
      "validation roc= 0.92003 validation ap= 0.92453\n",
      "Epoch: 0087 training loss= 0.00075 time= 0.44734\n",
      "validation roc= 0.92006 validation ap= 0.92497\n",
      "Epoch: 0088 training loss= 0.00075 time= 0.48228\n",
      "validation roc= 0.92014 validation ap= 0.92515\n",
      "Epoch: 0089 training loss= 0.00075 time= 0.45918\n",
      "validation roc= 0.92086 validation ap= 0.92563\n",
      "Epoch: 0090 training loss= 0.00075 time= 0.46705\n",
      "validation roc= 0.92107 validation ap= 0.92572\n",
      "Epoch: 0091 training loss= 0.00075 time= 0.45861\n",
      "validation roc= 0.92123 validation ap= 0.92589\n",
      "Epoch: 0092 training loss= 0.00075 time= 0.45205\n",
      "validation roc= 0.92183 validation ap= 0.92636\n",
      "Epoch: 0093 training loss= 0.00075 time= 0.45947\n",
      "validation roc= 0.92253 validation ap= 0.92693\n",
      "Epoch: 0094 training loss= 0.00075 time= 0.45759\n",
      "validation roc= 0.92278 validation ap= 0.92720\n",
      "Epoch: 0095 training loss= 0.00075 time= 0.47021\n",
      "validation roc= 0.92313 validation ap= 0.92758\n",
      "Epoch: 0096 training loss= 0.00075 time= 0.43754\n",
      "validation roc= 0.92342 validation ap= 0.92784\n",
      "Epoch: 0097 training loss= 0.00074 time= 0.45818\n",
      "validation roc= 0.92375 validation ap= 0.92834\n",
      "Epoch: 0098 training loss= 0.00074 time= 0.37299\n",
      "validation roc= 0.92447 validation ap= 0.92909\n",
      "Epoch: 0099 training loss= 0.00074 time= 0.37551\n",
      "validation roc= 0.92519 validation ap= 0.92978\n",
      "Epoch: 0100 training loss= 0.00074 time= 0.36941\n",
      "validation roc= 0.92577 validation ap= 0.93066\n",
      "Epoch: 0101 training loss= 0.00074 time= 0.38568\n",
      "validation roc= 0.92641 validation ap= 0.93171\n",
      "Epoch: 0102 training loss= 0.00074 time= 0.36935\n",
      "validation roc= 0.92701 validation ap= 0.93257\n",
      "Epoch: 0103 training loss= 0.00074 time= 0.36457\n",
      "validation roc= 0.92773 validation ap= 0.93359\n",
      "Epoch: 0104 training loss= 0.00074 time= 0.36943\n",
      "validation roc= 0.92827 validation ap= 0.93452\n",
      "Epoch: 0105 training loss= 0.00074 time= 0.43892\n",
      "validation roc= 0.92870 validation ap= 0.93528\n",
      "Epoch: 0106 training loss= 0.00074 time= 0.38262\n",
      "validation roc= 0.92922 validation ap= 0.93596\n",
      "Epoch: 0107 training loss= 0.00074 time= 0.38299\n",
      "validation roc= 0.92971 validation ap= 0.93683\n",
      "Epoch: 0108 training loss= 0.00074 time= 0.36779\n",
      "validation roc= 0.93002 validation ap= 0.93720\n",
      "Epoch: 0109 training loss= 0.00074 time= 0.36486\n",
      "validation roc= 0.93043 validation ap= 0.93789\n",
      "Epoch: 0110 training loss= 0.00073 time= 0.38444\n",
      "validation roc= 0.93080 validation ap= 0.93849\n",
      "Epoch: 0111 training loss= 0.00073 time= 0.37394\n",
      "validation roc= 0.93095 validation ap= 0.93867\n",
      "Epoch: 0112 training loss= 0.00073 time= 0.39833\n",
      "validation roc= 0.93105 validation ap= 0.93901\n",
      "Epoch: 0113 training loss= 0.00073 time= 0.37726\n",
      "validation roc= 0.93116 validation ap= 0.93899\n",
      "Epoch: 0114 training loss= 0.00073 time= 0.36961\n",
      "validation roc= 0.93111 validation ap= 0.93902\n",
      "Epoch: 0115 training loss= 0.00073 time= 0.36272\n",
      "validation roc= 0.93132 validation ap= 0.93916\n",
      "Epoch: 0116 training loss= 0.00073 time= 0.43796\n",
      "validation roc= 0.93177 validation ap= 0.93976\n",
      "Epoch: 0117 training loss= 0.00073 time= 0.42637\n",
      "validation roc= 0.93159 validation ap= 0.93959\n",
      "Epoch: 0118 training loss= 0.00073 time= 0.41634\n",
      "validation roc= 0.93167 validation ap= 0.93970\n",
      "Epoch: 0119 training loss= 0.00073 time= 0.43306\n",
      "validation roc= 0.93128 validation ap= 0.93955\n",
      "Epoch: 0120 training loss= 0.00073 time= 0.42371\n",
      "validation roc= 0.93136 validation ap= 0.93955\n",
      "Epoch: 0121 training loss= 0.00073 time= 0.43268\n",
      "validation roc= 0.93115 validation ap= 0.93930\n",
      "Epoch: 0122 training loss= 0.00073 time= 0.45832\n",
      "validation roc= 0.93085 validation ap= 0.93903\n",
      "Epoch: 0123 training loss= 0.00073 time= 0.44365\n",
      "validation roc= 0.93115 validation ap= 0.93964\n",
      "Epoch: 0124 training loss= 0.00073 time= 0.43616\n",
      "validation roc= 0.93109 validation ap= 0.93949\n",
      "Epoch: 0125 training loss= 0.00073 time= 0.42684\n",
      "validation roc= 0.93037 validation ap= 0.93876\n",
      "Epoch: 0126 training loss= 0.00073 time= 0.40389\n",
      "validation roc= 0.93031 validation ap= 0.93886\n",
      "Epoch: 0127 training loss= 0.00072 time= 0.47170\n",
      "validation roc= 0.93062 validation ap= 0.93917\n",
      "Epoch: 0128 training loss= 0.00072 time= 0.45962\n",
      "validation roc= 0.93010 validation ap= 0.93872\n",
      "Epoch: 0129 training loss= 0.00072 time= 0.43548\n",
      "validation roc= 0.93043 validation ap= 0.93890\n",
      "Epoch: 0130 training loss= 0.00072 time= 0.44738\n",
      "validation roc= 0.93018 validation ap= 0.93882\n",
      "Epoch: 0131 training loss= 0.00072 time= 0.45692\n",
      "validation roc= 0.92992 validation ap= 0.93871\n",
      "Epoch: 0132 training loss= 0.00072 time= 0.44006\n",
      "validation roc= 0.92996 validation ap= 0.93844\n",
      "Epoch: 0133 training loss= 0.00072 time= 0.49094\n",
      "validation roc= 0.92963 validation ap= 0.93844\n",
      "Epoch: 0134 training loss= 0.00072 time= 0.48417\n",
      "validation roc= 0.92952 validation ap= 0.93823\n",
      "Epoch: 0135 training loss= 0.00072 time= 0.45669\n",
      "validation roc= 0.92920 validation ap= 0.93786\n",
      "Epoch: 0136 training loss= 0.00072 time= 0.42509\n",
      "validation roc= 0.92870 validation ap= 0.93758\n",
      "Epoch: 0137 training loss= 0.00072 time= 0.47566\n",
      "validation roc= 0.92858 validation ap= 0.93731\n",
      "Epoch: 0138 training loss= 0.00072 time= 0.45487\n",
      "validation roc= 0.92876 validation ap= 0.93764\n",
      "Epoch: 0139 training loss= 0.00072 time= 0.44489\n",
      "validation roc= 0.92790 validation ap= 0.93694\n",
      "Epoch: 0140 training loss= 0.00072 time= 0.47717\n",
      "validation roc= 0.92818 validation ap= 0.93720\n",
      "Epoch: 0141 training loss= 0.00072 time= 0.45443\n",
      "validation roc= 0.92823 validation ap= 0.93750\n",
      "Epoch: 0142 training loss= 0.00072 time= 0.45503\n",
      "validation roc= 0.92767 validation ap= 0.93696\n",
      "Epoch: 0143 training loss= 0.00072 time= 0.45521\n",
      "validation roc= 0.92769 validation ap= 0.93695\n",
      "Epoch: 0144 training loss= 0.00071 time= 0.45293\n",
      "validation roc= 0.92783 validation ap= 0.93724\n",
      "Epoch: 0145 training loss= 0.00071 time= 0.44968\n",
      "validation roc= 0.92726 validation ap= 0.93671\n",
      "Epoch: 0146 training loss= 0.00071 time= 0.47469\n",
      "validation roc= 0.92728 validation ap= 0.93692\n",
      "Epoch: 0147 training loss= 0.00071 time= 0.41902\n",
      "validation roc= 0.92717 validation ap= 0.93699\n",
      "Epoch: 0148 training loss= 0.00071 time= 0.43599\n",
      "validation roc= 0.92682 validation ap= 0.93666\n",
      "Epoch: 0149 training loss= 0.00071 time= 0.46836\n",
      "validation roc= 0.92668 validation ap= 0.93682\n",
      "Epoch: 0150 training loss= 0.00071 time= 0.46026\n",
      "validation roc= 0.92645 validation ap= 0.93657\n",
      "Epoch: 0151 training loss= 0.00071 time= 0.46008\n",
      "validation roc= 0.92641 validation ap= 0.93661\n",
      "Epoch: 0152 training loss= 0.00071 time= 0.46840\n",
      "validation roc= 0.92635 validation ap= 0.93663\n",
      "Epoch: 0153 training loss= 0.00071 time= 0.47762\n",
      "validation roc= 0.92593 validation ap= 0.93629\n",
      "Epoch: 0154 training loss= 0.00071 time= 0.43779\n",
      "validation roc= 0.92631 validation ap= 0.93692\n",
      "Epoch: 0155 training loss= 0.00071 time= 0.45137\n",
      "validation roc= 0.92589 validation ap= 0.93632\n",
      "Epoch: 0156 training loss= 0.00071 time= 0.47643\n",
      "validation roc= 0.92561 validation ap= 0.93651\n",
      "Epoch: 0157 training loss= 0.00071 time= 0.48507\n",
      "validation roc= 0.92579 validation ap= 0.93625\n",
      "Epoch: 0158 training loss= 0.00071 time= 0.44410\n",
      "validation roc= 0.92525 validation ap= 0.93647\n",
      "Epoch: 0159 training loss= 0.00071 time= 0.45490\n",
      "validation roc= 0.92462 validation ap= 0.93537\n",
      "Epoch: 0160 training loss= 0.00071 time= 0.47519\n",
      "validation roc= 0.92523 validation ap= 0.93635\n",
      "Epoch: 0161 training loss= 0.00071 time= 0.50539\n",
      "validation roc= 0.92449 validation ap= 0.93566\n",
      "Epoch: 0162 training loss= 0.00071 time= 0.42641\n",
      "validation roc= 0.92523 validation ap= 0.93638\n",
      "Epoch: 0163 training loss= 0.00071 time= 0.46029\n",
      "validation roc= 0.92505 validation ap= 0.93641\n",
      "Epoch: 0164 training loss= 0.00071 time= 0.43042\n",
      "validation roc= 0.92455 validation ap= 0.93575\n",
      "Epoch: 0165 training loss= 0.00071 time= 0.41295\n",
      "validation roc= 0.92546 validation ap= 0.93717\n",
      "Epoch: 0166 training loss= 0.00071 time= 0.41128\n",
      "validation roc= 0.92484 validation ap= 0.93611\n",
      "Epoch: 0167 training loss= 0.00071 time= 0.43974\n",
      "validation roc= 0.92468 validation ap= 0.93595\n",
      "Epoch: 0168 training loss= 0.00071 time= 0.41550\n",
      "validation roc= 0.92542 validation ap= 0.93719\n",
      "Epoch: 0169 training loss= 0.00071 time= 0.41315\n",
      "validation roc= 0.92482 validation ap= 0.93599\n",
      "Epoch: 0170 training loss= 0.00071 time= 0.41792\n",
      "validation roc= 0.92472 validation ap= 0.93601\n",
      "Epoch: 0171 training loss= 0.00070 time= 0.44186\n",
      "validation roc= 0.92472 validation ap= 0.93666\n",
      "Epoch: 0172 training loss= 0.00070 time= 0.45548\n",
      "validation roc= 0.92433 validation ap= 0.93576\n",
      "Epoch: 0173 training loss= 0.00070 time= 0.46483\n",
      "validation roc= 0.92480 validation ap= 0.93642\n",
      "Epoch: 0174 training loss= 0.00070 time= 0.42894\n",
      "validation roc= 0.92412 validation ap= 0.93608\n",
      "Epoch: 0175 training loss= 0.00070 time= 0.43133\n",
      "validation roc= 0.92375 validation ap= 0.93532\n",
      "Epoch: 0176 training loss= 0.00070 time= 0.46667\n",
      "validation roc= 0.92439 validation ap= 0.93630\n",
      "Epoch: 0177 training loss= 0.00070 time= 0.42056\n",
      "validation roc= 0.92369 validation ap= 0.93577\n",
      "Epoch: 0178 training loss= 0.00070 time= 0.44013\n",
      "validation roc= 0.92381 validation ap= 0.93540\n",
      "Epoch: 0179 training loss= 0.00070 time= 0.46795\n",
      "validation roc= 0.92377 validation ap= 0.93594\n",
      "Epoch: 0180 training loss= 0.00070 time= 0.45114\n",
      "validation roc= 0.92371 validation ap= 0.93561\n",
      "Epoch: 0181 training loss= 0.00070 time= 0.42597\n",
      "validation roc= 0.92332 validation ap= 0.93526\n",
      "Epoch: 0182 training loss= 0.00070 time= 0.45606\n",
      "validation roc= 0.92402 validation ap= 0.93593\n",
      "Epoch: 0183 training loss= 0.00070 time= 0.46829\n",
      "validation roc= 0.92237 validation ap= 0.93447\n",
      "Epoch: 0184 training loss= 0.00070 time= 0.47395\n",
      "validation roc= 0.92447 validation ap= 0.93599\n",
      "Epoch: 0185 training loss= 0.00070 time= 0.46757\n",
      "validation roc= 0.92189 validation ap= 0.93449\n",
      "Epoch: 0186 training loss= 0.00070 time= 0.44730\n",
      "validation roc= 0.92443 validation ap= 0.93563\n",
      "Epoch: 0187 training loss= 0.00070 time= 0.47317\n",
      "validation roc= 0.92181 validation ap= 0.93415\n",
      "Epoch: 0188 training loss= 0.00070 time= 0.46476\n",
      "validation roc= 0.92367 validation ap= 0.93547\n",
      "Epoch: 0189 training loss= 0.00070 time= 0.46328\n",
      "validation roc= 0.92364 validation ap= 0.93513\n",
      "Epoch: 0190 training loss= 0.00070 time= 0.47273\n",
      "validation roc= 0.92197 validation ap= 0.93429\n",
      "Epoch: 0191 training loss= 0.00070 time= 0.40478\n",
      "validation roc= 0.92408 validation ap= 0.93551\n",
      "Epoch: 0192 training loss= 0.00070 time= 0.42191\n",
      "validation roc= 0.92239 validation ap= 0.93400\n",
      "Epoch: 0193 training loss= 0.00070 time= 0.45395\n",
      "validation roc= 0.92266 validation ap= 0.93450\n",
      "Epoch: 0194 training loss= 0.00070 time= 0.46258\n",
      "validation roc= 0.92375 validation ap= 0.93536\n",
      "Epoch: 0195 training loss= 0.00070 time= 0.45096\n",
      "validation roc= 0.92199 validation ap= 0.93381\n",
      "Epoch: 0196 training loss= 0.00070 time= 0.48874\n",
      "validation roc= 0.92284 validation ap= 0.93460\n",
      "Epoch: 0197 training loss= 0.00070 time= 0.43533\n",
      "validation roc= 0.92298 validation ap= 0.93466\n",
      "Epoch: 0198 training loss= 0.00070 time= 0.48036\n",
      "validation roc= 0.92202 validation ap= 0.93402\n",
      "Epoch: 0199 training loss= 0.00070 time= 0.46626\n",
      "validation roc= 0.92284 validation ap= 0.93466\n",
      "Epoch: 0200 training loss= 0.00070 time= 0.44313\n",
      "validation roc= 0.92230 validation ap= 0.93425\n",
      "testing roc= 0.95758 testing ap= 0.95425\n",
      "Epoch: 0001 training loss= 0.00124 time= 2.37960\n",
      "validation roc= 0.67521 validation ap= 0.68349\n",
      "Epoch: 0002 training loss= 0.00124 time= 0.43076\n",
      "validation roc= 0.78463 validation ap= 0.78186\n",
      "Epoch: 0003 training loss= 0.00121 time= 0.46301\n",
      "validation roc= 0.69272 validation ap= 0.71872\n",
      "Epoch: 0004 training loss= 0.00119 time= 0.42123\n",
      "validation roc= 0.76089 validation ap= 0.78366\n",
      "Epoch: 0005 training loss= 0.00116 time= 0.45157\n",
      "validation roc= 0.85554 validation ap= 0.86089\n",
      "Epoch: 0006 training loss= 0.00109 time= 0.43484\n",
      "validation roc= 0.87638 validation ap= 0.87878\n",
      "Epoch: 0007 training loss= 0.00104 time= 0.45154\n",
      "validation roc= 0.88065 validation ap= 0.88053\n",
      "Epoch: 0008 training loss= 0.00100 time= 0.44786\n",
      "validation roc= 0.88473 validation ap= 0.88360\n",
      "Epoch: 0009 training loss= 0.00099 time= 0.43928\n",
      "validation roc= 0.88630 validation ap= 0.88496\n",
      "Epoch: 0010 training loss= 0.00098 time= 0.47238\n",
      "validation roc= 0.89348 validation ap= 0.89202\n",
      "Epoch: 0011 training loss= 0.00096 time= 0.45053\n",
      "validation roc= 0.90266 validation ap= 0.90165\n",
      "Epoch: 0012 training loss= 0.00093 time= 0.42869\n",
      "validation roc= 0.90924 validation ap= 0.90977\n",
      "Epoch: 0013 training loss= 0.00092 time= 0.44685\n",
      "validation roc= 0.91021 validation ap= 0.91307\n",
      "Epoch: 0014 training loss= 0.00092 time= 0.44131\n",
      "validation roc= 0.90751 validation ap= 0.91201\n",
      "Epoch: 0015 training loss= 0.00091 time= 0.48641\n",
      "validation roc= 0.90615 validation ap= 0.91136\n",
      "Epoch: 0016 training loss= 0.00091 time= 0.41990\n",
      "validation roc= 0.90941 validation ap= 0.91485\n",
      "Epoch: 0017 training loss= 0.00091 time= 0.43494\n",
      "validation roc= 0.91430 validation ap= 0.91977\n",
      "Epoch: 0018 training loss= 0.00090 time= 0.43363\n",
      "validation roc= 0.91812 validation ap= 0.92266\n",
      "Epoch: 0019 training loss= 0.00089 time= 0.42967\n",
      "validation roc= 0.92177 validation ap= 0.92464\n",
      "Epoch: 0020 training loss= 0.00088 time= 0.42131\n",
      "validation roc= 0.92513 validation ap= 0.92550\n",
      "Epoch: 0021 training loss= 0.00088 time= 0.39816\n",
      "validation roc= 0.92690 validation ap= 0.92523\n",
      "Epoch: 0022 training loss= 0.00088 time= 0.43506\n",
      "validation roc= 0.92724 validation ap= 0.92498\n",
      "Epoch: 0023 training loss= 0.00087 time= 0.44520\n",
      "validation roc= 0.92818 validation ap= 0.92650\n",
      "Epoch: 0024 training loss= 0.00087 time= 0.41343\n",
      "validation roc= 0.92878 validation ap= 0.92701\n",
      "Epoch: 0025 training loss= 0.00087 time= 0.42578\n",
      "validation roc= 0.92990 validation ap= 0.92799\n",
      "Epoch: 0026 training loss= 0.00086 time= 0.44155\n",
      "validation roc= 0.93188 validation ap= 0.93017\n",
      "Epoch: 0027 training loss= 0.00086 time= 0.41669\n",
      "validation roc= 0.93361 validation ap= 0.93211\n",
      "Epoch: 0028 training loss= 0.00085 time= 0.40330\n",
      "validation roc= 0.93479 validation ap= 0.93352\n",
      "Epoch: 0029 training loss= 0.00085 time= 0.43992\n",
      "validation roc= 0.93751 validation ap= 0.93719\n",
      "Epoch: 0030 training loss= 0.00085 time= 0.44292\n",
      "validation roc= 0.93943 validation ap= 0.93960\n",
      "Epoch: 0031 training loss= 0.00084 time= 0.47069\n",
      "validation roc= 0.94073 validation ap= 0.94143\n",
      "Epoch: 0032 training loss= 0.00084 time= 0.45270\n",
      "validation roc= 0.94196 validation ap= 0.94282\n",
      "Epoch: 0033 training loss= 0.00084 time= 0.45683\n",
      "validation roc= 0.94411 validation ap= 0.94533\n",
      "Epoch: 0034 training loss= 0.00083 time= 0.44063\n",
      "validation roc= 0.94496 validation ap= 0.94658\n",
      "Epoch: 0035 training loss= 0.00083 time= 0.44426\n",
      "validation roc= 0.94595 validation ap= 0.94768\n",
      "Epoch: 0036 training loss= 0.00083 time= 0.42883\n",
      "validation roc= 0.94655 validation ap= 0.94832\n",
      "Epoch: 0037 training loss= 0.00083 time= 0.42252\n",
      "validation roc= 0.94795 validation ap= 0.94959\n",
      "Epoch: 0038 training loss= 0.00082 time= 0.40335\n",
      "validation roc= 0.94896 validation ap= 0.95032\n",
      "Epoch: 0039 training loss= 0.00082 time= 0.45305\n",
      "validation roc= 0.94937 validation ap= 0.95072\n",
      "Epoch: 0040 training loss= 0.00082 time= 0.42370\n",
      "validation roc= 0.94985 validation ap= 0.95144\n",
      "Epoch: 0041 training loss= 0.00082 time= 0.45356\n",
      "validation roc= 0.95040 validation ap= 0.95181\n",
      "Epoch: 0042 training loss= 0.00081 time= 0.46169\n",
      "validation roc= 0.95077 validation ap= 0.95234\n",
      "Epoch: 0043 training loss= 0.00081 time= 0.43947\n",
      "validation roc= 0.95125 validation ap= 0.95269\n",
      "Epoch: 0044 training loss= 0.00081 time= 0.46599\n",
      "validation roc= 0.95203 validation ap= 0.95340\n",
      "Epoch: 0045 training loss= 0.00081 time= 0.45573\n",
      "validation roc= 0.95236 validation ap= 0.95350\n",
      "Epoch: 0046 training loss= 0.00081 time= 0.46179\n",
      "validation roc= 0.95243 validation ap= 0.95363\n",
      "Epoch: 0047 training loss= 0.00080 time= 0.43158\n",
      "validation roc= 0.95259 validation ap= 0.95371\n",
      "Epoch: 0048 training loss= 0.00080 time= 0.45664\n",
      "validation roc= 0.95212 validation ap= 0.95337\n",
      "Epoch: 0049 training loss= 0.00080 time= 0.44737\n",
      "validation roc= 0.95209 validation ap= 0.95314\n",
      "Epoch: 0050 training loss= 0.00080 time= 0.48190\n",
      "validation roc= 0.95253 validation ap= 0.95378\n",
      "Epoch: 0051 training loss= 0.00080 time= 0.49382\n",
      "validation roc= 0.95251 validation ap= 0.95393\n",
      "Epoch: 0052 training loss= 0.00080 time= 0.45398\n",
      "validation roc= 0.95284 validation ap= 0.95443\n",
      "Epoch: 0053 training loss= 0.00079 time= 0.46420\n",
      "validation roc= 0.95286 validation ap= 0.95492\n",
      "Epoch: 0054 training loss= 0.00079 time= 0.46660\n",
      "validation roc= 0.95300 validation ap= 0.95568\n",
      "Epoch: 0055 training loss= 0.00079 time= 0.46080\n",
      "validation roc= 0.95304 validation ap= 0.95624\n",
      "Epoch: 0056 training loss= 0.00079 time= 0.43994\n",
      "validation roc= 0.95340 validation ap= 0.95692\n",
      "Epoch: 0057 training loss= 0.00079 time= 0.47042\n",
      "validation roc= 0.95360 validation ap= 0.95743\n",
      "Epoch: 0058 training loss= 0.00079 time= 0.40003\n",
      "validation roc= 0.95372 validation ap= 0.95755\n",
      "Epoch: 0059 training loss= 0.00079 time= 0.46001\n",
      "validation roc= 0.95408 validation ap= 0.95813\n",
      "Epoch: 0060 training loss= 0.00078 time= 0.44235\n",
      "validation roc= 0.95443 validation ap= 0.95855\n",
      "Epoch: 0061 training loss= 0.00078 time= 0.43008\n",
      "validation roc= 0.95482 validation ap= 0.95920\n",
      "Epoch: 0062 training loss= 0.00078 time= 0.42959\n",
      "validation roc= 0.95538 validation ap= 0.95990\n",
      "Epoch: 0063 training loss= 0.00078 time= 0.42524\n",
      "validation roc= 0.95591 validation ap= 0.96046\n",
      "Epoch: 0064 training loss= 0.00078 time= 0.45268\n",
      "validation roc= 0.95661 validation ap= 0.96113\n",
      "Epoch: 0065 training loss= 0.00078 time= 0.45322\n",
      "validation roc= 0.95694 validation ap= 0.96148\n",
      "Epoch: 0066 training loss= 0.00078 time= 0.46762\n",
      "validation roc= 0.95711 validation ap= 0.96169\n",
      "Epoch: 0067 training loss= 0.00078 time= 0.44516\n",
      "validation roc= 0.95777 validation ap= 0.96237\n",
      "Epoch: 0068 training loss= 0.00077 time= 0.45143\n",
      "validation roc= 0.95831 validation ap= 0.96295\n",
      "Epoch: 0069 training loss= 0.00077 time= 0.48806\n",
      "validation roc= 0.95859 validation ap= 0.96328\n",
      "Epoch: 0070 training loss= 0.00077 time= 0.42872\n",
      "validation roc= 0.95905 validation ap= 0.96378\n",
      "Epoch: 0071 training loss= 0.00077 time= 0.43361\n",
      "validation roc= 0.95944 validation ap= 0.96414\n",
      "Epoch: 0072 training loss= 0.00077 time= 0.43262\n",
      "validation roc= 0.95998 validation ap= 0.96474\n",
      "Epoch: 0073 training loss= 0.00077 time= 0.43150\n",
      "validation roc= 0.96024 validation ap= 0.96498\n",
      "Epoch: 0074 training loss= 0.00077 time= 0.42432\n",
      "validation roc= 0.96086 validation ap= 0.96563\n",
      "Epoch: 0075 training loss= 0.00077 time= 0.46006\n",
      "validation roc= 0.96119 validation ap= 0.96600\n",
      "Epoch: 0076 training loss= 0.00076 time= 0.47159\n",
      "validation roc= 0.96134 validation ap= 0.96618\n",
      "Epoch: 0077 training loss= 0.00076 time= 0.44830\n",
      "validation roc= 0.96210 validation ap= 0.96697\n",
      "Epoch: 0078 training loss= 0.00076 time= 0.44267\n",
      "validation roc= 0.96233 validation ap= 0.96719\n",
      "Epoch: 0079 training loss= 0.00076 time= 0.43398\n",
      "validation roc= 0.96247 validation ap= 0.96729\n",
      "Epoch: 0080 training loss= 0.00076 time= 0.44936\n",
      "validation roc= 0.96264 validation ap= 0.96745\n",
      "Epoch: 0081 training loss= 0.00076 time= 0.44978\n",
      "validation roc= 0.96284 validation ap= 0.96761\n",
      "Epoch: 0082 training loss= 0.00076 time= 0.45943\n",
      "validation roc= 0.96270 validation ap= 0.96751\n",
      "Epoch: 0083 training loss= 0.00076 time= 0.46839\n",
      "validation roc= 0.96270 validation ap= 0.96745\n",
      "Epoch: 0084 training loss= 0.00076 time= 0.42980\n",
      "validation roc= 0.96247 validation ap= 0.96711\n",
      "Epoch: 0085 training loss= 0.00075 time= 0.47088\n",
      "validation roc= 0.96249 validation ap= 0.96696\n",
      "Epoch: 0086 training loss= 0.00075 time= 0.45105\n",
      "validation roc= 0.96282 validation ap= 0.96717\n",
      "Epoch: 0087 training loss= 0.00075 time= 0.43345\n",
      "validation roc= 0.96260 validation ap= 0.96689\n",
      "Epoch: 0088 training loss= 0.00075 time= 0.43815\n",
      "validation roc= 0.96237 validation ap= 0.96659\n",
      "Epoch: 0089 training loss= 0.00075 time= 0.45088\n",
      "validation roc= 0.96223 validation ap= 0.96632\n",
      "Epoch: 0090 training loss= 0.00075 time= 0.37281\n",
      "validation roc= 0.96208 validation ap= 0.96611\n",
      "Epoch: 0091 training loss= 0.00075 time= 0.36904\n",
      "validation roc= 0.96212 validation ap= 0.96618\n",
      "Epoch: 0092 training loss= 0.00075 time= 0.37488\n",
      "validation roc= 0.96210 validation ap= 0.96623\n",
      "Epoch: 0093 training loss= 0.00075 time= 0.37360\n",
      "validation roc= 0.96216 validation ap= 0.96617\n",
      "Epoch: 0094 training loss= 0.00075 time= 0.36988\n",
      "validation roc= 0.96229 validation ap= 0.96638\n",
      "Epoch: 0095 training loss= 0.00075 time= 0.37100\n",
      "validation roc= 0.96222 validation ap= 0.96632\n",
      "Epoch: 0096 training loss= 0.00074 time= 0.37228\n",
      "validation roc= 0.96212 validation ap= 0.96637\n",
      "Epoch: 0097 training loss= 0.00074 time= 0.36659\n",
      "validation roc= 0.96223 validation ap= 0.96651\n",
      "Epoch: 0098 training loss= 0.00074 time= 0.38138\n",
      "validation roc= 0.96206 validation ap= 0.96653\n",
      "Epoch: 0099 training loss= 0.00074 time= 0.36592\n",
      "validation roc= 0.96204 validation ap= 0.96665\n",
      "Epoch: 0100 training loss= 0.00074 time= 0.37193\n",
      "validation roc= 0.96194 validation ap= 0.96660\n",
      "Epoch: 0101 training loss= 0.00074 time= 0.36834\n",
      "validation roc= 0.96192 validation ap= 0.96664\n",
      "Epoch: 0102 training loss= 0.00074 time= 0.37053\n",
      "validation roc= 0.96187 validation ap= 0.96665\n",
      "Epoch: 0103 training loss= 0.00074 time= 0.37125\n",
      "validation roc= 0.96173 validation ap= 0.96655\n",
      "Epoch: 0104 training loss= 0.00074 time= 0.36169\n",
      "validation roc= 0.96161 validation ap= 0.96647\n",
      "Epoch: 0105 training loss= 0.00074 time= 0.36550\n",
      "validation roc= 0.96140 validation ap= 0.96624\n",
      "Epoch: 0106 training loss= 0.00074 time= 0.36653\n",
      "validation roc= 0.96117 validation ap= 0.96600\n",
      "Epoch: 0107 training loss= 0.00074 time= 0.38971\n",
      "validation roc= 0.96119 validation ap= 0.96601\n",
      "Epoch: 0108 training loss= 0.00074 time= 0.37022\n",
      "validation roc= 0.96105 validation ap= 0.96590\n",
      "Epoch: 0109 training loss= 0.00073 time= 0.38252\n",
      "validation roc= 0.96113 validation ap= 0.96601\n",
      "Epoch: 0110 training loss= 0.00073 time= 0.35296\n",
      "validation roc= 0.96113 validation ap= 0.96599\n",
      "Epoch: 0111 training loss= 0.00073 time= 0.45557\n",
      "validation roc= 0.96103 validation ap= 0.96581\n",
      "Epoch: 0112 training loss= 0.00073 time= 0.36495\n",
      "validation roc= 0.96128 validation ap= 0.96601\n",
      "Epoch: 0113 training loss= 0.00073 time= 0.43861\n",
      "validation roc= 0.96121 validation ap= 0.96588\n",
      "Epoch: 0114 training loss= 0.00073 time= 0.42802\n",
      "validation roc= 0.96090 validation ap= 0.96550\n",
      "Epoch: 0115 training loss= 0.00073 time= 0.38857\n",
      "validation roc= 0.96099 validation ap= 0.96552\n",
      "Epoch: 0116 training loss= 0.00073 time= 0.42460\n",
      "validation roc= 0.96103 validation ap= 0.96553\n",
      "Epoch: 0117 training loss= 0.00073 time= 0.43420\n",
      "validation roc= 0.96078 validation ap= 0.96522\n",
      "Epoch: 0118 training loss= 0.00073 time= 0.43311\n",
      "validation roc= 0.96080 validation ap= 0.96526\n",
      "Epoch: 0119 training loss= 0.00073 time= 0.44588\n",
      "validation roc= 0.96082 validation ap= 0.96519\n",
      "Epoch: 0120 training loss= 0.00073 time= 0.42110\n",
      "validation roc= 0.96059 validation ap= 0.96502\n",
      "Epoch: 0121 training loss= 0.00073 time= 0.46048\n",
      "validation roc= 0.96066 validation ap= 0.96495\n",
      "Epoch: 0122 training loss= 0.00073 time= 0.44617\n",
      "validation roc= 0.96029 validation ap= 0.96464\n",
      "Epoch: 0123 training loss= 0.00073 time= 0.47430\n",
      "validation roc= 0.96047 validation ap= 0.96474\n",
      "Epoch: 0124 training loss= 0.00073 time= 0.46672\n",
      "validation roc= 0.96008 validation ap= 0.96446\n",
      "Epoch: 0125 training loss= 0.00073 time= 0.45929\n",
      "validation roc= 0.96076 validation ap= 0.96508\n",
      "Epoch: 0126 training loss= 0.00072 time= 0.45113\n",
      "validation roc= 0.95994 validation ap= 0.96440\n",
      "Epoch: 0127 training loss= 0.00072 time= 0.46971\n",
      "validation roc= 0.96068 validation ap= 0.96492\n",
      "Epoch: 0128 training loss= 0.00072 time= 0.45109\n",
      "validation roc= 0.96039 validation ap= 0.96492\n",
      "Epoch: 0129 training loss= 0.00072 time= 0.45938\n",
      "validation roc= 0.96033 validation ap= 0.96484\n",
      "Epoch: 0130 training loss= 0.00072 time= 0.45928\n",
      "validation roc= 0.96103 validation ap= 0.96546\n",
      "Epoch: 0131 training loss= 0.00072 time= 0.45416\n",
      "validation roc= 0.96045 validation ap= 0.96502\n",
      "Epoch: 0132 training loss= 0.00072 time= 0.45777\n",
      "validation roc= 0.96109 validation ap= 0.96544\n",
      "Epoch: 0133 training loss= 0.00072 time= 0.45966\n",
      "validation roc= 0.96111 validation ap= 0.96555\n",
      "Epoch: 0134 training loss= 0.00072 time= 0.46148\n",
      "validation roc= 0.96103 validation ap= 0.96560\n",
      "Epoch: 0135 training loss= 0.00072 time= 0.45432\n",
      "validation roc= 0.96163 validation ap= 0.96585\n",
      "Epoch: 0136 training loss= 0.00072 time= 0.45475\n",
      "validation roc= 0.96136 validation ap= 0.96593\n",
      "Epoch: 0137 training loss= 0.00072 time= 0.47627\n",
      "validation roc= 0.96144 validation ap= 0.96596\n",
      "Epoch: 0138 training loss= 0.00072 time= 0.45788\n",
      "validation roc= 0.96159 validation ap= 0.96592\n",
      "Epoch: 0139 training loss= 0.00072 time= 0.45841\n",
      "validation roc= 0.96177 validation ap= 0.96614\n",
      "Epoch: 0140 training loss= 0.00072 time= 0.44141\n",
      "validation roc= 0.96171 validation ap= 0.96607\n",
      "Epoch: 0141 training loss= 0.00072 time= 0.44542\n",
      "validation roc= 0.96200 validation ap= 0.96623\n",
      "Epoch: 0142 training loss= 0.00072 time= 0.45839\n",
      "validation roc= 0.96210 validation ap= 0.96641\n",
      "Epoch: 0143 training loss= 0.00072 time= 0.44516\n",
      "validation roc= 0.96198 validation ap= 0.96619\n",
      "Epoch: 0144 training loss= 0.00071 time= 0.43382\n",
      "validation roc= 0.96204 validation ap= 0.96613\n",
      "Epoch: 0145 training loss= 0.00071 time= 0.45320\n",
      "validation roc= 0.96175 validation ap= 0.96605\n",
      "Epoch: 0146 training loss= 0.00071 time= 0.44177\n",
      "validation roc= 0.96189 validation ap= 0.96587\n",
      "Epoch: 0147 training loss= 0.00071 time= 0.45548\n",
      "validation roc= 0.96134 validation ap= 0.96557\n",
      "Epoch: 0148 training loss= 0.00071 time= 0.44950\n",
      "validation roc= 0.96169 validation ap= 0.96572\n",
      "Epoch: 0149 training loss= 0.00071 time= 0.44674\n",
      "validation roc= 0.96101 validation ap= 0.96498\n",
      "Epoch: 0150 training loss= 0.00071 time= 0.44977\n",
      "validation roc= 0.96171 validation ap= 0.96579\n",
      "Epoch: 0151 training loss= 0.00071 time= 0.46455\n",
      "validation roc= 0.96055 validation ap= 0.96446\n",
      "Epoch: 0152 training loss= 0.00071 time= 0.43224\n",
      "validation roc= 0.96189 validation ap= 0.96594\n",
      "Epoch: 0153 training loss= 0.00071 time= 0.42663\n",
      "validation roc= 0.95977 validation ap= 0.96388\n",
      "Epoch: 0154 training loss= 0.00071 time= 0.49568\n",
      "validation roc= 0.96189 validation ap= 0.96557\n",
      "Epoch: 0155 training loss= 0.00071 time= 0.45491\n",
      "validation roc= 0.96078 validation ap= 0.96470\n",
      "Epoch: 0156 training loss= 0.00071 time= 0.46043\n",
      "validation roc= 0.96070 validation ap= 0.96459\n",
      "Epoch: 0157 training loss= 0.00071 time= 0.46686\n",
      "validation roc= 0.96154 validation ap= 0.96523\n",
      "Epoch: 0158 training loss= 0.00071 time= 0.43574\n",
      "validation roc= 0.96018 validation ap= 0.96418\n",
      "Epoch: 0159 training loss= 0.00071 time= 0.48599\n",
      "validation roc= 0.96115 validation ap= 0.96486\n",
      "Epoch: 0160 training loss= 0.00071 time= 0.46230\n",
      "validation roc= 0.96101 validation ap= 0.96473\n",
      "Epoch: 0161 training loss= 0.00071 time= 0.44414\n",
      "validation roc= 0.96049 validation ap= 0.96432\n",
      "Epoch: 0162 training loss= 0.00071 time= 0.46623\n",
      "validation roc= 0.96099 validation ap= 0.96475\n",
      "Epoch: 0163 training loss= 0.00071 time= 0.45100\n",
      "validation roc= 0.96004 validation ap= 0.96393\n",
      "Epoch: 0164 training loss= 0.00071 time= 0.45639\n",
      "validation roc= 0.96055 validation ap= 0.96453\n",
      "Epoch: 0165 training loss= 0.00071 time= 0.45535\n",
      "validation roc= 0.96047 validation ap= 0.96432\n",
      "Epoch: 0166 training loss= 0.00071 time= 0.44559\n",
      "validation roc= 0.96014 validation ap= 0.96417\n",
      "Epoch: 0167 training loss= 0.00071 time= 0.45992\n",
      "validation roc= 0.96064 validation ap= 0.96479\n",
      "Epoch: 0168 training loss= 0.00071 time= 0.46031\n",
      "validation roc= 0.96027 validation ap= 0.96425\n",
      "Epoch: 0169 training loss= 0.00071 time= 0.45438\n",
      "validation roc= 0.96055 validation ap= 0.96474\n",
      "Epoch: 0170 training loss= 0.00070 time= 0.45216\n",
      "validation roc= 0.96051 validation ap= 0.96470\n",
      "Epoch: 0171 training loss= 0.00070 time= 0.45612\n",
      "validation roc= 0.96057 validation ap= 0.96458\n",
      "Epoch: 0172 training loss= 0.00070 time= 0.46600\n",
      "validation roc= 0.96059 validation ap= 0.96491\n",
      "Epoch: 0173 training loss= 0.00070 time= 0.43493\n",
      "validation roc= 0.95998 validation ap= 0.96417\n",
      "Epoch: 0174 training loss= 0.00070 time= 0.42661\n",
      "validation roc= 0.96078 validation ap= 0.96509\n",
      "Epoch: 0175 training loss= 0.00070 time= 0.43205\n",
      "validation roc= 0.95998 validation ap= 0.96444\n",
      "Epoch: 0176 training loss= 0.00070 time= 0.44570\n",
      "validation roc= 0.96072 validation ap= 0.96500\n",
      "Epoch: 0177 training loss= 0.00070 time= 0.45084\n",
      "validation roc= 0.96002 validation ap= 0.96449\n",
      "Epoch: 0178 training loss= 0.00070 time= 0.42439\n",
      "validation roc= 0.96060 validation ap= 0.96499\n",
      "Epoch: 0179 training loss= 0.00070 time= 0.43147\n",
      "validation roc= 0.96012 validation ap= 0.96462\n",
      "Epoch: 0180 training loss= 0.00070 time= 0.46515\n",
      "validation roc= 0.96064 validation ap= 0.96519\n",
      "Epoch: 0181 training loss= 0.00070 time= 0.44874\n",
      "validation roc= 0.96012 validation ap= 0.96469\n",
      "Epoch: 0182 training loss= 0.00070 time= 0.46298\n",
      "validation roc= 0.96059 validation ap= 0.96526\n",
      "Epoch: 0183 training loss= 0.00070 time= 0.49206\n",
      "validation roc= 0.96024 validation ap= 0.96481\n",
      "Epoch: 0184 training loss= 0.00070 time= 0.46480\n",
      "validation roc= 0.96066 validation ap= 0.96524\n",
      "Epoch: 0185 training loss= 0.00070 time= 0.42495\n",
      "validation roc= 0.96037 validation ap= 0.96518\n",
      "Epoch: 0186 training loss= 0.00070 time= 0.46554\n",
      "validation roc= 0.96062 validation ap= 0.96519\n",
      "Epoch: 0187 training loss= 0.00070 time= 0.45822\n",
      "validation roc= 0.96084 validation ap= 0.96567\n",
      "Epoch: 0188 training loss= 0.00070 time= 0.47386\n",
      "validation roc= 0.96041 validation ap= 0.96506\n",
      "Epoch: 0189 training loss= 0.00070 time= 0.45035\n",
      "validation roc= 0.96092 validation ap= 0.96548\n",
      "Epoch: 0190 training loss= 0.00070 time= 0.47299\n",
      "validation roc= 0.96037 validation ap= 0.96524\n",
      "Epoch: 0191 training loss= 0.00070 time= 0.46446\n",
      "validation roc= 0.96099 validation ap= 0.96562\n",
      "Epoch: 0192 training loss= 0.00070 time= 0.44900\n",
      "validation roc= 0.96045 validation ap= 0.96525\n",
      "Epoch: 0193 training loss= 0.00070 time= 0.44567\n",
      "validation roc= 0.96068 validation ap= 0.96538\n",
      "Epoch: 0194 training loss= 0.00070 time= 0.44475\n",
      "validation roc= 0.96072 validation ap= 0.96544\n",
      "Epoch: 0195 training loss= 0.00070 time= 0.45390\n",
      "validation roc= 0.96060 validation ap= 0.96548\n",
      "Epoch: 0196 training loss= 0.00070 time= 0.43699\n",
      "validation roc= 0.96088 validation ap= 0.96568\n",
      "Epoch: 0197 training loss= 0.00070 time= 0.46552\n",
      "validation roc= 0.96016 validation ap= 0.96509\n",
      "Epoch: 0198 training loss= 0.00070 time= 0.47459\n",
      "validation roc= 0.96093 validation ap= 0.96574\n",
      "Epoch: 0199 training loss= 0.00070 time= 0.47406\n",
      "validation roc= 0.96026 validation ap= 0.96519\n",
      "Epoch: 0200 training loss= 0.00070 time= 0.44496\n",
      "validation roc= 0.96078 validation ap= 0.96562\n",
      "testing roc= 0.94242 testing ap= 0.95373\n"
     ]
    }
   ],
   "source": [
    "loss_coeff_adj=0.001\n",
    "loss_coeff_AE=0.1\n",
    "results_output_path = path_now+model_name+\"/\"\n",
    "mkdir(results_output_path)\n",
    "\n",
    "for seed_i in np.arange(nb_run):\n",
    "    \n",
    "    seed=seed_i\n",
    "    lost_list=[]\n",
    "    roc_list=[]\n",
    "    ap_list=[]\n",
    "    mean_time=[]\n",
    "    \n",
    "    adj, val_edges, val_edges_false, test_edges, test_edges_false =mask_test_edges(adj_init, seed,prop_test, prop_val)\n",
    "                \n",
    "    t_start = time.time()\n",
    "\n",
    "    if features_used:\n",
    "        features = features_init\n",
    "    \n",
    "    num_nodes = adj.shape[0]\n",
    "\n",
    "    if not features_used:\n",
    "        features = sp.identity(adj.shape[0])\n",
    "\n",
    "    features = sparse_to_tuple(features)\n",
    "    num_features = features[2][1]\n",
    "    features_nonzero = features[1].shape[0]\n",
    "        \n",
    "    placeholders = {\n",
    "        'features': tf.sparse_placeholder(tf.float32),\n",
    "        'adj': tf.sparse_placeholder(tf.float32),\n",
    "        'adj_orig': tf.sparse_placeholder(tf.float32),\n",
    "        'dropout': tf.placeholder_with_default(0., shape = ())\n",
    "    }\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "# Create model\n",
    "    if model_name=='DGAE_alpha_beta_feature':\n",
    "        model = DGAE_alpha_beta_feature(placeholders, layers_no,num_features, features_nonzero)\n",
    "    elif model_name=='DGAE_alpha_beta_no_feature':\n",
    "        model=DGAE_alpha_beta_no_feature(placeholders, layers_no,num_features, num_adj,features_nonzero)\n",
    "    elif model_name == 'deep_gcn_ae':\n",
    "        model = DeepGCNModelAE(placeholders, layers_no,num_features, features_nonzero)\n",
    "    elif model_name == 'linear_ae':\n",
    "        model = LinearModelAE(placeholders, num_features, features_nonzero)\n",
    "    elif model_name == 'gcn_ae':\n",
    "        model = GCNModelAE(placeholders, num_features, features_nonzero)\n",
    "    else:\n",
    "        raise ValueError('Undefined model!')\n",
    "\n",
    "    pos_weight = float(adj.shape[0] * adj.shape[0] - adj.sum()) / adj.sum()\n",
    "    norm = adj.shape[0] * adj.shape[0] / float((adj.shape[0] * adj.shape[0]- adj.sum()) * 2)\n",
    "    \n",
    "    with tf.name_scope('optimizer'):\n",
    "        if model_name in ('DGAE_alpha_beta_feature'):\n",
    "            opt =OptimizerAE_FeatureReconstrution(preds_adj = model.reconstructions,\\\n",
    "                                                  preds_Features=model.feature_reconstruction,\\\n",
    "                                                  labels_adj = tf.reshape(tf.sparse_tensor_to_dense(placeholders['adj_orig'],\\\n",
    "                                                                                                    validate_indices = False), [-1]),\\\n",
    "                                                  labels_Features=placeholders['features'],\\\n",
    "                                                  labels_adj_rec=placeholders['adj'],\\\n",
    "                                                  loss_coeff_adj=loss_coeff_adj,\\\n",
    "                                                  loss_coeff_AE=loss_coeff_AE,\\\n",
    "                                                  pos_weight = pos_weight,\\\n",
    "                                                  norm = norm)\n",
    "                \n",
    "        elif model_name in ('DGAE_alpha_beta_no_feature'):\n",
    "            opt =OptimizerAE_AdjReconstrution(preds_adj = model.reconstructions,\\\n",
    "                                              preds_adj_rec=model.adj_reconstruction,\\\n",
    "                                              labels_adj = tf.reshape(tf.sparse_tensor_to_dense(placeholders['adj_orig'],\n",
    "                                                                                                validate_indices = False), [-1]),\\\n",
    "                                              labels_Features=placeholders['features'],\\\n",
    "                                              labels_adj_rec=placeholders['adj'],\\\n",
    "                                              loss_coeff_adj=loss_coeff_adj,\\\n",
    "                                              loss_coeff_AE=loss_coeff_AE,\\\n",
    "                                              pos_weight = pos_weight,\\\n",
    "                                              norm = norm)\n",
    "            \n",
    "        elif model_name in ('gcn_ae', 'linear_ae', 'deep_gcn_ae'):\n",
    "            opt = OptimizerAE(preds = model.reconstructions,\\\n",
    "                              labels = tf.reshape(tf.sparse_tensor_to_dense(placeholders['adj_orig'],\\\n",
    "                                                                            validate_indices = False), [-1]),\n",
    "                              pos_weight = pos_weight,\n",
    "                              norm = norm)\n",
    "\n",
    "    adj_norm = preprocess_graph(adj)\n",
    "    adj_label = sparse_to_tuple(adj + sp.eye(adj.shape[0]))\n",
    "\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        t = time.time()\n",
    "        feed_dict = construct_feed_dict(adj_norm, adj_label, features,placeholders)\n",
    "        feed_dict.update({placeholders['dropout']: dropout})\n",
    "        outs = sess.run([opt.opt_op, opt.cost, opt.accuracy],feed_dict = feed_dict)\n",
    "        avg_cost = outs[1]\n",
    "        if verbose:\n",
    "            lost_list.append(avg_cost)\n",
    "            print(\"Epoch:\", '%04d' % (epoch + 1), \"training loss=\", \"{:.5f}\".format(avg_cost),\"time=\", \"{:.5f}\".format(time.time() - t))\n",
    "                    \n",
    "            if validation:\n",
    "                feed_dict.update({placeholders['dropout']: 0})\n",
    "                emb = sess.run(model.z_mean, feed_dict = feed_dict)\n",
    "                feed_dict.update({placeholders['dropout']: dropout})\n",
    "                val_roc, val_ap = get_roc_score(val_edges, val_edges_false, emb)\n",
    "                roc_list.append(val_roc)\n",
    "                ap_list.append(val_ap)\n",
    "                print(\"validation roc=\", \"{:.5f}\".format(val_roc), \"validation ap=\", \"{:.5f}\".format(val_ap))\n",
    "\n",
    "    emb = sess.run(model.z_mean, feed_dict = feed_dict)   \n",
    "    mean_time.append(time.time() - t_start)\n",
    "    \n",
    "    roc_score, ap_score = get_roc_score(test_edges, test_edges_false, emb)\n",
    "    print(\"testing roc=\", \"{:.5f}\".format(roc_score), \"testing ap=\", \"{:.5f}\".format(ap_score))\n",
    "    \n",
    "    roc_list.append(roc_score)\n",
    "    ap_list.append(ap_score)\n",
    "    \n",
    "    mean_time_=np.array(mean_time)\n",
    "    write_to_csv(mean_time_.reshape(1,len(mean_time_)),results_output_path+\"layers_\"+str(layers_no)+\"_time_10run.csv\")\n",
    "\n",
    "    roc_list_=np.array(roc_list)\n",
    "    write_to_csv(roc_list_.reshape(1,len(roc_list_)),results_output_path+\"layers_\"+str(layers_no)+\"_roc_10run.csv\")\n",
    "\n",
    "    ap_list_=np.array(ap_list)\n",
    "    write_to_csv(ap_list_.reshape(1,len(ap_list_)),results_output_path+\"layers_\"+str(layers_no)+\"_ap_10run.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  [119.50172138 116.28479028 116.47095156 109.18362451 103.23720622\n",
      " 102.79034662 103.43382692 107.37970352 111.33015132 111.75167704]\n",
      "\n",
      "\n",
      "AUC:  [0.95034416 0.94599445 0.93285352 0.93292598 0.93963531 0.94066417\n",
      " 0.93741336 0.95318923 0.95757517 0.94241517]\n",
      "\n",
      "\n",
      "AP:  [0.95500815 0.95055093 0.94428707 0.93759223 0.94608003 0.94896018\n",
      " 0.94921701 0.95876997 0.95425256 0.9537312 ]\n"
     ]
    }
   ],
   "source": [
    "time_10run=results_output_path+\"layers_\"+str(layers_no)+\"_time_10run.csv\"\n",
    "roc_10run=results_output_path+\"layers_\"+str(layers_no)+\"_roc_10run.csv\"\n",
    "ap_10run=results_output_path+\"layers_\"+str(layers_no)+\"_ap_10run.csv\"\n",
    "\n",
    "mean_time_read=np.array(pd.read_csv(time_10run,header=None))\n",
    "mean_roc_read=np.array(pd.read_csv(roc_10run,header=None))\n",
    "mean_ap_read=np.array(pd.read_csv(ap_10run,header=None))\n",
    "\n",
    "p_used_number=10\n",
    "time_test=mean_time_read[:,-1][0:p_used_number]\n",
    "roc_test=mean_roc_read[:,-1][0:p_used_number]\n",
    "ap_test=mean_ap_read[:,-1][0:p_used_number]\n",
    "\n",
    "print(\"Time: \", time_test)\n",
    "print(\"\\n\")\n",
    "print(\"AUC: \", roc_test)\n",
    "print(\"\\n\")\n",
    "print(\"AP: \", ap_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged AUC:  0.94330105059775380.00794367672597302\n",
      "\n",
      "\n",
      "Averaged AP:  0.94984493400488650.0058113152173750356\n"
     ]
    }
   ],
   "source": [
    "print(\"Averaged AUC: \", str(np.mean(roc_test))+''+str(np.std(roc_test)))\n",
    "print(\"\\n\")\n",
    "print(\"Averaged AP: \",  str(np.mean(ap_test))+''+str(np.std(ap_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
