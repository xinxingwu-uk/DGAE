{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import scipy.sparse as sp\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "# Import defined methods\n",
    "import sys\n",
    "sys.path.append(r'/home/xinxingwu/Done_Results/GAE_VGAE_Results/GVAE_Pubmed_36')\n",
    "\n",
    "from linear_gae.evaluation import get_roc_score\n",
    "from linear_gae.input_data import load_data, load_label\n",
    "from linear_gae.model import *\n",
    "from linear_gae.optimizer import OptimizerAE, OptimizerVAE\n",
    "from linear_gae.preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(p_data,p_path):\n",
    "    dataframe = pd.DataFrame(p_data)\n",
    "    dataframe.to_csv(p_path, mode='a',header=False,index=False,sep=',')\n",
    "    del dataframe\n",
    "\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "output_path=\"/home/xinxingwu/Done_Results/GAE_VGAE_Results/GVAE_Pubmed_36/2Citeseer_AE/log/\"\n",
    "dataset='citeseer'\n",
    "task='link_prediction'\n",
    "model_name='deep36_gcn_vae'\n",
    "dropout=0.\n",
    "epochs=200\n",
    "features_used=True\n",
    "learning_rate=0.01\n",
    "nb_run=10 # Number of model run + test\n",
    "prop_val=5 # Proportion of edges in validation set (for Link Prediction task)\n",
    "prop_test=10 # Proportion of edges in test set (for Link Prediction task)\n",
    "validation=True # Whether to report validation results at each epoch (for Link Prediction task)\n",
    "verbose=True # Whether to print comments details\n",
    "kcore=False # Whether to run k-core decomposition and use the framework. False = model will be trained on the entire graph\n",
    "task='link_prediction'\n",
    "\n",
    "p_model_name=model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "mean_time = []\n",
    "if verbose:\n",
    "    print(\"Loading data...\")\n",
    "adj_init, features_init = load_data(dataset)\n",
    "\n",
    "# Lists to collect average results\n",
    "if task == 'link_prediction':\n",
    "    mean_roc = []\n",
    "    mean_ap = []\n",
    "\n",
    "mean_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masking test edges...\n",
      "Preprocessing and Initializing...\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201: calling weighted_cross_entropy_with_logits (from tensorflow.python.ops.nn_impl) with targets is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "targets is deprecated, use labels instead\n",
      "Training...\n",
      "Epoch: 0001 train_loss= 1.75732 time= 2.92148\n",
      "val_roc= 0.60131 val_ap= 0.64058\n",
      "Epoch: 0002 train_loss= 1.74698 time= 0.73434\n",
      "val_roc= 0.61519 val_ap= 0.66744\n",
      "Epoch: 0003 train_loss= 1.64078 time= 0.57794\n",
      "val_roc= 0.49780 val_ap= 0.49890\n",
      "Epoch: 0004 train_loss= 8279587840.00000 time= 0.38228\n",
      "val_roc= 0.61503 val_ap= 0.66817\n",
      "Epoch: 0005 train_loss= 1.52194 time= 0.45925\n",
      "val_roc= 0.61038 val_ap= 0.66623\n",
      "Epoch: 0006 train_loss= 1.70955 time= 0.44124\n",
      "val_roc= 0.61419 val_ap= 0.66562\n",
      "Epoch: 0007 train_loss= 1.70829 time= 0.46760\n",
      "val_roc= 0.62341 val_ap= 0.66427\n",
      "Epoch: 0008 train_loss= 1.69559 time= 0.50491\n",
      "val_roc= 0.63196 val_ap= 0.63083\n",
      "Epoch: 0009 train_loss= 1.72867 time= 0.50572\n",
      "val_roc= 0.60816 val_ap= 0.58114\n",
      "Epoch: 0010 train_loss= 1.72529 time= 0.44441\n",
      "val_roc= 0.59708 val_ap= 0.57675\n",
      "Epoch: 0011 train_loss= 1.74670 time= 0.37005\n",
      "val_roc= 0.58370 val_ap= 0.57130\n",
      "Epoch: 0012 train_loss= 1.73495 time= 0.36198\n",
      "val_roc= 0.61633 val_ap= 0.58737\n",
      "Epoch: 0013 train_loss= 1.71090 time= 0.55131\n",
      "val_roc= 0.55861 val_ap= 0.56376\n",
      "Epoch: 0014 train_loss= 1.73471 time= 0.40531\n",
      "val_roc= 0.61972 val_ap= 0.63563\n",
      "Epoch: 0015 train_loss= 1.76060 time= 0.43216\n",
      "val_roc= 0.62419 val_ap= 0.66226\n",
      "Epoch: 0016 train_loss= 1.76067 time= 0.39242\n",
      "val_roc= 0.62556 val_ap= 0.67195\n",
      "Epoch: 0017 train_loss= 1.71073 time= 0.32568\n",
      "val_roc= 0.62606 val_ap= 0.67420\n",
      "Epoch: 0018 train_loss= 1.76306 time= 0.46234\n",
      "val_roc= 0.62607 val_ap= 0.67466\n",
      "Epoch: 0019 train_loss= 1.73413 time= 0.38336\n",
      "val_roc= 0.62535 val_ap= 0.67452\n",
      "Epoch: 0020 train_loss= 1.71928 time= 0.39164\n",
      "val_roc= 0.62568 val_ap= 0.67465\n",
      "Epoch: 0021 train_loss= 1.64187 time= 0.38370\n",
      "val_roc= 0.62553 val_ap= 0.67475\n",
      "Epoch: 0022 train_loss= 1.50249 time= 0.34548\n",
      "val_roc= 0.62536 val_ap= 0.67463\n",
      "Epoch: 0023 train_loss= 1.28478 time= 0.33931\n",
      "val_roc= 0.62522 val_ap= 0.67442\n",
      "Epoch: 0024 train_loss= 3.52356 time= 0.40072\n",
      "val_roc= 0.62510 val_ap= 0.67442\n",
      "Epoch: 0025 train_loss= 1.23822 time= 0.36912\n",
      "val_roc= 0.62545 val_ap= 0.67474\n",
      "Epoch: 0026 train_loss= 1.35083 time= 0.35511\n",
      "val_roc= 0.62514 val_ap= 0.67441\n",
      "Epoch: 0027 train_loss= 1.53826 time= 0.33263\n",
      "val_roc= 0.62499 val_ap= 0.67440\n",
      "Epoch: 0028 train_loss= 1.60635 time= 0.33540\n",
      "val_roc= 0.62529 val_ap= 0.67468\n",
      "Epoch: 0029 train_loss= 1.65521 time= 0.38663\n",
      "val_roc= 0.62533 val_ap= 0.67437\n",
      "Epoch: 0030 train_loss= 1.68756 time= 0.38014\n",
      "val_roc= 0.62541 val_ap= 0.67432\n",
      "Epoch: 0031 train_loss= 1.68779 time= 0.37538\n",
      "val_roc= 0.62514 val_ap= 0.67388\n",
      "Epoch: 0032 train_loss= 1.69410 time= 0.39022\n",
      "val_roc= 0.62530 val_ap= 0.67379\n",
      "Epoch: 0033 train_loss= 1.73116 time= 0.37243\n",
      "val_roc= 0.62554 val_ap= 0.67387\n",
      "Epoch: 0034 train_loss= 1.70831 time= 0.33129\n",
      "val_roc= 0.62580 val_ap= 0.67419\n",
      "Epoch: 0035 train_loss= 1.71653 time= 0.36556\n",
      "val_roc= 0.62580 val_ap= 0.67415\n",
      "Epoch: 0036 train_loss= 1.72779 time= 0.33402\n",
      "val_roc= 0.62601 val_ap= 0.67418\n",
      "Epoch: 0037 train_loss= 1.72048 time= 0.38302\n",
      "val_roc= 0.62599 val_ap= 0.67399\n",
      "Epoch: 0038 train_loss= 1.69303 time= 0.33793\n",
      "val_roc= 0.62602 val_ap= 0.67375\n",
      "Epoch: 0039 train_loss= 1.70664 time= 0.35758\n",
      "val_roc= 0.62594 val_ap= 0.67368\n",
      "Epoch: 0040 train_loss= 1.69302 time= 0.42660\n",
      "val_roc= 0.62605 val_ap= 0.67374\n",
      "Epoch: 0041 train_loss= 1.63961 time= 0.35112\n",
      "val_roc= 0.62600 val_ap= 0.67380\n",
      "Epoch: 0042 train_loss= 1.68975 time= 0.33306\n",
      "val_roc= 0.62583 val_ap= 0.67368\n",
      "Epoch: 0043 train_loss= 1.60970 time= 0.31191\n",
      "val_roc= 0.62569 val_ap= 0.67356\n",
      "Epoch: 0044 train_loss= 1.57151 time= 0.42365\n",
      "val_roc= 0.62553 val_ap= 0.67330\n",
      "Epoch: 0045 train_loss= 1.44595 time= 0.31758\n",
      "val_roc= 0.62514 val_ap= 0.67273\n",
      "Epoch: 0046 train_loss= 1.29524 time= 0.32934\n",
      "val_roc= 0.62503 val_ap= 0.67277\n",
      "Epoch: 0047 train_loss= 1.08992 time= 0.33301\n",
      "val_roc= 0.62462 val_ap= 0.67266\n",
      "Epoch: 0048 train_loss= 1.17305 time= 0.28634\n",
      "val_roc= 0.62466 val_ap= 0.67266\n",
      "Epoch: 0049 train_loss= 1.12020 time= 0.29172\n",
      "val_roc= 0.62474 val_ap= 0.67239\n",
      "Epoch: 0050 train_loss= 1.01088 time= 0.34193\n",
      "val_roc= 0.62458 val_ap= 0.67220\n",
      "Epoch: 0051 train_loss= 1.03541 time= 0.33236\n",
      "val_roc= 0.62423 val_ap= 0.67195\n",
      "Epoch: 0052 train_loss= 1.04802 time= 0.34449\n",
      "val_roc= 0.62411 val_ap= 0.67204\n",
      "Epoch: 0053 train_loss= 1.05314 time= 0.31628\n",
      "val_roc= 0.62411 val_ap= 0.67208\n",
      "Epoch: 0054 train_loss= 1.00375 time= 0.38980\n",
      "val_roc= 0.62427 val_ap= 0.67211\n",
      "Epoch: 0055 train_loss= 0.94138 time= 0.31172\n",
      "val_roc= 0.62411 val_ap= 0.67204\n",
      "Epoch: 0056 train_loss= 0.90108 time= 0.33377\n",
      "val_roc= 0.62398 val_ap= 0.67191\n",
      "Epoch: 0057 train_loss= 0.92450 time= 0.31538\n",
      "val_roc= 0.62400 val_ap= 0.67196\n",
      "Epoch: 0058 train_loss= 0.91162 time= 0.33940\n",
      "val_roc= 0.62400 val_ap= 0.67201\n",
      "Epoch: 0059 train_loss= 0.86081 time= 0.33283\n",
      "val_roc= 0.62398 val_ap= 0.67196\n",
      "Epoch: 0060 train_loss= 0.83724 time= 0.36795\n",
      "val_roc= 0.62342 val_ap= 0.67160\n",
      "Epoch: 0061 train_loss= 0.83071 time= 0.33297\n",
      "val_roc= 0.62342 val_ap= 0.67145\n",
      "Epoch: 0062 train_loss= 0.84750 time= 0.38821\n",
      "val_roc= 0.62344 val_ap= 0.67147\n",
      "Epoch: 0063 train_loss= 0.82380 time= 0.32929\n",
      "val_roc= 0.62305 val_ap= 0.67120\n",
      "Epoch: 0064 train_loss= 0.80697 time= 0.36131\n",
      "val_roc= 0.62274 val_ap= 0.67117\n",
      "Epoch: 0065 train_loss= 0.78566 time= 0.30994\n",
      "val_roc= 0.62262 val_ap= 0.67104\n",
      "Epoch: 0066 train_loss= 0.77717 time= 0.31717\n",
      "val_roc= 0.62239 val_ap= 0.67089\n",
      "Epoch: 0067 train_loss= 0.77974 time= 0.32553\n",
      "val_roc= 0.62214 val_ap= 0.67071\n",
      "Epoch: 0068 train_loss= 0.77896 time= 0.32982\n",
      "val_roc= 0.62204 val_ap= 0.67079\n",
      "Epoch: 0069 train_loss= 0.76550 time= 0.32040\n",
      "val_roc= 0.62247 val_ap= 0.67115\n",
      "Epoch: 0070 train_loss= 0.75861 time= 0.33491\n",
      "val_roc= 0.62186 val_ap= 0.67075\n",
      "Epoch: 0071 train_loss= 0.75420 time= 0.35097\n",
      "val_roc= 0.62196 val_ap= 0.67122\n",
      "Epoch: 0072 train_loss= 0.74910 time= 0.29863\n",
      "val_roc= 0.62118 val_ap= 0.67103\n",
      "Epoch: 0073 train_loss= 0.75163 time= 0.34472\n",
      "val_roc= 0.62122 val_ap= 0.67131\n",
      "Epoch: 0074 train_loss= 0.75532 time= 0.33665\n",
      "val_roc= 0.62052 val_ap= 0.67119\n",
      "Epoch: 0075 train_loss= 0.75436 time= 0.34453\n",
      "val_roc= 0.61981 val_ap= 0.67083\n",
      "Epoch: 0076 train_loss= 0.75298 time= 0.33078\n",
      "val_roc= 0.61860 val_ap= 0.67112\n",
      "Epoch: 0077 train_loss= 0.75674 time= 0.33461\n",
      "val_roc= 0.61728 val_ap= 0.67136\n",
      "Epoch: 0078 train_loss= 0.75091 time= 0.34657\n",
      "val_roc= 0.61548 val_ap= 0.67049\n",
      "Epoch: 0079 train_loss= 0.75162 time= 0.33603\n",
      "val_roc= 0.61416 val_ap= 0.67024\n",
      "Epoch: 0080 train_loss= 0.74748 time= 0.33583\n",
      "val_roc= 0.61377 val_ap= 0.67102\n",
      "Epoch: 0081 train_loss= 0.74698 time= 0.36610\n",
      "val_roc= 0.61563 val_ap= 0.67406\n",
      "Epoch: 0082 train_loss= 0.74310 time= 0.29726\n",
      "val_roc= 0.61746 val_ap= 0.67749\n",
      "Epoch: 0083 train_loss= 0.74217 time= 0.32887\n",
      "val_roc= 0.62095 val_ap= 0.68189\n",
      "Epoch: 0084 train_loss= 0.73877 time= 0.35290\n",
      "val_roc= 0.62590 val_ap= 0.68743\n",
      "Epoch: 0085 train_loss= 0.73619 time= 0.35583\n",
      "val_roc= 0.63062 val_ap= 0.69229\n",
      "Epoch: 0086 train_loss= 0.73026 time= 0.33817\n",
      "val_roc= 0.63139 val_ap= 0.69345\n",
      "Epoch: 0087 train_loss= 0.73015 time= 0.31883\n",
      "val_roc= 0.63258 val_ap= 0.69452\n",
      "Epoch: 0088 train_loss= 0.73300 time= 0.35463\n",
      "val_roc= 0.63184 val_ap= 0.69517\n",
      "Epoch: 0089 train_loss= 0.72183 time= 0.32641\n",
      "val_roc= 0.63190 val_ap= 0.69679\n",
      "Epoch: 0090 train_loss= 0.72482 time= 0.33464\n",
      "val_roc= 0.63052 val_ap= 0.69759\n",
      "Epoch: 0091 train_loss= 0.72213 time= 0.34471\n",
      "val_roc= 0.62844 val_ap= 0.69696\n",
      "Epoch: 0092 train_loss= 0.72001 time= 0.36109\n",
      "val_roc= 0.62530 val_ap= 0.69512\n",
      "Epoch: 0093 train_loss= 0.72047 time= 0.35822\n",
      "val_roc= 0.62239 val_ap= 0.69369\n",
      "Epoch: 0094 train_loss= 0.71808 time= 0.33526\n",
      "val_roc= 0.61961 val_ap= 0.69282\n",
      "Epoch: 0095 train_loss= 0.71175 time= 0.31713\n",
      "val_roc= 0.61627 val_ap= 0.69136\n",
      "Epoch: 0096 train_loss= 0.71407 time= 0.33047\n",
      "val_roc= 0.61406 val_ap= 0.69002\n",
      "Epoch: 0097 train_loss= 0.71143 time= 0.30735\n",
      "val_roc= 0.61346 val_ap= 0.69048\n",
      "Epoch: 0098 train_loss= 0.71148 time= 0.41080\n",
      "val_roc= 0.61284 val_ap= 0.69049\n",
      "Epoch: 0099 train_loss= 0.70726 time= 0.35397\n",
      "val_roc= 0.61323 val_ap= 0.69117\n",
      "Epoch: 0100 train_loss= 0.71158 time= 0.40382\n",
      "val_roc= 0.61309 val_ap= 0.69085\n",
      "Epoch: 0101 train_loss= 0.70522 time= 0.28978\n",
      "val_roc= 0.61319 val_ap= 0.69094\n",
      "Epoch: 0102 train_loss= 0.70397 time= 0.32027\n",
      "val_roc= 0.61356 val_ap= 0.69090\n",
      "Epoch: 0103 train_loss= 0.71035 time= 0.28567\n",
      "val_roc= 0.61334 val_ap= 0.69076\n",
      "Epoch: 0104 train_loss= 0.70900 time= 0.26419\n",
      "val_roc= 0.61265 val_ap= 0.69015\n",
      "Epoch: 0105 train_loss= 0.70647 time= 0.34261\n",
      "val_roc= 0.61111 val_ap= 0.68873\n",
      "Epoch: 0106 train_loss= 0.69948 time= 0.27134\n",
      "val_roc= 0.61059 val_ap= 0.68783\n",
      "Epoch: 0107 train_loss= 0.70410 time= 0.35821\n",
      "val_roc= 0.61012 val_ap= 0.68751\n",
      "Epoch: 0108 train_loss= 0.70071 time= 0.32544\n",
      "val_roc= 0.61006 val_ap= 0.68725\n",
      "Epoch: 0109 train_loss= 0.70540 time= 0.27911\n",
      "val_roc= 0.61018 val_ap= 0.68662\n",
      "Epoch: 0110 train_loss= 0.70425 time= 0.28921\n",
      "val_roc= 0.61012 val_ap= 0.68629\n",
      "Epoch: 0111 train_loss= 0.70378 time= 0.42056\n",
      "val_roc= 0.61055 val_ap= 0.68619\n",
      "Epoch: 0112 train_loss= 0.69729 time= 0.32903\n",
      "val_roc= 0.61059 val_ap= 0.68595\n",
      "Epoch: 0113 train_loss= 0.69976 time= 0.33739\n",
      "val_roc= 0.61142 val_ap= 0.68589\n",
      "Epoch: 0114 train_loss= 0.70584 time= 0.33909\n",
      "val_roc= 0.61245 val_ap= 0.68593\n",
      "Epoch: 0115 train_loss= 0.70034 time= 0.32071\n",
      "val_roc= 0.61280 val_ap= 0.68602\n",
      "Epoch: 0116 train_loss= 0.70302 time= 0.28900\n",
      "val_roc= 0.61298 val_ap= 0.68602\n",
      "Epoch: 0117 train_loss= 0.69988 time= 0.35259\n",
      "val_roc= 0.61133 val_ap= 0.68432\n",
      "Epoch: 0118 train_loss= 0.70316 time= 0.29831\n",
      "val_roc= 0.61016 val_ap= 0.68337\n",
      "Epoch: 0119 train_loss= 0.70276 time= 0.33481\n",
      "val_roc= 0.60886 val_ap= 0.68236\n",
      "Epoch: 0120 train_loss= 0.69782 time= 0.34444\n",
      "val_roc= 0.60841 val_ap= 0.68218\n",
      "Epoch: 0121 train_loss= 0.69795 time= 0.27592\n",
      "val_roc= 0.60663 val_ap= 0.68168\n",
      "Epoch: 0122 train_loss= 0.69997 time= 0.37594\n",
      "val_roc= 0.60446 val_ap= 0.68079\n",
      "Epoch: 0123 train_loss= 0.69640 time= 0.28810\n",
      "val_roc= 0.60257 val_ap= 0.67951\n",
      "Epoch: 0124 train_loss= 0.69332 time= 0.36018\n",
      "val_roc= 0.60094 val_ap= 0.67890\n",
      "Epoch: 0125 train_loss= 0.69913 time= 0.32424\n",
      "val_roc= 0.60021 val_ap= 0.67883\n",
      "Epoch: 0126 train_loss= 0.69961 time= 0.31494\n",
      "val_roc= 0.59990 val_ap= 0.67892\n",
      "Epoch: 0127 train_loss= 0.69849 time= 0.39760\n",
      "val_roc= 0.59786 val_ap= 0.67805\n",
      "Epoch: 0128 train_loss= 0.70079 time= 0.29409\n",
      "val_roc= 0.59640 val_ap= 0.67752\n",
      "Epoch: 0129 train_loss= 0.69796 time= 0.29826\n",
      "val_roc= 0.59532 val_ap= 0.67705\n",
      "Epoch: 0130 train_loss= 0.69663 time= 0.33587\n",
      "val_roc= 0.59497 val_ap= 0.67694\n",
      "Epoch: 0131 train_loss= 0.69733 time= 0.32196\n",
      "val_roc= 0.59434 val_ap= 0.67666\n",
      "Epoch: 0132 train_loss= 0.69697 time= 0.33781\n",
      "val_roc= 0.59400 val_ap= 0.67666\n",
      "Epoch: 0133 train_loss= 0.69972 time= 0.31137\n",
      "val_roc= 0.59343 val_ap= 0.67654\n",
      "Epoch: 0134 train_loss= 0.69532 time= 0.40921\n",
      "val_roc= 0.59324 val_ap= 0.67643\n",
      "Epoch: 0135 train_loss= 0.69699 time= 0.35003\n",
      "val_roc= 0.59361 val_ap= 0.67661\n",
      "Epoch: 0136 train_loss= 0.69453 time= 0.33485\n",
      "val_roc= 0.59372 val_ap= 0.67667\n",
      "Epoch: 0137 train_loss= 0.69582 time= 0.29833\n",
      "val_roc= 0.59336 val_ap= 0.67664\n",
      "Epoch: 0138 train_loss= 0.69491 time= 0.33625\n",
      "val_roc= 0.59351 val_ap= 0.67666\n",
      "Epoch: 0139 train_loss= 0.69652 time= 0.33604\n",
      "val_roc= 0.59409 val_ap= 0.67665\n",
      "Epoch: 0140 train_loss= 0.69599 time= 0.31223\n",
      "val_roc= 0.59413 val_ap= 0.67663\n",
      "Epoch: 0141 train_loss= 0.69513 time= 0.26712\n",
      "val_roc= 0.59497 val_ap= 0.67710\n",
      "Epoch: 0142 train_loss= 0.69788 time= 0.34141\n",
      "val_roc= 0.59565 val_ap= 0.67742\n",
      "Epoch: 0143 train_loss= 0.69545 time= 0.32968\n",
      "val_roc= 0.59638 val_ap= 0.67767\n",
      "Epoch: 0144 train_loss= 0.69473 time= 0.42308\n",
      "val_roc= 0.59611 val_ap= 0.67752\n",
      "Epoch: 0145 train_loss= 0.69423 time= 0.32201\n",
      "val_roc= 0.59572 val_ap= 0.67719\n",
      "Epoch: 0146 train_loss= 0.69378 time= 0.36271\n",
      "val_roc= 0.59586 val_ap= 0.67744\n",
      "Epoch: 0147 train_loss= 0.69362 time= 0.33671\n",
      "val_roc= 0.59545 val_ap= 0.67736\n",
      "Epoch: 0148 train_loss= 0.69182 time= 0.33750\n",
      "val_roc= 0.59543 val_ap= 0.67726\n",
      "Epoch: 0149 train_loss= 0.69194 time= 0.33685\n",
      "val_roc= 0.59535 val_ap= 0.67706\n",
      "Epoch: 0150 train_loss= 0.69524 time= 0.33710\n",
      "val_roc= 0.59485 val_ap= 0.67677\n",
      "Epoch: 0151 train_loss= 0.69283 time= 0.32090\n",
      "val_roc= 0.59479 val_ap= 0.67677\n",
      "Epoch: 0152 train_loss= 0.69328 time= 0.33927\n",
      "val_roc= 0.59448 val_ap= 0.67679\n",
      "Epoch: 0153 train_loss= 0.69376 time= 0.31883\n",
      "val_roc= 0.59398 val_ap= 0.67684\n",
      "Epoch: 0154 train_loss= 0.69146 time= 0.29188\n",
      "val_roc= 0.59337 val_ap= 0.67655\n",
      "Epoch: 0155 train_loss= 0.69670 time= 0.33098\n",
      "val_roc= 0.59235 val_ap= 0.67614\n",
      "Epoch: 0156 train_loss= 0.69109 time= 0.35647\n",
      "val_roc= 0.59184 val_ap= 0.67600\n",
      "Epoch: 0157 train_loss= 0.69489 time= 0.29684\n",
      "val_roc= 0.59167 val_ap= 0.67585\n",
      "Epoch: 0158 train_loss= 0.69371 time= 0.33544\n",
      "val_roc= 0.59114 val_ap= 0.67554\n",
      "Epoch: 0159 train_loss= 0.68997 time= 0.32776\n",
      "val_roc= 0.59105 val_ap= 0.67558\n",
      "Epoch: 0160 train_loss= 0.69440 time= 0.28733\n",
      "val_roc= 0.59062 val_ap= 0.67537\n",
      "Epoch: 0161 train_loss= 0.69342 time= 0.33802\n",
      "val_roc= 0.58973 val_ap= 0.67511\n",
      "Epoch: 0162 train_loss= 0.69331 time= 0.30628\n",
      "val_roc= 0.58870 val_ap= 0.67495\n",
      "Epoch: 0163 train_loss= 0.69160 time= 0.38576\n",
      "val_roc= 0.58790 val_ap= 0.67467\n",
      "Epoch: 0164 train_loss= 0.69259 time= 0.37208\n",
      "val_roc= 0.58722 val_ap= 0.67448\n",
      "Epoch: 0165 train_loss= 0.69296 time= 0.32254\n",
      "val_roc= 0.58672 val_ap= 0.67439\n",
      "Epoch: 0166 train_loss= 0.69217 time= 0.43218\n",
      "val_roc= 0.58643 val_ap= 0.67459\n",
      "Epoch: 0167 train_loss= 0.69044 time= 0.38576\n",
      "val_roc= 0.58641 val_ap= 0.67439\n",
      "Epoch: 0168 train_loss= 0.69529 time= 0.32485\n",
      "val_roc= 0.58672 val_ap= 0.67467\n",
      "Epoch: 0169 train_loss= 0.68991 time= 0.35141\n",
      "val_roc= 0.58697 val_ap= 0.67484\n",
      "Epoch: 0170 train_loss= 0.68997 time= 0.35176\n",
      "val_roc= 0.58765 val_ap= 0.67510\n",
      "Epoch: 0171 train_loss= 0.69054 time= 0.36136\n",
      "val_roc= 0.58815 val_ap= 0.67512\n",
      "Epoch: 0172 train_loss= 0.68850 time= 0.34495\n",
      "val_roc= 0.58881 val_ap= 0.67538\n",
      "Epoch: 0173 train_loss= 0.69079 time= 0.34515\n",
      "val_roc= 0.58924 val_ap= 0.67553\n",
      "Epoch: 0174 train_loss= 0.69022 time= 0.38118\n",
      "val_roc= 0.58903 val_ap= 0.67537\n",
      "Epoch: 0175 train_loss= 0.68889 time= 0.34332\n",
      "val_roc= 0.58905 val_ap= 0.67536\n",
      "Epoch: 0176 train_loss= 0.69127 time= 0.33535\n",
      "val_roc= 0.58850 val_ap= 0.67511\n",
      "Epoch: 0177 train_loss= 0.69126 time= 0.28665\n",
      "val_roc= 0.58755 val_ap= 0.67473\n",
      "Epoch: 0178 train_loss= 0.69289 time= 0.32445\n",
      "val_roc= 0.58666 val_ap= 0.67461\n",
      "Epoch: 0179 train_loss= 0.68699 time= 0.35573\n",
      "val_roc= 0.58536 val_ap= 0.67416\n",
      "Epoch: 0180 train_loss= 0.68955 time= 0.33819\n",
      "val_roc= 0.58530 val_ap= 0.67424\n",
      "Epoch: 0181 train_loss= 0.68993 time= 0.42697\n",
      "val_roc= 0.58577 val_ap= 0.67438\n",
      "Epoch: 0182 train_loss= 0.69118 time= 0.37160\n",
      "val_roc= 0.58643 val_ap= 0.67470\n",
      "Epoch: 0183 train_loss= 0.69051 time= 0.33088\n",
      "val_roc= 0.58693 val_ap= 0.67462\n",
      "Epoch: 0184 train_loss= 0.69269 time= 0.34771\n",
      "val_roc= 0.58761 val_ap= 0.67471\n",
      "Epoch: 0185 train_loss= 0.69213 time= 0.87292\n",
      "val_roc= 0.58831 val_ap= 0.67508\n",
      "Epoch: 0186 train_loss= 0.69222 time= 1.28024\n",
      "val_roc= 0.58905 val_ap= 0.67530\n",
      "Epoch: 0187 train_loss= 0.68908 time= 1.68014\n",
      "val_roc= 0.58784 val_ap= 0.67483\n",
      "Epoch: 0188 train_loss= 0.69164 time= 1.67685\n",
      "val_roc= 0.58685 val_ap= 0.67445\n",
      "Epoch: 0189 train_loss= 0.69087 time= 2.43277\n",
      "val_roc= 0.58598 val_ap= 0.67430\n",
      "Epoch: 0190 train_loss= 0.68989 time= 1.81919\n",
      "val_roc= 0.58538 val_ap= 0.67399\n",
      "Epoch: 0191 train_loss= 0.69138 time= 2.71854\n",
      "val_roc= 0.58478 val_ap= 0.67386\n",
      "Epoch: 0192 train_loss= 0.69148 time= 1.70118\n",
      "val_roc= 0.58427 val_ap= 0.67352\n",
      "Epoch: 0193 train_loss= 0.69039 time= 2.44940\n",
      "val_roc= 0.58398 val_ap= 0.67349\n",
      "Epoch: 0194 train_loss= 0.69062 time= 2.35095\n",
      "val_roc= 0.58361 val_ap= 0.67323\n",
      "Epoch: 0195 train_loss= 0.68957 time= 0.38800\n",
      "val_roc= 0.58264 val_ap= 0.67286\n",
      "Epoch: 0196 train_loss= 0.69035 time= 0.38674\n",
      "val_roc= 0.58229 val_ap= 0.67271\n",
      "Epoch: 0197 train_loss= 0.69014 time= 0.39204\n",
      "val_roc= 0.58216 val_ap= 0.67270\n",
      "Epoch: 0198 train_loss= 0.69300 time= 0.41387\n",
      "val_roc= 0.58224 val_ap= 0.67250\n",
      "Epoch: 0199 train_loss= 0.69055 time= 0.36984\n",
      "val_roc= 0.58249 val_ap= 0.67263\n",
      "Epoch: 0200 train_loss= 0.69161 time= 0.41718\n",
      "val_roc= 0.58247 val_ap= 0.67274\n",
      "Testing model...\n",
      "Masking test edges...\n",
      "Preprocessing and Initializing...\n",
      "Training...\n",
      "Epoch: 0001 train_loss= 1.68022 time= 2.25206\n",
      "val_roc= 0.68720 val_ap= 0.70720\n",
      "Epoch: 0002 train_loss= 1.74508 time= 0.43731\n",
      "val_roc= 0.69776 val_ap= 0.72847\n",
      "Epoch: 0003 train_loss= 10.98258 time= 0.45723\n",
      "val_roc= 0.69984 val_ap= 0.72296\n",
      "Epoch: 0004 train_loss= 1.72801 time= 0.40538\n",
      "val_roc= 0.65894 val_ap= 0.66840\n",
      "Epoch: 0005 train_loss= 1.72982 time= 0.43151\n",
      "val_roc= 0.59919 val_ap= 0.57792\n",
      "Epoch: 0006 train_loss= 1.71397 time= 0.37959\n",
      "val_roc= 0.55947 val_ap= 0.54758\n",
      "Epoch: 0007 train_loss= 1.74474 time= 0.40810\n",
      "val_roc= 0.55286 val_ap= 0.54509\n",
      "Epoch: 0008 train_loss= 1.76508 time= 0.39665\n",
      "val_roc= 0.58383 val_ap= 0.56759\n",
      "Epoch: 0009 train_loss= 1.76347 time= 0.43111\n",
      "val_roc= 0.61495 val_ap= 0.58026\n",
      "Epoch: 0010 train_loss= 1.74657 time= 0.40657\n",
      "val_roc= 0.67979 val_ap= 0.66887\n",
      "Epoch: 0011 train_loss= 1.73777 time= 0.38304\n",
      "val_roc= 0.68961 val_ap= 0.69617\n",
      "Epoch: 0012 train_loss= 1.71135 time= 0.42431\n",
      "val_roc= 0.69194 val_ap= 0.70354\n",
      "Epoch: 0013 train_loss= 1.72093 time= 0.39697\n",
      "val_roc= 0.69244 val_ap= 0.70520\n",
      "Epoch: 0014 train_loss= 1.70464 time= 0.36423\n",
      "val_roc= 0.69245 val_ap= 0.70528\n",
      "Epoch: 0015 train_loss= 1.71093 time= 0.39449\n",
      "val_roc= 0.69328 val_ap= 0.70599\n",
      "Epoch: 0016 train_loss= 1.64281 time= 0.40032\n",
      "val_roc= 0.69441 val_ap= 0.70749\n",
      "Epoch: 0017 train_loss= 1.46231 time= 0.40560\n",
      "val_roc= 0.69536 val_ap= 0.70873\n",
      "Epoch: 0018 train_loss= 1.20814 time= 0.40139\n",
      "val_roc= 0.69825 val_ap= 0.71185\n",
      "Epoch: 0019 train_loss= 1.73410 time= 0.35949\n",
      "val_roc= 0.69864 val_ap= 0.71252\n",
      "Epoch: 0020 train_loss= 1.15322 time= 0.36025\n",
      "val_roc= 0.69961 val_ap= 0.71399\n",
      "Epoch: 0021 train_loss= 1.37858 time= 0.38478\n",
      "val_roc= 0.70153 val_ap= 0.71618\n",
      "Epoch: 0022 train_loss= 1.55408 time= 0.38688\n",
      "val_roc= 0.70330 val_ap= 0.71885\n",
      "Epoch: 0023 train_loss= 1.59321 time= 0.39093\n",
      "val_roc= 0.70521 val_ap= 0.72170\n",
      "Epoch: 0024 train_loss= 1.62228 time= 0.37769\n",
      "val_roc= 0.70660 val_ap= 0.72332\n",
      "Epoch: 0025 train_loss= 1.59940 time= 0.35510\n",
      "val_roc= 0.70834 val_ap= 0.72504\n",
      "Epoch: 0026 train_loss= 1.64426 time= 0.43340\n",
      "val_roc= 0.70963 val_ap= 0.72689\n",
      "Epoch: 0027 train_loss= 1.68113 time= 0.36346\n",
      "val_roc= 0.71112 val_ap= 0.72873\n",
      "Epoch: 0028 train_loss= 1.66777 time= 0.37765\n",
      "val_roc= 0.71247 val_ap= 0.73023\n",
      "Epoch: 0029 train_loss= 1.65743 time= 0.40394\n",
      "val_roc= 0.71331 val_ap= 0.73135\n",
      "Epoch: 0030 train_loss= 1.64698 time= 0.35553\n",
      "val_roc= 0.71406 val_ap= 0.73217\n",
      "Epoch: 0031 train_loss= 1.59981 time= 0.37855\n",
      "val_roc= 0.71459 val_ap= 0.73281\n",
      "Epoch: 0032 train_loss= 1.57802 time= 0.36154\n",
      "val_roc= 0.71498 val_ap= 0.73312\n",
      "Epoch: 0033 train_loss= 1.53112 time= 0.37101\n",
      "val_roc= 0.71542 val_ap= 0.73336\n",
      "Epoch: 0034 train_loss= 1.43071 time= 0.36606\n",
      "val_roc= 0.71531 val_ap= 0.73358\n",
      "Epoch: 0035 train_loss= 1.29261 time= 0.38352\n",
      "val_roc= 0.71534 val_ap= 0.73428\n",
      "Epoch: 0036 train_loss= 1.05185 time= 0.40950\n",
      "val_roc= 0.71600 val_ap= 0.73485\n",
      "Epoch: 0037 train_loss= 0.90070 time= 0.35402\n",
      "val_roc= 0.71622 val_ap= 0.73519\n",
      "Epoch: 0038 train_loss= 1.31433 time= 0.38400\n",
      "val_roc= 0.71715 val_ap= 0.73674\n",
      "Epoch: 0039 train_loss= 0.87283 time= 0.37684\n",
      "val_roc= 0.71829 val_ap= 0.73827\n",
      "Epoch: 0040 train_loss= 0.86266 time= 0.38088\n",
      "val_roc= 0.71864 val_ap= 0.73935\n",
      "Epoch: 0041 train_loss= 0.94052 time= 0.32701\n",
      "val_roc= 0.71907 val_ap= 0.74048\n",
      "Epoch: 0042 train_loss= 0.96521 time= 0.38635\n",
      "val_roc= 0.71981 val_ap= 0.74151\n",
      "Epoch: 0043 train_loss= 0.96308 time= 0.35022\n",
      "val_roc= 0.72041 val_ap= 0.74206\n",
      "Epoch: 0044 train_loss= 0.91559 time= 0.36581\n",
      "val_roc= 0.72031 val_ap= 0.74215\n",
      "Epoch: 0045 train_loss= 0.85026 time= 0.36493\n",
      "val_roc= 0.72064 val_ap= 0.74265\n",
      "Epoch: 0046 train_loss= 0.81472 time= 0.32753\n",
      "val_roc= 0.72088 val_ap= 0.74302\n",
      "Epoch: 0047 train_loss= 0.78815 time= 0.39763\n",
      "val_roc= 0.72078 val_ap= 0.74315\n",
      "Epoch: 0048 train_loss= 0.78619 time= 0.35936\n",
      "val_roc= 0.72107 val_ap= 0.74383\n",
      "Epoch: 0049 train_loss= 0.84274 time= 0.40507\n",
      "val_roc= 0.72119 val_ap= 0.74434\n",
      "Epoch: 0050 train_loss= 0.83694 time= 0.37663\n",
      "val_roc= 0.72208 val_ap= 0.74542\n",
      "Epoch: 0051 train_loss= 0.78245 time= 0.33660\n",
      "val_roc= 0.72202 val_ap= 0.74663\n",
      "Epoch: 0052 train_loss= 0.78122 time= 0.37924\n",
      "val_roc= 0.72224 val_ap= 0.74748\n",
      "Epoch: 0053 train_loss= 0.78039 time= 0.36365\n",
      "val_roc= 0.72299 val_ap= 0.74858\n",
      "Epoch: 0054 train_loss= 0.78377 time= 0.39035\n",
      "val_roc= 0.72326 val_ap= 0.74969\n",
      "Epoch: 0055 train_loss= 0.78144 time= 0.36124\n",
      "val_roc= 0.72295 val_ap= 0.74999\n",
      "Epoch: 0056 train_loss= 0.78394 time= 0.42669\n",
      "val_roc= 0.72287 val_ap= 0.75043\n",
      "Epoch: 0057 train_loss= 0.78107 time= 0.34221\n",
      "val_roc= 0.72264 val_ap= 0.75081\n",
      "Epoch: 0058 train_loss= 0.77386 time= 0.37985\n",
      "val_roc= 0.72229 val_ap= 0.75107\n",
      "Epoch: 0059 train_loss= 0.76487 time= 0.37452\n",
      "val_roc= 0.72190 val_ap= 0.75108\n",
      "Epoch: 0060 train_loss= 0.74939 time= 0.36213\n",
      "val_roc= 0.72171 val_ap= 0.75159\n",
      "Epoch: 0061 train_loss= 0.75587 time= 0.40822\n",
      "val_roc= 0.72181 val_ap= 0.75219\n",
      "Epoch: 0062 train_loss= 0.75829 time= 0.37398\n",
      "val_roc= 0.72187 val_ap= 0.75252\n",
      "Epoch: 0063 train_loss= 0.75644 time= 0.36682\n",
      "val_roc= 0.72190 val_ap= 0.75348\n",
      "Epoch: 0064 train_loss= 0.74992 time= 0.33695\n",
      "val_roc= 0.72150 val_ap= 0.75387\n",
      "Epoch: 0065 train_loss= 0.74331 time= 0.36776\n",
      "val_roc= 0.72105 val_ap= 0.75427\n",
      "Epoch: 0066 train_loss= 0.74562 time= 0.39835\n",
      "val_roc= 0.72039 val_ap= 0.75415\n",
      "Epoch: 0067 train_loss= 0.74804 time= 0.34388\n",
      "val_roc= 0.71936 val_ap= 0.75392\n",
      "Epoch: 0068 train_loss= 0.74233 time= 0.31461\n",
      "val_roc= 0.71866 val_ap= 0.75399\n",
      "Epoch: 0069 train_loss= 0.73489 time= 0.33771\n",
      "val_roc= 0.71858 val_ap= 0.75397\n",
      "Epoch: 0070 train_loss= 0.73474 time= 0.37991\n",
      "val_roc= 0.71769 val_ap= 0.75397\n",
      "Epoch: 0071 train_loss= 0.73520 time= 0.38456\n",
      "val_roc= 0.71715 val_ap= 0.75385\n",
      "Epoch: 0072 train_loss= 0.73596 time= 0.37996\n",
      "val_roc= 0.71663 val_ap= 0.75385\n",
      "Epoch: 0073 train_loss= 0.73435 time= 0.38486\n",
      "val_roc= 0.71552 val_ap= 0.75337\n",
      "Epoch: 0074 train_loss= 0.73168 time= 0.35660\n",
      "val_roc= 0.71488 val_ap= 0.75351\n",
      "Epoch: 0075 train_loss= 0.73132 time= 0.38735\n",
      "val_roc= 0.71377 val_ap= 0.75345\n",
      "Epoch: 0076 train_loss= 0.73027 time= 0.37014\n",
      "val_roc= 0.71305 val_ap= 0.75322\n",
      "Epoch: 0077 train_loss= 0.72673 time= 0.39101\n",
      "val_roc= 0.71243 val_ap= 0.75325\n",
      "Epoch: 0078 train_loss= 0.72584 time= 0.38757\n",
      "val_roc= 0.71172 val_ap= 0.75283\n",
      "Epoch: 0079 train_loss= 0.72551 time= 0.39250\n",
      "val_roc= 0.71057 val_ap= 0.75266\n",
      "Epoch: 0080 train_loss= 0.72741 time= 0.36436\n",
      "val_roc= 0.70962 val_ap= 0.75246\n",
      "Epoch: 0081 train_loss= 0.72342 time= 0.34502\n",
      "val_roc= 0.70867 val_ap= 0.75245\n",
      "Epoch: 0082 train_loss= 0.72399 time= 0.34342\n",
      "val_roc= 0.70818 val_ap= 0.75274\n",
      "Epoch: 0083 train_loss= 0.72654 time= 0.34172\n",
      "val_roc= 0.70696 val_ap= 0.75243\n",
      "Epoch: 0084 train_loss= 0.72341 time= 0.38048\n",
      "val_roc= 0.70523 val_ap= 0.75164\n",
      "Epoch: 0085 train_loss= 0.72192 time= 0.35478\n",
      "val_roc= 0.70389 val_ap= 0.75125\n",
      "Epoch: 0086 train_loss= 0.71986 time= 0.37620\n",
      "val_roc= 0.70254 val_ap= 0.75125\n",
      "Epoch: 0087 train_loss= 0.71691 time= 0.38316\n",
      "val_roc= 0.70112 val_ap= 0.75065\n",
      "Epoch: 0088 train_loss= 0.71821 time= 0.34617\n",
      "val_roc= 0.69937 val_ap= 0.74961\n",
      "Epoch: 0089 train_loss= 0.71288 time= 0.35511\n",
      "val_roc= 0.69792 val_ap= 0.74922\n",
      "Epoch: 0090 train_loss= 0.71296 time= 0.33102\n",
      "val_roc= 0.69613 val_ap= 0.74882\n",
      "Epoch: 0091 train_loss= 0.71711 time= 0.32953\n",
      "val_roc= 0.69425 val_ap= 0.74822\n",
      "Epoch: 0092 train_loss= 0.71447 time= 0.29982\n",
      "val_roc= 0.69208 val_ap= 0.74730\n",
      "Epoch: 0093 train_loss= 0.71435 time= 0.36447\n",
      "val_roc= 0.68800 val_ap= 0.74572\n",
      "Epoch: 0094 train_loss= 0.71547 time= 0.32918\n",
      "val_roc= 0.68490 val_ap= 0.74460\n",
      "Epoch: 0095 train_loss= 0.70989 time= 0.33659\n",
      "val_roc= 0.68245 val_ap= 0.74369\n",
      "Epoch: 0096 train_loss= 0.71195 time= 0.35165\n",
      "val_roc= 0.68039 val_ap= 0.74288\n",
      "Epoch: 0097 train_loss= 0.70999 time= 0.35646\n",
      "val_roc= 0.67636 val_ap= 0.74085\n",
      "Epoch: 0098 train_loss= 0.70808 time= 0.35064\n",
      "val_roc= 0.67308 val_ap= 0.73934\n",
      "Epoch: 0099 train_loss= 0.71100 time= 0.34751\n",
      "val_roc= 0.67077 val_ap= 0.73796\n",
      "Epoch: 0100 train_loss= 0.70768 time= 0.33764\n",
      "val_roc= 0.66801 val_ap= 0.73630\n",
      "Epoch: 0101 train_loss= 0.70613 time= 0.33686\n",
      "val_roc= 0.66502 val_ap= 0.73441\n",
      "Epoch: 0102 train_loss= 0.70383 time= 0.31064\n",
      "val_roc= 0.66289 val_ap= 0.73344\n",
      "Epoch: 0103 train_loss= 0.70517 time= 0.33212\n",
      "val_roc= 0.66052 val_ap= 0.73199\n",
      "Epoch: 0104 train_loss= 0.70512 time= 0.35126\n",
      "val_roc= 0.65747 val_ap= 0.73039\n",
      "Epoch: 0105 train_loss= 0.70323 time= 0.34783\n",
      "val_roc= 0.65484 val_ap= 0.72892\n",
      "Epoch: 0106 train_loss= 0.70406 time= 0.33475\n",
      "val_roc= 0.65418 val_ap= 0.72799\n",
      "Epoch: 0107 train_loss= 0.70365 time= 0.49295\n",
      "val_roc= 0.65371 val_ap= 0.72784\n",
      "Epoch: 0108 train_loss= 0.70217 time= 0.34329\n",
      "val_roc= 0.65332 val_ap= 0.72730\n",
      "Epoch: 0109 train_loss= 0.70290 time= 0.39319\n",
      "val_roc= 0.65454 val_ap= 0.72778\n",
      "Epoch: 0110 train_loss= 0.70539 time= 0.37371\n",
      "val_roc= 0.65625 val_ap= 0.72853\n",
      "Epoch: 0111 train_loss= 0.70254 time= 0.36446\n",
      "val_roc= 0.65505 val_ap= 0.72808\n",
      "Epoch: 0112 train_loss= 0.69772 time= 0.40905\n",
      "val_roc= 0.65286 val_ap= 0.72722\n",
      "Epoch: 0113 train_loss= 0.70094 time= 0.37332\n",
      "val_roc= 0.65288 val_ap= 0.72730\n",
      "Epoch: 0114 train_loss= 0.70325 time= 0.37514\n",
      "val_roc= 0.65381 val_ap= 0.72769\n",
      "Epoch: 0115 train_loss= 0.70225 time= 0.37723\n",
      "val_roc= 0.65394 val_ap= 0.72790\n",
      "Epoch: 0116 train_loss= 0.69876 time= 0.37788\n",
      "val_roc= 0.65245 val_ap= 0.72709\n",
      "Epoch: 0117 train_loss= 0.70137 time= 0.39673\n",
      "val_roc= 0.65264 val_ap= 0.72677\n",
      "Epoch: 0118 train_loss= 0.69902 time= 0.36838\n",
      "val_roc= 0.65272 val_ap= 0.72639\n",
      "Epoch: 0119 train_loss= 0.70017 time= 0.40172\n",
      "val_roc= 0.65369 val_ap= 0.72638\n",
      "Epoch: 0120 train_loss= 0.69891 time= 0.39565\n",
      "val_roc= 0.65324 val_ap= 0.72635\n",
      "Epoch: 0121 train_loss= 0.69923 time= 0.36117\n",
      "val_roc= 0.65119 val_ap= 0.72535\n",
      "Epoch: 0122 train_loss= 0.69966 time= 0.35030\n",
      "val_roc= 0.64971 val_ap= 0.72459\n",
      "Epoch: 0123 train_loss= 0.70261 time= 0.37294\n",
      "val_roc= 0.65016 val_ap= 0.72450\n",
      "Epoch: 0124 train_loss= 0.69953 time= 0.34697\n",
      "val_roc= 0.65035 val_ap= 0.72463\n",
      "Epoch: 0125 train_loss= 0.69594 time= 0.31696\n",
      "val_roc= 0.64872 val_ap= 0.72351\n",
      "Epoch: 0126 train_loss= 0.70115 time= 0.36661\n",
      "val_roc= 0.64744 val_ap= 0.72306\n",
      "Epoch: 0127 train_loss= 0.70357 time= 0.32837\n",
      "val_roc= 0.64732 val_ap= 0.72303\n",
      "Epoch: 0128 train_loss= 0.69823 time= 0.34388\n",
      "val_roc= 0.64765 val_ap= 0.72313\n",
      "Epoch: 0129 train_loss= 0.69536 time= 0.38289\n",
      "val_roc= 0.64709 val_ap= 0.72267\n",
      "Epoch: 0130 train_loss= 0.69848 time= 0.36980\n",
      "val_roc= 0.64616 val_ap= 0.72215\n",
      "Epoch: 0131 train_loss= 0.69888 time= 0.39990\n",
      "val_roc= 0.64560 val_ap= 0.72189\n",
      "Epoch: 0132 train_loss= 0.69728 time= 0.38506\n",
      "val_roc= 0.64488 val_ap= 0.72116\n",
      "Epoch: 0133 train_loss= 0.69887 time= 0.33520\n",
      "val_roc= 0.64428 val_ap= 0.72108\n",
      "Epoch: 0134 train_loss= 0.69732 time= 0.37588\n",
      "val_roc= 0.64482 val_ap= 0.72113\n",
      "Epoch: 0135 train_loss= 0.69964 time= 0.38397\n",
      "val_roc= 0.64536 val_ap= 0.72113\n",
      "Epoch: 0136 train_loss= 0.69888 time= 0.40690\n",
      "val_roc= 0.64564 val_ap= 0.72119\n",
      "Epoch: 0137 train_loss= 0.69709 time= 0.38009\n",
      "val_roc= 0.64469 val_ap= 0.72075\n",
      "Epoch: 0138 train_loss= 0.69687 time= 0.33942\n",
      "val_roc= 0.64323 val_ap= 0.72013\n",
      "Epoch: 0139 train_loss= 0.69816 time= 0.36764\n",
      "val_roc= 0.64263 val_ap= 0.71976\n",
      "Epoch: 0140 train_loss= 0.69873 time= 0.30781\n",
      "val_roc= 0.64381 val_ap= 0.71998\n",
      "Epoch: 0141 train_loss= 0.69861 time= 0.37327\n",
      "val_roc= 0.64426 val_ap= 0.71995\n",
      "Epoch: 0142 train_loss= 0.69802 time= 0.38582\n",
      "val_roc= 0.64436 val_ap= 0.71991\n",
      "Epoch: 0143 train_loss= 0.69775 time= 0.36920\n",
      "val_roc= 0.64467 val_ap= 0.71992\n",
      "Epoch: 0144 train_loss= 0.69750 time= 0.35302\n",
      "val_roc= 0.64417 val_ap= 0.71964\n",
      "Epoch: 0145 train_loss= 0.69781 time= 0.37356\n",
      "val_roc= 0.64366 val_ap= 0.71929\n",
      "Epoch: 0146 train_loss= 0.69504 time= 0.37851\n",
      "val_roc= 0.64224 val_ap= 0.71879\n",
      "Epoch: 0147 train_loss= 0.69676 time= 0.33428\n",
      "val_roc= 0.64185 val_ap= 0.71871\n",
      "Epoch: 0148 train_loss= 0.69540 time= 0.34143\n",
      "val_roc= 0.64160 val_ap= 0.71856\n",
      "Epoch: 0149 train_loss= 0.69550 time= 0.34405\n",
      "val_roc= 0.64158 val_ap= 0.71879\n",
      "Epoch: 0150 train_loss= 0.69599 time= 0.33872\n",
      "val_roc= 0.64152 val_ap= 0.71874\n",
      "Epoch: 0151 train_loss= 0.70006 time= 0.40746\n",
      "val_roc= 0.64325 val_ap= 0.71950\n",
      "Epoch: 0152 train_loss= 0.69379 time= 0.41146\n",
      "val_roc= 0.64238 val_ap= 0.71897\n",
      "Epoch: 0153 train_loss= 0.69517 time= 0.36351\n",
      "val_roc= 0.64055 val_ap= 0.71826\n",
      "Epoch: 0154 train_loss= 0.69745 time= 0.37785\n",
      "val_roc= 0.63993 val_ap= 0.71835\n",
      "Epoch: 0155 train_loss= 0.69189 time= 0.36308\n",
      "val_roc= 0.63954 val_ap= 0.71817\n",
      "Epoch: 0156 train_loss= 0.69505 time= 0.33834\n",
      "val_roc= 0.63958 val_ap= 0.71799\n",
      "Epoch: 0157 train_loss= 0.69476 time= 0.37021\n",
      "val_roc= 0.64144 val_ap= 0.71894\n",
      "Epoch: 0158 train_loss= 0.69362 time= 0.38782\n",
      "val_roc= 0.64251 val_ap= 0.71939\n",
      "Epoch: 0159 train_loss= 0.69434 time= 0.38673\n",
      "val_roc= 0.64317 val_ap= 0.71961\n",
      "Epoch: 0160 train_loss= 0.69501 time= 0.35253\n",
      "val_roc= 0.64340 val_ap= 0.71976\n",
      "Epoch: 0161 train_loss= 0.69428 time= 0.41983\n",
      "val_roc= 0.64360 val_ap= 0.71993\n",
      "Epoch: 0162 train_loss= 0.69437 time= 0.36722\n",
      "val_roc= 0.64370 val_ap= 0.72010\n",
      "Epoch: 0163 train_loss= 0.69439 time= 0.38076\n",
      "val_roc= 0.64393 val_ap= 0.72019\n",
      "Epoch: 0164 train_loss= 0.69417 time= 0.38741\n",
      "val_roc= 0.64432 val_ap= 0.72052\n",
      "Epoch: 0165 train_loss= 0.69711 time= 0.39957\n",
      "val_roc= 0.64571 val_ap= 0.72124\n",
      "Epoch: 0166 train_loss= 0.69453 time= 0.32590\n",
      "val_roc= 0.64564 val_ap= 0.72128\n",
      "Epoch: 0167 train_loss= 0.69413 time= 0.37942\n",
      "val_roc= 0.64449 val_ap= 0.72089\n",
      "Epoch: 0168 train_loss= 0.69607 time= 0.35043\n",
      "val_roc= 0.64368 val_ap= 0.72063\n",
      "Epoch: 0169 train_loss= 0.69346 time= 0.34393\n",
      "val_roc= 0.64296 val_ap= 0.72080\n",
      "Epoch: 0170 train_loss= 0.69322 time= 0.40332\n",
      "val_roc= 0.64232 val_ap= 0.72023\n",
      "Epoch: 0171 train_loss= 0.69438 time= 0.38063\n",
      "val_roc= 0.64379 val_ap= 0.72099\n",
      "Epoch: 0172 train_loss= 0.69343 time= 0.38045\n",
      "val_roc= 0.64503 val_ap= 0.72138\n",
      "Epoch: 0173 train_loss= 0.69182 time= 0.35290\n",
      "val_roc= 0.64569 val_ap= 0.72149\n",
      "Epoch: 0174 train_loss= 0.69169 time= 0.35754\n",
      "val_roc= 0.64585 val_ap= 0.72132\n",
      "Epoch: 0175 train_loss= 0.69445 time= 0.37915\n",
      "val_roc= 0.64637 val_ap= 0.72160\n",
      "Epoch: 0176 train_loss= 0.69097 time= 0.37481\n",
      "val_roc= 0.64637 val_ap= 0.72094\n",
      "Epoch: 0177 train_loss= 0.69282 time= 0.39179\n",
      "val_roc= 0.64721 val_ap= 0.72151\n",
      "Epoch: 0178 train_loss= 0.69233 time= 0.35795\n",
      "val_roc= 0.64793 val_ap= 0.72172\n",
      "Epoch: 0179 train_loss= 0.69257 time= 0.34669\n",
      "val_roc= 0.64744 val_ap= 0.72109\n",
      "Epoch: 0180 train_loss= 0.69226 time= 0.35633\n",
      "val_roc= 0.64575 val_ap= 0.72048\n",
      "Epoch: 0181 train_loss= 0.68971 time= 0.38947\n",
      "val_roc= 0.64430 val_ap= 0.71983\n",
      "Epoch: 0182 train_loss= 0.69302 time= 0.36053\n",
      "val_roc= 0.64426 val_ap= 0.71992\n",
      "Epoch: 0183 train_loss= 0.68950 time= 0.35044\n",
      "val_roc= 0.64387 val_ap= 0.71973\n",
      "Epoch: 0184 train_loss= 0.69022 time= 0.32954\n",
      "val_roc= 0.64346 val_ap= 0.71933\n",
      "Epoch: 0185 train_loss= 0.69273 time= 0.38013\n",
      "val_roc= 0.64197 val_ap= 0.71866\n",
      "Epoch: 0186 train_loss= 0.68912 time= 0.32746\n",
      "val_roc= 0.64131 val_ap= 0.71826\n",
      "Epoch: 0187 train_loss= 0.69258 time= 0.36925\n",
      "val_roc= 0.64051 val_ap= 0.71815\n",
      "Epoch: 0188 train_loss= 0.69171 time= 0.38027\n",
      "val_roc= 0.64051 val_ap= 0.71819\n",
      "Epoch: 0189 train_loss= 0.69172 time= 0.35244\n",
      "val_roc= 0.64108 val_ap= 0.71872\n",
      "Epoch: 0190 train_loss= 0.69426 time= 0.37221\n",
      "val_roc= 0.64102 val_ap= 0.71867\n",
      "Epoch: 0191 train_loss= 0.68912 time= 0.35939\n",
      "val_roc= 0.64061 val_ap= 0.71876\n",
      "Epoch: 0192 train_loss= 0.69298 time= 0.37818\n",
      "val_roc= 0.64067 val_ap= 0.71859\n",
      "Epoch: 0193 train_loss= 0.69346 time= 0.39024\n",
      "val_roc= 0.64131 val_ap= 0.71876\n",
      "Epoch: 0194 train_loss= 0.69149 time= 0.32031\n",
      "val_roc= 0.64176 val_ap= 0.71894\n",
      "Epoch: 0195 train_loss= 0.69040 time= 0.36878\n",
      "val_roc= 0.64240 val_ap= 0.71923\n",
      "Epoch: 0196 train_loss= 0.69600 time= 0.31492\n",
      "val_roc= 0.64193 val_ap= 0.71894\n",
      "Epoch: 0197 train_loss= 0.69323 time= 0.32054\n",
      "val_roc= 0.64195 val_ap= 0.71899\n",
      "Epoch: 0198 train_loss= 0.69490 time= 0.37888\n",
      "val_roc= 0.64197 val_ap= 0.71904\n",
      "Epoch: 0199 train_loss= 0.69330 time= 0.37151\n",
      "val_roc= 0.64181 val_ap= 0.71894\n",
      "Epoch: 0200 train_loss= 0.69270 time= 0.39022\n",
      "val_roc= 0.64111 val_ap= 0.71853\n",
      "Testing model...\n",
      "Masking test edges...\n",
      "Preprocessing and Initializing...\n",
      "Training...\n",
      "Epoch: 0001 train_loss= 1.74607 time= 2.53755\n",
      "val_roc= 0.65861 val_ap= 0.67892\n",
      "Epoch: 0002 train_loss= 1.72103 time= 0.40062\n",
      "val_roc= 0.67553 val_ap= 0.70994\n",
      "Epoch: 0003 train_loss= 1.62047 time= 0.33701\n",
      "val_roc= 0.50000 val_ap= 0.50000\n",
      "Epoch: 0004 train_loss= 8826591232.00000 time= 0.37413\n",
      "val_roc= 0.67957 val_ap= 0.71220\n",
      "Epoch: 0005 train_loss= 1.45805 time= 0.37751\n",
      "val_roc= 0.67761 val_ap= 0.71634\n",
      "Epoch: 0006 train_loss= 1.71312 time= 0.41143\n",
      "val_roc= 0.68904 val_ap= 0.72707\n",
      "Epoch: 0007 train_loss= 1.73979 time= 0.38255\n",
      "val_roc= 0.70166 val_ap= 0.70463\n",
      "Epoch: 0008 train_loss= 1.68355 time= 0.37078\n",
      "val_roc= 0.60339 val_ap= 0.58348\n",
      "Epoch: 0009 train_loss= 1.74120 time= 0.39936\n",
      "val_roc= 0.63717 val_ap= 0.60463\n",
      "Epoch: 0010 train_loss= 1.71136 time= 0.39282\n",
      "val_roc= 0.59471 val_ap= 0.57380\n",
      "Epoch: 0011 train_loss= 1.74342 time= 0.36425\n",
      "val_roc= 0.63720 val_ap= 0.60363\n",
      "Epoch: 0012 train_loss= 1.71390 time= 0.33790\n",
      "val_roc= 0.61219 val_ap= 0.58578\n",
      "Epoch: 0013 train_loss= 1.70567 time= 0.35248\n",
      "val_roc= 0.66366 val_ap= 0.64801\n",
      "Epoch: 0014 train_loss= 1.71094 time= 0.31182\n",
      "val_roc= 0.69388 val_ap= 0.68884\n",
      "Epoch: 0015 train_loss= 1.73490 time= 0.33155\n",
      "val_roc= 0.69717 val_ap= 0.70963\n",
      "Epoch: 0016 train_loss= 1.70706 time= 0.31050\n",
      "val_roc= 0.69933 val_ap= 0.71621\n",
      "Epoch: 0017 train_loss= 1.72173 time= 0.34652\n",
      "val_roc= 0.69739 val_ap= 0.71640\n",
      "Epoch: 0018 train_loss= 1.71219 time= 0.32791\n",
      "val_roc= 0.69557 val_ap= 0.71488\n",
      "Epoch: 0019 train_loss= 1.71240 time= 0.32391\n",
      "val_roc= 0.69400 val_ap= 0.71205\n",
      "Epoch: 0020 train_loss= 1.70738 time= 0.33730\n",
      "val_roc= 0.69190 val_ap= 0.70980\n",
      "Epoch: 0021 train_loss= 1.66492 time= 0.38869\n",
      "val_roc= 0.68912 val_ap= 0.70720\n",
      "Epoch: 0022 train_loss= 1.51367 time= 0.36817\n",
      "val_roc= 0.68601 val_ap= 0.70440\n",
      "Epoch: 0023 train_loss= 1.27982 time= 0.35925\n",
      "val_roc= 0.68374 val_ap= 0.70267\n",
      "Epoch: 0024 train_loss= 3.17671 time= 0.34001\n",
      "val_roc= 0.68527 val_ap= 0.70372\n",
      "Epoch: 0025 train_loss= 1.21752 time= 0.31953\n",
      "val_roc= 0.68741 val_ap= 0.70569\n",
      "Epoch: 0026 train_loss= 1.32216 time= 0.38029\n",
      "val_roc= 0.68892 val_ap= 0.70723\n",
      "Epoch: 0027 train_loss= 1.48836 time= 0.35402\n",
      "val_roc= 0.69039 val_ap= 0.70866\n",
      "Epoch: 0028 train_loss= 1.56560 time= 0.34370\n",
      "val_roc= 0.69174 val_ap= 0.70994\n",
      "Epoch: 0029 train_loss= 1.66384 time= 0.34090\n",
      "val_roc= 0.69308 val_ap= 0.71133\n",
      "Epoch: 0030 train_loss= 1.64714 time= 0.33930\n",
      "val_roc= 0.69412 val_ap= 0.71258\n",
      "Epoch: 0031 train_loss= 1.64949 time= 0.34911\n",
      "val_roc= 0.69486 val_ap= 0.71361\n",
      "Epoch: 0032 train_loss= 1.72468 time= 0.34561\n",
      "val_roc= 0.69550 val_ap= 0.71427\n",
      "Epoch: 0033 train_loss= 1.69765 time= 0.34725\n",
      "val_roc= 0.69598 val_ap= 0.71538\n",
      "Epoch: 0034 train_loss= 1.71504 time= 0.41412\n",
      "val_roc= 0.69615 val_ap= 0.71605\n",
      "Epoch: 0035 train_loss= 1.71808 time= 0.34731\n",
      "val_roc= 0.69663 val_ap= 0.71685\n",
      "Epoch: 0036 train_loss= 1.72467 time= 0.36340\n",
      "val_roc= 0.69717 val_ap= 0.71804\n",
      "Epoch: 0037 train_loss= 1.71183 time= 0.42228\n",
      "val_roc= 0.69766 val_ap= 0.71913\n",
      "Epoch: 0038 train_loss= 1.72948 time= 0.32620\n",
      "val_roc= 0.69769 val_ap= 0.71959\n",
      "Epoch: 0039 train_loss= 1.71655 time= 0.33802\n",
      "val_roc= 0.69800 val_ap= 0.72025\n",
      "Epoch: 0040 train_loss= 1.72322 time= 0.38156\n",
      "val_roc= 0.69820 val_ap= 0.72033\n",
      "Epoch: 0041 train_loss= 1.74996 time= 0.31969\n",
      "val_roc= 0.69819 val_ap= 0.72041\n",
      "Epoch: 0042 train_loss= 1.67009 time= 0.37395\n",
      "val_roc= 0.69849 val_ap= 0.72061\n",
      "Epoch: 0043 train_loss= 1.68619 time= 0.38164\n",
      "val_roc= 0.69836 val_ap= 0.72102\n",
      "Epoch: 0044 train_loss= 1.71368 time= 0.38337\n",
      "val_roc= 0.69911 val_ap= 0.72162\n",
      "Epoch: 0045 train_loss= 1.72503 time= 0.38431\n",
      "val_roc= 0.69914 val_ap= 0.72174\n",
      "Epoch: 0046 train_loss= 1.70890 time= 0.29778\n",
      "val_roc= 0.69904 val_ap= 0.72132\n",
      "Epoch: 0047 train_loss= 1.71906 time= 0.36991\n",
      "val_roc= 0.69879 val_ap= 0.72107\n",
      "Epoch: 0048 train_loss= 1.73280 time= 0.36330\n",
      "val_roc= 0.69904 val_ap= 0.72098\n",
      "Epoch: 0049 train_loss= 1.73565 time= 0.37154\n",
      "val_roc= 0.69865 val_ap= 0.72047\n",
      "Epoch: 0050 train_loss= 1.74634 time= 0.41248\n",
      "val_roc= 0.69879 val_ap= 0.72100\n",
      "Epoch: 0051 train_loss= 1.70695 time= 0.40049\n",
      "val_roc= 0.69842 val_ap= 0.72074\n",
      "Epoch: 0052 train_loss= 1.75652 time= 0.36644\n",
      "val_roc= 0.69827 val_ap= 0.72080\n",
      "Epoch: 0053 train_loss= 1.72806 time= 0.40178\n",
      "val_roc= 0.69843 val_ap= 0.72110\n",
      "Epoch: 0054 train_loss= 1.69850 time= 0.43656\n",
      "val_roc= 0.69823 val_ap= 0.72108\n",
      "Epoch: 0055 train_loss= 1.75318 time= 0.36508\n",
      "val_roc= 0.69774 val_ap= 0.72082\n",
      "Epoch: 0056 train_loss= 1.69095 time= 0.33851\n",
      "val_roc= 0.69761 val_ap= 0.72096\n",
      "Epoch: 0057 train_loss= 1.72994 time= 0.43651\n",
      "val_roc= 0.69688 val_ap= 0.72069\n",
      "Epoch: 0058 train_loss= 1.70609 time= 0.37156\n",
      "val_roc= 0.69627 val_ap= 0.72063\n",
      "Epoch: 0059 train_loss= 1.71479 time= 0.36593\n",
      "val_roc= 0.69566 val_ap= 0.72050\n",
      "Epoch: 0060 train_loss= 1.70398 time= 0.32251\n",
      "val_roc= 0.69506 val_ap= 0.72035\n",
      "Epoch: 0061 train_loss= 1.70831 time= 0.37580\n",
      "val_roc= 0.69478 val_ap= 0.72019\n",
      "Epoch: 0062 train_loss= 1.70793 time= 0.38888\n",
      "val_roc= 0.69452 val_ap= 0.72007\n",
      "Epoch: 0063 train_loss= 1.70645 time= 0.37609\n",
      "val_roc= 0.69440 val_ap= 0.72007\n",
      "Epoch: 0064 train_loss= 1.69060 time= 0.40252\n",
      "val_roc= 0.69411 val_ap= 0.71980\n",
      "Epoch: 0065 train_loss= 1.69539 time= 0.36107\n",
      "val_roc= 0.69392 val_ap= 0.71971\n",
      "Epoch: 0066 train_loss= 1.63289 time= 0.35720\n",
      "val_roc= 0.69398 val_ap= 0.71953\n",
      "Epoch: 0067 train_loss= 1.54427 time= 0.38967\n",
      "val_roc= 0.69366 val_ap= 0.71943\n",
      "Epoch: 0068 train_loss= 1.50062 time= 0.39090\n",
      "val_roc= 0.69375 val_ap= 0.71942\n",
      "Epoch: 0069 train_loss= 1.37151 time= 0.37423\n",
      "val_roc= 0.69377 val_ap= 0.71921\n",
      "Epoch: 0070 train_loss= 1.20830 time= 0.37303\n",
      "val_roc= 0.69391 val_ap= 0.71972\n",
      "Epoch: 0071 train_loss= 0.95100 time= 0.39754\n",
      "val_roc= 0.69416 val_ap= 0.71965\n",
      "Epoch: 0072 train_loss= 0.86857 time= 0.36405\n",
      "val_roc= 0.69436 val_ap= 0.71988\n",
      "Epoch: 0073 train_loss= 1.20692 time= 0.35811\n",
      "val_roc= 0.69436 val_ap= 0.71981\n",
      "Epoch: 0074 train_loss= 0.85336 time= 0.38116\n",
      "val_roc= 0.69440 val_ap= 0.72023\n",
      "Epoch: 0075 train_loss= 0.81711 time= 0.37671\n",
      "val_roc= 0.69443 val_ap= 0.72034\n",
      "Epoch: 0076 train_loss= 0.88805 time= 0.37705\n",
      "val_roc= 0.69461 val_ap= 0.72061\n",
      "Epoch: 0077 train_loss= 0.92633 time= 0.37930\n",
      "val_roc= 0.69490 val_ap= 0.72114\n",
      "Epoch: 0078 train_loss= 0.93499 time= 0.38543\n",
      "val_roc= 0.69515 val_ap= 0.72134\n",
      "Epoch: 0079 train_loss= 0.91746 time= 0.37818\n",
      "val_roc= 0.69507 val_ap= 0.72132\n",
      "Epoch: 0080 train_loss= 0.85680 time= 0.37987\n",
      "val_roc= 0.69529 val_ap= 0.72168\n",
      "Epoch: 0081 train_loss= 0.79475 time= 0.37267\n",
      "val_roc= 0.69507 val_ap= 0.72178\n",
      "Epoch: 0082 train_loss= 0.75876 time= 0.38601\n",
      "val_roc= 0.69540 val_ap= 0.72179\n",
      "Epoch: 0083 train_loss= 0.74872 time= 0.37775\n",
      "val_roc= 0.69558 val_ap= 0.72215\n",
      "Epoch: 0084 train_loss= 0.77398 time= 0.35848\n",
      "val_roc= 0.69577 val_ap= 0.72232\n",
      "Epoch: 0085 train_loss= 0.79612 time= 0.38829\n",
      "val_roc= 0.69564 val_ap= 0.72228\n",
      "Epoch: 0086 train_loss= 0.79584 time= 0.37195\n",
      "val_roc= 0.69589 val_ap= 0.72287\n",
      "Epoch: 0087 train_loss= 0.77868 time= 0.36252\n",
      "val_roc= 0.69595 val_ap= 0.72288\n",
      "Epoch: 0088 train_loss= 0.76472 time= 0.40318\n",
      "val_roc= 0.69610 val_ap= 0.72328\n",
      "Epoch: 0089 train_loss= 0.76141 time= 0.31593\n",
      "val_roc= 0.69637 val_ap= 0.72371\n",
      "Epoch: 0090 train_loss= 0.76178 time= 0.38475\n",
      "val_roc= 0.69637 val_ap= 0.72384\n",
      "Epoch: 0091 train_loss= 0.75943 time= 0.37678\n",
      "val_roc= 0.69663 val_ap= 0.72415\n",
      "Epoch: 0092 train_loss= 0.75746 time= 0.36588\n",
      "val_roc= 0.69684 val_ap= 0.72443\n",
      "Epoch: 0093 train_loss= 0.75548 time= 0.34417\n",
      "val_roc= 0.69686 val_ap= 0.72459\n",
      "Epoch: 0094 train_loss= 0.75918 time= 0.37397\n",
      "val_roc= 0.69686 val_ap= 0.72459\n",
      "Epoch: 0095 train_loss= 0.76146 time= 0.31663\n",
      "val_roc= 0.69694 val_ap= 0.72476\n",
      "Epoch: 0096 train_loss= 0.75973 time= 0.37933\n",
      "val_roc= 0.69682 val_ap= 0.72461\n",
      "Epoch: 0097 train_loss= 0.76027 time= 0.33616\n",
      "val_roc= 0.69678 val_ap= 0.72475\n",
      "Epoch: 0098 train_loss= 0.75903 time= 0.38950\n",
      "val_roc= 0.69655 val_ap= 0.72496\n",
      "Epoch: 0099 train_loss= 0.76325 time= 0.38036\n",
      "val_roc= 0.69667 val_ap= 0.72515\n",
      "Epoch: 0100 train_loss= 0.75724 time= 0.37289\n",
      "val_roc= 0.69688 val_ap= 0.72526\n",
      "Epoch: 0101 train_loss= 0.75289 time= 0.36984\n",
      "val_roc= 0.69705 val_ap= 0.72549\n",
      "Epoch: 0102 train_loss= 0.75285 time= 0.31658\n",
      "val_roc= 0.69731 val_ap= 0.72575\n",
      "Epoch: 0103 train_loss= 0.74721 time= 0.34759\n",
      "val_roc= 0.69740 val_ap= 0.72599\n",
      "Epoch: 0104 train_loss= 0.74693 time= 0.39992\n",
      "val_roc= 0.69787 val_ap= 0.72641\n",
      "Epoch: 0105 train_loss= 0.74619 time= 0.35137\n",
      "val_roc= 0.69795 val_ap= 0.72648\n",
      "Epoch: 0106 train_loss= 0.74502 time= 0.36434\n",
      "val_roc= 0.69766 val_ap= 0.72656\n",
      "Epoch: 0107 train_loss= 0.74699 time= 0.32678\n",
      "val_roc= 0.69750 val_ap= 0.72666\n",
      "Epoch: 0108 train_loss= 0.74668 time= 0.35587\n",
      "val_roc= 0.69744 val_ap= 0.72695\n",
      "Epoch: 0109 train_loss= 0.74450 time= 0.36581\n",
      "val_roc= 0.69754 val_ap= 0.72721\n",
      "Epoch: 0110 train_loss= 0.74333 time= 0.38815\n",
      "val_roc= 0.69738 val_ap= 0.72747\n",
      "Epoch: 0111 train_loss= 0.74387 time= 0.36515\n",
      "val_roc= 0.69713 val_ap= 0.72744\n",
      "Epoch: 0112 train_loss= 0.73788 time= 0.39555\n",
      "val_roc= 0.69738 val_ap= 0.72783\n",
      "Epoch: 0113 train_loss= 0.73884 time= 0.38479\n",
      "val_roc= 0.69793 val_ap= 0.72856\n",
      "Epoch: 0114 train_loss= 0.74379 time= 0.38489\n",
      "val_roc= 0.69768 val_ap= 0.72866\n",
      "Epoch: 0115 train_loss= 0.73983 time= 0.36596\n",
      "val_roc= 0.69750 val_ap= 0.72882\n",
      "Epoch: 0116 train_loss= 0.73961 time= 0.32774\n",
      "val_roc= 0.69779 val_ap= 0.72948\n",
      "Epoch: 0117 train_loss= 0.73728 time= 0.39964\n",
      "val_roc= 0.69789 val_ap= 0.72952\n",
      "Epoch: 0118 train_loss= 0.73838 time= 0.37143\n",
      "val_roc= 0.69779 val_ap= 0.72955\n",
      "Epoch: 0119 train_loss= 0.73635 time= 0.37350\n",
      "val_roc= 0.69795 val_ap= 0.72988\n",
      "Epoch: 0120 train_loss= 0.73840 time= 0.38656\n",
      "val_roc= 0.69820 val_ap= 0.73046\n",
      "Epoch: 0121 train_loss= 0.73851 time= 0.39686\n",
      "val_roc= 0.69826 val_ap= 0.73070\n",
      "Epoch: 0122 train_loss= 0.73644 time= 0.37548\n",
      "val_roc= 0.69814 val_ap= 0.73089\n",
      "Epoch: 0123 train_loss= 0.73639 time= 0.36793\n",
      "val_roc= 0.69806 val_ap= 0.73123\n",
      "Epoch: 0124 train_loss= 0.73384 time= 0.39059\n",
      "val_roc= 0.69804 val_ap= 0.73172\n",
      "Epoch: 0125 train_loss= 0.73686 time= 0.37225\n",
      "val_roc= 0.69816 val_ap= 0.73185\n",
      "Epoch: 0126 train_loss= 0.73274 time= 0.36474\n",
      "val_roc= 0.69849 val_ap= 0.73228\n",
      "Epoch: 0127 train_loss= 0.73656 time= 0.38540\n",
      "val_roc= 0.69905 val_ap= 0.73319\n",
      "Epoch: 0128 train_loss= 0.73142 time= 0.33663\n",
      "val_roc= 0.69973 val_ap= 0.73385\n",
      "Epoch: 0129 train_loss= 0.73586 time= 0.34230\n",
      "val_roc= 0.69998 val_ap= 0.73452\n",
      "Epoch: 0130 train_loss= 0.72972 time= 0.31280\n",
      "val_roc= 0.70068 val_ap= 0.73568\n",
      "Epoch: 0131 train_loss= 0.73182 time= 0.36760\n",
      "val_roc= 0.70090 val_ap= 0.73649\n",
      "Epoch: 0132 train_loss= 0.73238 time= 0.50241\n",
      "val_roc= 0.70146 val_ap= 0.73797\n",
      "Epoch: 0133 train_loss= 0.72992 time= 0.38464\n",
      "val_roc= 0.70208 val_ap= 0.73881\n",
      "Epoch: 0134 train_loss= 0.72780 time= 0.60424\n",
      "val_roc= 0.70266 val_ap= 0.73947\n",
      "Epoch: 0135 train_loss= 0.73095 time= 0.37406\n",
      "val_roc= 0.70332 val_ap= 0.74063\n",
      "Epoch: 0136 train_loss= 0.73108 time= 0.42193\n",
      "val_roc= 0.70456 val_ap= 0.74242\n",
      "Epoch: 0137 train_loss= 0.73014 time= 0.46317\n",
      "val_roc= 0.70573 val_ap= 0.74383\n",
      "Epoch: 0138 train_loss= 0.72646 time= 0.37343\n",
      "val_roc= 0.70676 val_ap= 0.74549\n",
      "Epoch: 0139 train_loss= 0.72942 time= 0.48163\n",
      "val_roc= 0.70713 val_ap= 0.74647\n",
      "Epoch: 0140 train_loss= 0.72758 time= 0.37676\n",
      "val_roc= 0.70759 val_ap= 0.74746\n",
      "Epoch: 0141 train_loss= 0.72813 time= 0.36356\n",
      "val_roc= 0.70819 val_ap= 0.74821\n",
      "Epoch: 0142 train_loss= 0.72647 time= 0.50603\n",
      "val_roc= 0.70901 val_ap= 0.74941\n",
      "Epoch: 0143 train_loss= 0.72197 time= 0.39550\n",
      "val_roc= 0.70951 val_ap= 0.75070\n",
      "Epoch: 0144 train_loss= 0.72720 time= 0.53065\n",
      "val_roc= 0.70949 val_ap= 0.75202\n",
      "Epoch: 0145 train_loss= 0.72389 time= 0.33119\n",
      "val_roc= 0.70930 val_ap= 0.75285\n",
      "Epoch: 0146 train_loss= 0.72528 time= 0.35102\n",
      "val_roc= 0.70911 val_ap= 0.75407\n",
      "Epoch: 0147 train_loss= 0.72511 time= 0.45399\n",
      "val_roc= 0.70802 val_ap= 0.75485\n",
      "Epoch: 0148 train_loss= 0.72081 time= 0.37695\n",
      "val_roc= 0.70625 val_ap= 0.75521\n",
      "Epoch: 0149 train_loss= 0.71938 time= 0.44855\n",
      "val_roc= 0.70519 val_ap= 0.75622\n",
      "Epoch: 0150 train_loss= 0.71901 time= 0.45693\n",
      "val_roc= 0.70470 val_ap= 0.75715\n",
      "Epoch: 0151 train_loss= 0.71962 time= 0.37038\n",
      "val_roc= 0.70379 val_ap= 0.75735\n",
      "Epoch: 0152 train_loss= 0.71745 time= 0.49603\n",
      "val_roc= 0.70365 val_ap= 0.75804\n",
      "Epoch: 0153 train_loss= 0.71799 time= 0.36581\n",
      "val_roc= 0.70328 val_ap= 0.75920\n",
      "Epoch: 0154 train_loss= 0.71289 time= 0.35491\n",
      "val_roc= 0.70295 val_ap= 0.76013\n",
      "Epoch: 0155 train_loss= 0.71757 time= 0.36883\n",
      "val_roc= 0.70091 val_ap= 0.75990\n",
      "Epoch: 0156 train_loss= 0.71442 time= 0.45099\n",
      "val_roc= 0.69845 val_ap= 0.75886\n",
      "Epoch: 0157 train_loss= 0.71370 time= 0.39122\n",
      "val_roc= 0.69645 val_ap= 0.75813\n",
      "Epoch: 0158 train_loss= 0.71369 time= 0.37409\n",
      "val_roc= 0.69519 val_ap= 0.75796\n",
      "Epoch: 0159 train_loss= 0.70965 time= 0.40484\n",
      "val_roc= 0.69240 val_ap= 0.75609\n",
      "Epoch: 0160 train_loss= 0.70817 time= 0.34089\n",
      "val_roc= 0.68943 val_ap= 0.75448\n",
      "Epoch: 0161 train_loss= 0.70923 time= 0.31390\n",
      "val_roc= 0.68714 val_ap= 0.75324\n",
      "Epoch: 0162 train_loss= 0.70970 time= 0.33461\n",
      "val_roc= 0.68498 val_ap= 0.75229\n",
      "Epoch: 0163 train_loss= 0.70863 time= 0.45492\n",
      "val_roc= 0.68258 val_ap= 0.75108\n",
      "Epoch: 0164 train_loss= 0.70710 time= 0.34695\n",
      "val_roc= 0.67807 val_ap= 0.74942\n",
      "Epoch: 0165 train_loss= 0.70724 time= 0.32856\n",
      "val_roc= 0.67454 val_ap= 0.74819\n",
      "Epoch: 0166 train_loss= 0.70523 time= 0.32528\n",
      "val_roc= 0.67078 val_ap= 0.74678\n",
      "Epoch: 0167 train_loss= 0.70531 time= 0.34443\n",
      "val_roc= 0.66785 val_ap= 0.74547\n",
      "Epoch: 0168 train_loss= 0.70477 time= 0.32908\n",
      "val_roc= 0.66591 val_ap= 0.74441\n",
      "Epoch: 0169 train_loss= 0.70408 time= 0.32558\n",
      "val_roc= 0.66470 val_ap= 0.74374\n",
      "Epoch: 0170 train_loss= 0.70565 time= 0.32383\n",
      "val_roc= 0.66377 val_ap= 0.74329\n",
      "Epoch: 0171 train_loss= 0.70817 time= 0.38346\n",
      "val_roc= 0.66294 val_ap= 0.74306\n",
      "Epoch: 0172 train_loss= 0.70518 time= 0.33940\n",
      "val_roc= 0.66197 val_ap= 0.74298\n",
      "Epoch: 0173 train_loss= 0.70483 time= 0.32384\n",
      "val_roc= 0.66040 val_ap= 0.74197\n",
      "Epoch: 0174 train_loss= 0.70337 time= 0.34437\n",
      "val_roc= 0.65873 val_ap= 0.74096\n",
      "Epoch: 0175 train_loss= 0.70514 time= 0.35618\n",
      "val_roc= 0.65779 val_ap= 0.74043\n",
      "Epoch: 0176 train_loss= 0.70173 time= 0.29668\n",
      "val_roc= 0.65651 val_ap= 0.73980\n",
      "Epoch: 0177 train_loss= 0.70366 time= 0.33271\n",
      "val_roc= 0.65490 val_ap= 0.73896\n",
      "Epoch: 0178 train_loss= 0.70753 time= 0.33739\n",
      "val_roc= 0.65380 val_ap= 0.73849\n",
      "Epoch: 0179 train_loss= 0.70483 time= 0.33163\n",
      "val_roc= 0.65255 val_ap= 0.73761\n",
      "Epoch: 0180 train_loss= 0.70082 time= 0.35376\n",
      "val_roc= 0.65139 val_ap= 0.73676\n",
      "Epoch: 0181 train_loss= 0.70294 time= 0.42647\n",
      "val_roc= 0.65026 val_ap= 0.73581\n",
      "Epoch: 0182 train_loss= 0.70085 time= 0.46684\n",
      "val_roc= 0.64959 val_ap= 0.73502\n",
      "Epoch: 0183 train_loss= 0.70301 time= 0.48762\n",
      "val_roc= 0.64842 val_ap= 0.73438\n",
      "Epoch: 0184 train_loss= 0.69752 time= 0.33300\n",
      "val_roc= 0.64627 val_ap= 0.73312\n",
      "Epoch: 0185 train_loss= 0.70390 time= 0.39221\n",
      "val_roc= 0.64547 val_ap= 0.73274\n",
      "Epoch: 0186 train_loss= 0.70377 time= 0.33000\n",
      "val_roc= 0.64466 val_ap= 0.73253\n",
      "Epoch: 0187 train_loss= 0.70146 time= 0.34448\n",
      "val_roc= 0.64351 val_ap= 0.73229\n",
      "Epoch: 0188 train_loss= 0.69881 time= 0.34551\n",
      "val_roc= 0.64277 val_ap= 0.73176\n",
      "Epoch: 0189 train_loss= 0.70001 time= 0.30862\n",
      "val_roc= 0.64153 val_ap= 0.73111\n",
      "Epoch: 0190 train_loss= 0.70166 time= 0.33974\n",
      "val_roc= 0.64066 val_ap= 0.73098\n",
      "Epoch: 0191 train_loss= 0.70031 time= 0.32576\n",
      "val_roc= 0.63988 val_ap= 0.73074\n",
      "Epoch: 0192 train_loss= 0.70103 time= 0.31478\n",
      "val_roc= 0.63922 val_ap= 0.73068\n",
      "Epoch: 0193 train_loss= 0.69720 time= 0.31819\n",
      "val_roc= 0.63808 val_ap= 0.73029\n",
      "Epoch: 0194 train_loss= 0.69925 time= 0.33258\n",
      "val_roc= 0.63744 val_ap= 0.73025\n",
      "Epoch: 0195 train_loss= 0.69864 time= 0.32914\n",
      "val_roc= 0.63705 val_ap= 0.73020\n",
      "Epoch: 0196 train_loss= 0.69829 time= 0.36948\n",
      "val_roc= 0.63639 val_ap= 0.73020\n",
      "Epoch: 0197 train_loss= 0.69571 time= 0.33283\n",
      "val_roc= 0.63608 val_ap= 0.73013\n",
      "Epoch: 0198 train_loss= 0.69883 time= 0.33956\n",
      "val_roc= 0.63546 val_ap= 0.73000\n",
      "Epoch: 0199 train_loss= 0.69561 time= 0.33704\n",
      "val_roc= 0.63519 val_ap= 0.73004\n",
      "Epoch: 0200 train_loss= 0.69961 time= 0.33105\n",
      "val_roc= 0.63468 val_ap= 0.72976\n",
      "Testing model...\n",
      "Masking test edges...\n",
      "Preprocessing and Initializing...\n",
      "Training...\n",
      "Epoch: 0001 train_loss= 1.74405 time= 2.29692\n",
      "val_roc= 0.69098 val_ap= 0.71429\n",
      "Epoch: 0002 train_loss= 1.69199 time= 0.31358\n",
      "val_roc= 0.50001 val_ap= 0.50000\n",
      "Epoch: 0003 train_loss= 514714.25000 time= 0.28935\n",
      "val_roc= 0.69757 val_ap= 0.72780\n",
      "Epoch: 0004 train_loss= 1.65885 time= 0.33381\n",
      "val_roc= 0.67142 val_ap= 0.68337\n",
      "Epoch: 0005 train_loss= 1.74134 time= 0.29099\n",
      "val_roc= 0.65872 val_ap= 0.65507\n",
      "Epoch: 0006 train_loss= 1.73804 time= 0.52259\n",
      "val_roc= 0.61122 val_ap= 0.57346\n",
      "Epoch: 0007 train_loss= 1.71246 time= 0.39483\n",
      "val_roc= 0.58811 val_ap= 0.57443\n",
      "Epoch: 0008 train_loss= 1.74269 time= 0.28048\n",
      "val_roc= 0.55727 val_ap= 0.55053\n",
      "Epoch: 0009 train_loss= 1.70300 time= 0.31052\n",
      "val_roc= 0.62335 val_ap= 0.59921\n",
      "Epoch: 0010 train_loss= 1.73839 time= 0.35338\n",
      "val_roc= 0.55439 val_ap= 0.55213\n",
      "Epoch: 0011 train_loss= 1.70237 time= 0.32785\n",
      "val_roc= 0.65582 val_ap= 0.65586\n",
      "Epoch: 0012 train_loss= 1.74103 time= 0.43863\n",
      "val_roc= 0.65083 val_ap= 0.68428\n",
      "Epoch: 0013 train_loss= 1.70401 time= 0.38487\n",
      "val_roc= 0.64955 val_ap= 0.68986\n",
      "Epoch: 0014 train_loss= 1.71812 time= 0.42025\n",
      "val_roc= 0.64777 val_ap= 0.68657\n",
      "Epoch: 0015 train_loss= 1.73815 time= 0.32937\n",
      "val_roc= 0.64662 val_ap= 0.68331\n",
      "Epoch: 0016 train_loss= 1.70396 time= 0.30973\n",
      "val_roc= 0.64688 val_ap= 0.68088\n",
      "Epoch: 0017 train_loss= 1.71389 time= 0.32189\n",
      "val_roc= 0.64728 val_ap= 0.68059\n",
      "Epoch: 0018 train_loss= 1.65945 time= 0.37303\n",
      "val_roc= 0.64911 val_ap= 0.68244\n",
      "Epoch: 0019 train_loss= 1.48651 time= 0.33147\n",
      "val_roc= 0.65117 val_ap= 0.68399\n",
      "Epoch: 0020 train_loss= 2.53474 time= 0.30553\n",
      "val_roc= 0.65084 val_ap= 0.68446\n",
      "Epoch: 0021 train_loss= 1.44014 time= 0.31999\n",
      "val_roc= 0.65080 val_ap= 0.68500\n",
      "Epoch: 0022 train_loss= 1.50397 time= 0.28617\n",
      "val_roc= 0.65057 val_ap= 0.68510\n",
      "Epoch: 0023 train_loss= 1.58708 time= 0.31894\n",
      "val_roc= 0.65057 val_ap= 0.68557\n",
      "Epoch: 0024 train_loss= 1.65118 time= 0.33822\n",
      "val_roc= 0.65059 val_ap= 0.68573\n",
      "Epoch: 0025 train_loss= 1.69401 time= 0.32410\n",
      "val_roc= 0.65072 val_ap= 0.68644\n",
      "Epoch: 0026 train_loss= 1.70953 time= 0.33349\n",
      "val_roc= 0.65141 val_ap= 0.68828\n",
      "Epoch: 0027 train_loss= 1.68584 time= 0.32910\n",
      "val_roc= 0.65095 val_ap= 0.68850\n",
      "Epoch: 0028 train_loss= 1.66438 time= 0.31087\n",
      "val_roc= 0.65133 val_ap= 0.68954\n",
      "Epoch: 0029 train_loss= 1.73574 time= 0.27523\n",
      "val_roc= 0.65190 val_ap= 0.69045\n",
      "Epoch: 0030 train_loss= 1.69191 time= 0.31404\n",
      "val_roc= 0.65267 val_ap= 0.69165\n",
      "Epoch: 0031 train_loss= 1.72380 time= 0.33468\n",
      "val_roc= 0.65322 val_ap= 0.69245\n",
      "Epoch: 0032 train_loss= 1.70915 time= 0.33433\n",
      "val_roc= 0.65317 val_ap= 0.69298\n",
      "Epoch: 0033 train_loss= 1.70951 time= 0.29427\n",
      "val_roc= 0.65331 val_ap= 0.69417\n",
      "Epoch: 0034 train_loss= 1.72314 time= 0.33445\n",
      "val_roc= 0.65376 val_ap= 0.69523\n",
      "Epoch: 0035 train_loss= 1.71801 time= 0.29000\n",
      "val_roc= 0.65388 val_ap= 0.69536\n",
      "Epoch: 0036 train_loss= 1.72457 time= 0.30492\n",
      "val_roc= 0.65365 val_ap= 0.69495\n",
      "Epoch: 0037 train_loss= 1.69790 time= 0.31562\n",
      "val_roc= 0.65442 val_ap= 0.69535\n",
      "Epoch: 0038 train_loss= 1.69698 time= 0.35521\n",
      "val_roc= 0.65557 val_ap= 0.69605\n",
      "Epoch: 0039 train_loss= 1.73791 time= 0.28474\n",
      "val_roc= 0.65617 val_ap= 0.69783\n",
      "Epoch: 0040 train_loss= 1.78645 time= 0.32603\n",
      "val_roc= 0.65651 val_ap= 0.69800\n",
      "Epoch: 0041 train_loss= 1.70029 time= 0.32115\n",
      "val_roc= 0.65674 val_ap= 0.69819\n",
      "Epoch: 0042 train_loss= 1.71811 time= 0.37338\n",
      "val_roc= 0.65689 val_ap= 0.69907\n",
      "Epoch: 0043 train_loss= 1.68924 time= 0.30805\n",
      "val_roc= 0.65708 val_ap= 0.69949\n",
      "Epoch: 0044 train_loss= 1.64721 time= 0.31902\n",
      "val_roc= 0.65705 val_ap= 0.69969\n",
      "Epoch: 0045 train_loss= 1.69650 time= 0.35126\n",
      "val_roc= 0.65738 val_ap= 0.70011\n",
      "Epoch: 0046 train_loss= 1.70474 time= 0.26973\n",
      "val_roc= 0.65758 val_ap= 0.70048\n",
      "Epoch: 0047 train_loss= 1.65833 time= 0.33272\n",
      "val_roc= 0.65788 val_ap= 0.70096\n",
      "Epoch: 0048 train_loss= 1.57798 time= 0.39096\n",
      "val_roc= 0.65817 val_ap= 0.70170\n",
      "Epoch: 0049 train_loss= 1.48962 time= 0.35113\n",
      "val_roc= 0.65852 val_ap= 0.70214\n",
      "Epoch: 0050 train_loss= 1.34725 time= 0.32661\n",
      "val_roc= 0.65891 val_ap= 0.70257\n",
      "Epoch: 0051 train_loss= 1.17713 time= 0.29680\n",
      "val_roc= 0.65969 val_ap= 0.70355\n",
      "Epoch: 0052 train_loss= 1.08338 time= 0.32141\n",
      "val_roc= 0.66062 val_ap= 0.70535\n",
      "Epoch: 0053 train_loss= 1.32730 time= 0.31906\n",
      "val_roc= 0.66073 val_ap= 0.70626\n",
      "Epoch: 0054 train_loss= 1.04796 time= 0.32484\n",
      "val_roc= 0.66106 val_ap= 0.70709\n",
      "Epoch: 0055 train_loss= 1.05828 time= 0.31684\n",
      "val_roc= 0.66155 val_ap= 0.70789\n",
      "Epoch: 0056 train_loss= 1.09592 time= 0.33001\n",
      "val_roc= 0.66209 val_ap= 0.70952\n",
      "Epoch: 0057 train_loss= 1.11857 time= 0.28108\n",
      "val_roc= 0.66297 val_ap= 0.71051\n",
      "Epoch: 0058 train_loss= 1.07934 time= 0.32617\n",
      "val_roc= 0.66328 val_ap= 0.71160\n",
      "Epoch: 0059 train_loss= 1.02839 time= 0.33119\n",
      "val_roc= 0.66456 val_ap= 0.71294\n",
      "Epoch: 0060 train_loss= 0.94730 time= 0.33339\n",
      "val_roc= 0.66601 val_ap= 0.71511\n",
      "Epoch: 0061 train_loss= 0.86544 time= 0.32636\n",
      "val_roc= 0.66652 val_ap= 0.71688\n",
      "Epoch: 0062 train_loss= 0.86627 time= 0.32552\n",
      "val_roc= 0.66640 val_ap= 0.71739\n",
      "Epoch: 0063 train_loss= 0.91678 time= 0.32610\n",
      "val_roc= 0.66700 val_ap= 0.71843\n",
      "Epoch: 0064 train_loss= 0.84298 time= 0.31256\n",
      "val_roc= 0.66764 val_ap= 0.71906\n",
      "Epoch: 0065 train_loss= 0.78610 time= 0.32355\n",
      "val_roc= 0.66780 val_ap= 0.71990\n",
      "Epoch: 0066 train_loss= 0.78573 time= 0.40563\n",
      "val_roc= 0.66826 val_ap= 0.72149\n",
      "Epoch: 0067 train_loss= 0.79020 time= 0.32716\n",
      "val_roc= 0.66863 val_ap= 0.72225\n",
      "Epoch: 0068 train_loss= 0.78978 time= 0.38060\n",
      "val_roc= 0.66910 val_ap= 0.72284\n",
      "Epoch: 0069 train_loss= 0.78754 time= 0.31608\n",
      "val_roc= 0.66955 val_ap= 0.72348\n",
      "Epoch: 0070 train_loss= 0.77293 time= 0.27484\n",
      "val_roc= 0.66980 val_ap= 0.72345\n",
      "Epoch: 0071 train_loss= 0.76089 time= 0.30205\n",
      "val_roc= 0.67017 val_ap= 0.72447\n",
      "Epoch: 0072 train_loss= 0.75467 time= 0.32669\n",
      "val_roc= 0.67034 val_ap= 0.72462\n",
      "Epoch: 0073 train_loss= 0.75262 time= 0.32608\n",
      "val_roc= 0.67052 val_ap= 0.72482\n",
      "Epoch: 0074 train_loss= 0.76389 time= 0.28318\n",
      "val_roc= 0.67057 val_ap= 0.72525\n",
      "Epoch: 0075 train_loss= 0.76412 time= 0.31927\n",
      "val_roc= 0.67083 val_ap= 0.72582\n",
      "Epoch: 0076 train_loss= 0.75400 time= 0.28992\n",
      "val_roc= 0.67098 val_ap= 0.72623\n",
      "Epoch: 0077 train_loss= 0.74741 time= 0.40704\n",
      "val_roc= 0.67119 val_ap= 0.72690\n",
      "Epoch: 0078 train_loss= 0.74487 time= 0.32628\n",
      "val_roc= 0.67141 val_ap= 0.72781\n",
      "Epoch: 0079 train_loss= 0.74947 time= 0.33446\n",
      "val_roc= 0.67149 val_ap= 0.72841\n",
      "Epoch: 0080 train_loss= 0.74687 time= 0.29636\n",
      "val_roc= 0.67152 val_ap= 0.72868\n",
      "Epoch: 0081 train_loss= 0.74999 time= 0.31903\n",
      "val_roc= 0.67143 val_ap= 0.72924\n",
      "Epoch: 0082 train_loss= 0.74752 time= 0.32149\n",
      "val_roc= 0.67090 val_ap= 0.72915\n",
      "Epoch: 0083 train_loss= 0.74081 time= 0.34902\n",
      "val_roc= 0.66989 val_ap= 0.72845\n",
      "Epoch: 0084 train_loss= 0.74205 time= 0.31718\n",
      "val_roc= 0.66929 val_ap= 0.72836\n",
      "Epoch: 0085 train_loss= 0.73743 time= 0.29491\n",
      "val_roc= 0.66803 val_ap= 0.72744\n",
      "Epoch: 0086 train_loss= 0.73627 time= 0.31864\n",
      "val_roc= 0.66803 val_ap= 0.72795\n",
      "Epoch: 0087 train_loss= 0.73666 time= 0.31828\n",
      "val_roc= 0.66739 val_ap= 0.72793\n",
      "Epoch: 0088 train_loss= 0.73805 time= 0.31702\n",
      "val_roc= 0.66720 val_ap= 0.72859\n",
      "Epoch: 0089 train_loss= 0.73442 time= 0.30435\n",
      "val_roc= 0.66727 val_ap= 0.72900\n",
      "Epoch: 0090 train_loss= 0.72933 time= 0.26470\n",
      "val_roc= 0.66632 val_ap= 0.72898\n",
      "Epoch: 0091 train_loss= 0.73397 time= 0.31365\n",
      "val_roc= 0.66644 val_ap= 0.72951\n",
      "Epoch: 0092 train_loss= 0.72945 time= 0.27453\n",
      "val_roc= 0.66627 val_ap= 0.72965\n",
      "Epoch: 0093 train_loss= 0.72877 time= 0.31957\n",
      "val_roc= 0.66638 val_ap= 0.73009\n",
      "Epoch: 0094 train_loss= 0.72699 time= 0.30214\n",
      "val_roc= 0.66497 val_ap= 0.72935\n",
      "Epoch: 0095 train_loss= 0.72734 time= 0.32302\n",
      "val_roc= 0.66446 val_ap= 0.72925\n",
      "Epoch: 0096 train_loss= 0.72772 time= 0.30857\n",
      "val_roc= 0.66349 val_ap= 0.72872\n",
      "Epoch: 0097 train_loss= 0.72557 time= 0.31489\n",
      "val_roc= 0.66273 val_ap= 0.72816\n",
      "Epoch: 0098 train_loss= 0.72292 time= 0.36702\n",
      "val_roc= 0.66083 val_ap= 0.72738\n",
      "Epoch: 0099 train_loss= 0.72513 time= 0.32784\n",
      "val_roc= 0.65835 val_ap= 0.72613\n",
      "Epoch: 0100 train_loss= 0.72230 time= 0.33235\n",
      "val_roc= 0.65579 val_ap= 0.72545\n",
      "Epoch: 0101 train_loss= 0.72070 time= 0.30778\n",
      "val_roc= 0.65330 val_ap= 0.72523\n",
      "Epoch: 0102 train_loss= 0.72164 time= 0.32127\n",
      "val_roc= 0.65101 val_ap= 0.72413\n",
      "Epoch: 0103 train_loss= 0.72146 time= 0.29400\n",
      "val_roc= 0.65057 val_ap= 0.72475\n",
      "Epoch: 0104 train_loss= 0.71886 time= 0.31233\n",
      "val_roc= 0.64946 val_ap= 0.72497\n",
      "Epoch: 0105 train_loss= 0.71583 time= 0.32267\n",
      "val_roc= 0.64863 val_ap= 0.72500\n",
      "Epoch: 0106 train_loss= 0.71495 time= 0.30251\n",
      "val_roc= 0.64818 val_ap= 0.72518\n",
      "Epoch: 0107 train_loss= 0.71312 time= 0.32196\n",
      "val_roc= 0.64624 val_ap= 0.72496\n",
      "Epoch: 0108 train_loss= 0.71413 time= 0.31739\n",
      "val_roc= 0.64550 val_ap= 0.72535\n",
      "Epoch: 0109 train_loss= 0.71182 time= 0.27279\n",
      "val_roc= 0.64410 val_ap= 0.72475\n",
      "Epoch: 0110 train_loss= 0.71284 time= 0.32230\n",
      "val_roc= 0.64051 val_ap= 0.72280\n",
      "Epoch: 0111 train_loss= 0.70918 time= 0.33678\n",
      "val_roc= 0.63719 val_ap= 0.72118\n",
      "Epoch: 0112 train_loss= 0.70969 time= 0.32481\n",
      "val_roc= 0.63551 val_ap= 0.72026\n",
      "Epoch: 0113 train_loss= 0.71094 time= 0.31644\n",
      "val_roc= 0.63380 val_ap= 0.71928\n",
      "Epoch: 0114 train_loss= 0.71109 time= 0.31680\n",
      "val_roc= 0.63244 val_ap= 0.71843\n",
      "Epoch: 0115 train_loss= 0.70629 time= 0.28258\n",
      "val_roc= 0.63126 val_ap= 0.71774\n",
      "Epoch: 0116 train_loss= 0.70910 time= 0.31946\n",
      "val_roc= 0.63058 val_ap= 0.71724\n",
      "Epoch: 0117 train_loss= 0.70637 time= 0.33200\n",
      "val_roc= 0.63071 val_ap= 0.71727\n",
      "Epoch: 0118 train_loss= 0.70721 time= 0.33371\n",
      "val_roc= 0.62998 val_ap= 0.71686\n",
      "Epoch: 0119 train_loss= 0.70466 time= 0.32404\n",
      "val_roc= 0.63003 val_ap= 0.71708\n",
      "Epoch: 0120 train_loss= 0.70669 time= 0.28652\n",
      "val_roc= 0.62968 val_ap= 0.71681\n",
      "Epoch: 0121 train_loss= 0.70801 time= 0.25187\n",
      "val_roc= 0.62945 val_ap= 0.71643\n",
      "Epoch: 0122 train_loss= 0.70555 time= 0.30213\n",
      "val_roc= 0.63023 val_ap= 0.71701\n",
      "Epoch: 0123 train_loss= 0.70410 time= 0.33472\n",
      "val_roc= 0.63033 val_ap= 0.71700\n",
      "Epoch: 0124 train_loss= 0.70149 time= 0.29044\n",
      "val_roc= 0.63054 val_ap= 0.71689\n",
      "Epoch: 0125 train_loss= 0.70487 time= 0.31498\n",
      "val_roc= 0.63118 val_ap= 0.71722\n",
      "Epoch: 0126 train_loss= 0.70380 time= 0.32298\n",
      "val_roc= 0.63093 val_ap= 0.71700\n",
      "Epoch: 0127 train_loss= 0.70231 time= 0.29591\n",
      "val_roc= 0.63064 val_ap= 0.71680\n",
      "Epoch: 0128 train_loss= 0.70331 time= 0.31456\n",
      "val_roc= 0.62978 val_ap= 0.71624\n",
      "Epoch: 0129 train_loss= 0.69980 time= 0.26905\n",
      "val_roc= 0.62908 val_ap= 0.71595\n",
      "Epoch: 0130 train_loss= 0.70007 time= 0.33335\n",
      "val_roc= 0.62836 val_ap= 0.71579\n",
      "Epoch: 0131 train_loss= 0.70186 time= 0.33946\n",
      "val_roc= 0.62802 val_ap= 0.71584\n",
      "Epoch: 0132 train_loss= 0.70322 time= 0.32277\n",
      "val_roc= 0.62802 val_ap= 0.71575\n",
      "Epoch: 0133 train_loss= 0.69986 time= 0.33095\n",
      "val_roc= 0.62745 val_ap= 0.71542\n",
      "Epoch: 0134 train_loss= 0.70078 time= 0.31709\n",
      "val_roc= 0.62607 val_ap= 0.71473\n",
      "Epoch: 0135 train_loss= 0.69950 time= 0.31648\n",
      "val_roc= 0.62454 val_ap= 0.71421\n",
      "Epoch: 0136 train_loss= 0.69925 time= 0.34952\n",
      "val_roc= 0.62386 val_ap= 0.71391\n",
      "Epoch: 0137 train_loss= 0.70127 time= 0.30487\n",
      "val_roc= 0.62314 val_ap= 0.71423\n",
      "Epoch: 0138 train_loss= 0.70291 time= 0.34517\n",
      "val_roc= 0.62270 val_ap= 0.71436\n",
      "Epoch: 0139 train_loss= 0.69967 time= 0.31892\n",
      "val_roc= 0.62149 val_ap= 0.71346\n",
      "Epoch: 0140 train_loss= 0.70085 time= 0.31700\n",
      "val_roc= 0.61992 val_ap= 0.71271\n",
      "Epoch: 0141 train_loss= 0.69870 time= 0.32737\n",
      "val_roc= 0.61695 val_ap= 0.71164\n",
      "Epoch: 0142 train_loss= 0.69590 time= 0.30502\n",
      "val_roc= 0.61373 val_ap= 0.71037\n",
      "Epoch: 0143 train_loss= 0.69921 time= 0.29623\n",
      "val_roc= 0.61290 val_ap= 0.71031\n",
      "Epoch: 0144 train_loss= 0.69783 time= 0.31069\n",
      "val_roc= 0.61241 val_ap= 0.71038\n",
      "Epoch: 0145 train_loss= 0.69900 time= 0.30907\n",
      "val_roc= 0.61266 val_ap= 0.71070\n",
      "Epoch: 0146 train_loss= 0.69803 time= 0.30459\n",
      "val_roc= 0.61265 val_ap= 0.71104\n",
      "Epoch: 0147 train_loss= 0.69914 time= 0.30176\n",
      "val_roc= 0.61204 val_ap= 0.71100\n",
      "Epoch: 0148 train_loss= 0.69896 time= 0.32772\n",
      "val_roc= 0.61111 val_ap= 0.71108\n",
      "Epoch: 0149 train_loss= 0.69671 time= 0.32270\n",
      "val_roc= 0.60939 val_ap= 0.71075\n",
      "Epoch: 0150 train_loss= 0.69670 time= 0.31085\n",
      "val_roc= 0.60826 val_ap= 0.71071\n",
      "Epoch: 0151 train_loss= 0.69412 time= 0.32612\n",
      "val_roc= 0.60774 val_ap= 0.71071\n",
      "Epoch: 0152 train_loss= 0.69911 time= 0.33266\n",
      "val_roc= 0.60808 val_ap= 0.71082\n",
      "Epoch: 0153 train_loss= 0.69417 time= 0.32894\n",
      "val_roc= 0.60874 val_ap= 0.71091\n",
      "Epoch: 0154 train_loss= 0.69519 time= 0.28876\n",
      "val_roc= 0.60847 val_ap= 0.71067\n",
      "Epoch: 0155 train_loss= 0.69351 time= 0.27564\n",
      "val_roc= 0.60845 val_ap= 0.71057\n",
      "Epoch: 0156 train_loss= 0.69649 time= 0.30922\n",
      "val_roc= 0.60853 val_ap= 0.71067\n",
      "Epoch: 0157 train_loss= 0.69382 time= 0.29582\n",
      "val_roc= 0.60774 val_ap= 0.71041\n",
      "Epoch: 0158 train_loss= 0.69436 time= 0.31106\n",
      "val_roc= 0.60739 val_ap= 0.71023\n",
      "Epoch: 0159 train_loss= 0.69665 time= 0.29353\n",
      "val_roc= 0.60793 val_ap= 0.71042\n",
      "Epoch: 0160 train_loss= 0.69390 time= 0.25922\n",
      "val_roc= 0.60795 val_ap= 0.71004\n",
      "Epoch: 0161 train_loss= 0.69619 time= 0.25483\n",
      "val_roc= 0.60764 val_ap= 0.70964\n",
      "Epoch: 0162 train_loss= 0.69579 time= 0.30516\n",
      "val_roc= 0.60824 val_ap= 0.70971\n",
      "Epoch: 0163 train_loss= 0.69663 time= 0.33199\n",
      "val_roc= 0.60774 val_ap= 0.70954\n",
      "Epoch: 0164 train_loss= 0.69462 time= 0.29893\n",
      "val_roc= 0.60783 val_ap= 0.70956\n",
      "Epoch: 0165 train_loss= 0.69474 time= 0.30551\n",
      "val_roc= 0.60750 val_ap= 0.70934\n",
      "Epoch: 0166 train_loss= 0.69460 time= 0.26709\n",
      "val_roc= 0.60739 val_ap= 0.70920\n",
      "Epoch: 0167 train_loss= 0.69529 time= 0.26968\n",
      "val_roc= 0.60708 val_ap= 0.70908\n",
      "Epoch: 0168 train_loss= 0.69299 time= 0.26035\n",
      "val_roc= 0.60702 val_ap= 0.70901\n",
      "Epoch: 0169 train_loss= 0.69642 time= 0.27891\n",
      "val_roc= 0.60733 val_ap= 0.70944\n",
      "Epoch: 0170 train_loss= 0.69392 time= 0.32581\n",
      "val_roc= 0.60830 val_ap= 0.70996\n",
      "Epoch: 0171 train_loss= 0.69577 time= 0.37619\n",
      "val_roc= 0.60828 val_ap= 0.71010\n",
      "Epoch: 0172 train_loss= 0.69726 time= 0.26552\n",
      "val_roc= 0.60929 val_ap= 0.71057\n",
      "Epoch: 0173 train_loss= 0.69453 time= 0.32939\n",
      "val_roc= 0.60966 val_ap= 0.71066\n",
      "Epoch: 0174 train_loss= 0.69301 time= 0.31189\n",
      "val_roc= 0.60944 val_ap= 0.71076\n",
      "Epoch: 0175 train_loss= 0.69310 time= 0.32314\n",
      "val_roc= 0.60946 val_ap= 0.71099\n",
      "Epoch: 0176 train_loss= 0.69433 time= 0.31972\n",
      "val_roc= 0.60931 val_ap= 0.71078\n",
      "Epoch: 0177 train_loss= 0.69224 time= 0.33518\n",
      "val_roc= 0.60954 val_ap= 0.71094\n",
      "Epoch: 0178 train_loss= 0.68861 time= 0.31813\n",
      "val_roc= 0.60950 val_ap= 0.71095\n",
      "Epoch: 0179 train_loss= 0.69225 time= 0.32469\n",
      "val_roc= 0.60999 val_ap= 0.71117\n",
      "Epoch: 0180 train_loss= 0.68933 time= 0.27812\n",
      "val_roc= 0.60948 val_ap= 0.71113\n",
      "Epoch: 0181 train_loss= 0.69573 time= 0.33083\n",
      "val_roc= 0.60917 val_ap= 0.71103\n",
      "Epoch: 0182 train_loss= 0.69380 time= 0.31308\n",
      "val_roc= 0.60973 val_ap= 0.71122\n",
      "Epoch: 0183 train_loss= 0.69263 time= 0.27992\n",
      "val_roc= 0.60836 val_ap= 0.71064\n",
      "Epoch: 0184 train_loss= 0.69298 time= 0.31520\n",
      "val_roc= 0.60661 val_ap= 0.71017\n",
      "Epoch: 0185 train_loss= 0.69432 time= 0.36368\n",
      "val_roc= 0.60589 val_ap= 0.70986\n",
      "Epoch: 0186 train_loss= 0.69232 time= 0.35440\n",
      "val_roc= 0.60546 val_ap= 0.70941\n",
      "Epoch: 0187 train_loss= 0.69689 time= 0.32287\n",
      "val_roc= 0.60570 val_ap= 0.70958\n",
      "Epoch: 0188 train_loss= 0.69301 time= 0.33025\n",
      "val_roc= 0.60562 val_ap= 0.70952\n",
      "Epoch: 0189 train_loss= 0.69241 time= 0.32413\n",
      "val_roc= 0.60611 val_ap= 0.70964\n",
      "Epoch: 0190 train_loss= 0.69060 time= 0.32770\n",
      "val_roc= 0.60680 val_ap= 0.70974\n",
      "Epoch: 0191 train_loss= 0.69445 time= 0.32156\n",
      "val_roc= 0.60717 val_ap= 0.70985\n",
      "Epoch: 0192 train_loss= 0.69091 time= 0.28836\n",
      "val_roc= 0.60779 val_ap= 0.70992\n",
      "Epoch: 0193 train_loss= 0.69245 time= 0.33296\n",
      "val_roc= 0.60859 val_ap= 0.71032\n",
      "Epoch: 0194 train_loss= 0.69303 time= 0.31270\n",
      "val_roc= 0.60929 val_ap= 0.71058\n",
      "Epoch: 0195 train_loss= 0.69222 time= 0.33331\n",
      "val_roc= 0.60956 val_ap= 0.71041\n",
      "Epoch: 0196 train_loss= 0.69016 time= 0.30200\n",
      "val_roc= 0.60927 val_ap= 0.71036\n",
      "Epoch: 0197 train_loss= 0.69246 time= 0.32495\n",
      "val_roc= 0.60942 val_ap= 0.71065\n",
      "Epoch: 0198 train_loss= 0.68920 time= 0.30474\n",
      "val_roc= 0.60900 val_ap= 0.71039\n",
      "Epoch: 0199 train_loss= 0.69001 time= 0.31851\n",
      "val_roc= 0.60867 val_ap= 0.70961\n",
      "Epoch: 0200 train_loss= 0.69214 time= 0.31121\n",
      "val_roc= 0.60952 val_ap= 0.70990\n",
      "Testing model...\n",
      "Masking test edges...\n",
      "Preprocessing and Initializing...\n",
      "Training...\n",
      "Epoch: 0001 train_loss= 1.76421 time= 2.38876\n",
      "val_roc= 0.68497 val_ap= 0.70353\n",
      "Epoch: 0002 train_loss= 1.61942 time= 0.35373\n",
      "val_roc= 0.50000 val_ap= 0.50000\n",
      "Epoch: 0003 train_loss= 57158853304655271690240.00000 time= 0.32831\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-cad3da40b5e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mplaceholders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dropout'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                 \u001b[0mval_roc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_roc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_edges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_edges_false\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"val_roc=\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"{:.5f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_roc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val_ap=\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"{:.5f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_ap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Done_Results/GAE_VGAE_Results/GVAE_Pubmed_36/linear_gae/evaluation.py\u001b[0m in \u001b[0;36mget_roc_score\u001b[0;34m(edges_pos, edges_neg, emb)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mlabels_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_neg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mroc_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0map_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage_precision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mroc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0map_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     if y_type == \"multiclass\" or (y_type == \"binary\" and\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             _assert_all_finite(array,\n\u001b[0m\u001b[1;32m    645\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     95\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m     97\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                     (type_err,\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# The entire training+test process is repeated nb_run times\n",
    "for seed_i in np.arange(nb_run):\n",
    "    seed=seed_i\n",
    "    if task == 'link_prediction' :\n",
    "        if verbose:\n",
    "            print(\"Masking test edges...\")\n",
    "        adj, val_edges, val_edges_false, test_edges, test_edges_false = \\\n",
    "        mask_test_edges(adj_init, seed,prop_test, prop_val)\n",
    "        \n",
    "    # Start computation of running times\n",
    "    t_start = time.time()\n",
    "\n",
    "    if features_used:\n",
    "        features = features_init\n",
    "        \n",
    "    # Preprocessing and initialization\n",
    "    if verbose:\n",
    "        print(\"Preprocessing and Initializing...\")\n",
    "        \n",
    "    # Compute number of nodes\n",
    "    num_nodes = adj.shape[0]\n",
    "    # If features are not used, replace feature matrix by identity matrix\n",
    "    if not features_used:\n",
    "        features = sp.identity(adj.shape[0])\n",
    "    # Preprocessing on node features\n",
    "    features = sparse_to_tuple(features)\n",
    "    num_features = features[2][1]\n",
    "    features_nonzero = features[1].shape[0]\n",
    "    \n",
    "    # Define placeholders\n",
    "    placeholders = {\n",
    "        'features': tf.sparse_placeholder(tf.float32),\n",
    "        'adj': tf.sparse_placeholder(tf.float32),\n",
    "        'adj_orig': tf.sparse_placeholder(tf.float32),\n",
    "        'dropout': tf.placeholder_with_default(0., shape = ())\n",
    "    }\n",
    "\n",
    "    # Create model\n",
    "    if model_name == 'gcn_ae':\n",
    "        # Standard Graph Autoencoder\n",
    "        model = GCNModelAE(placeholders, num_features, features_nonzero)\n",
    "    elif model_name == 'gcn_vae':\n",
    "        # Standard Graph Variational Autoencoder\n",
    "        model = GCNModelVAE(placeholders, num_features, num_nodes,\n",
    "                            features_nonzero)\n",
    "    elif model_name == 'linear_ae':\n",
    "        # Linear Graph Autoencoder\n",
    "        model = LinearModelAE(placeholders, num_features, features_nonzero)\n",
    "    elif model_name == 'linear_vae':\n",
    "        # Linear Graph Variational Autoencoder\n",
    "        model = LinearModelVAE(placeholders, num_features, num_nodes,\n",
    "                               features_nonzero)\n",
    "    elif model_name == 'deep12_gcn_ae':\n",
    "        # Deep (3-layer GCN) Graph Autoencoder\n",
    "        model = Deep12GCNModelAE(placeholders, num_features, features_nonzero)\n",
    "    elif model_name == 'deep_gcn_vae':\n",
    "        # Deep (3-layer GCN) Graph Variational Autoencoder\n",
    "        model = DeepGCNModelVAE(placeholders, num_features, num_nodes,\n",
    "                                features_nonzero)\n",
    "    elif model_name == 'deep6_gcn_vae':\n",
    "        # Deep (3-layer GCN) Graph Autoencoder\n",
    "        model = Deep6GCNModelVAE(placeholders, num_features, num_nodes,features_nonzero)\n",
    "    elif model_name == 'deep12_gcn_vae':\n",
    "        # Deep (3-layer GCN) Graph Autoencoder\n",
    "        model = Deep12GCNModelVAE(placeholders, num_features, num_nodes,features_nonzero)\n",
    "    elif model_name == 'deep18_gcn_vae':\n",
    "        # Deep (3-layer GCN) Graph Autoencoder\n",
    "        model = Deep18GCNModelVAE(placeholders, num_features, num_nodes,features_nonzero)\n",
    "    elif model_name == 'deep36_gcn_vae':\n",
    "        # Deep (3-layer GCN) Graph Autoencoder\n",
    "        model = Deep36GCNModelVAE(placeholders, num_features, num_nodes,features_nonzero)\n",
    "    else:\n",
    "        raise ValueError('Undefined model!')\n",
    "\n",
    "    # Optimizer\n",
    "    pos_weight = float(adj.shape[0] * adj.shape[0] - adj.sum()) / adj.sum()\n",
    "    norm = adj.shape[0] * adj.shape[0] / float((adj.shape[0] * adj.shape[0]\n",
    "                                                - adj.sum()) * 2)\n",
    "    with tf.name_scope('optimizer'):\n",
    "        # Optimizer for Non-Variational Autoencoders\n",
    "        if model_name in ('gcn_ae', 'linear_ae', 'deep_gcn_ae','deep12_gcn_ae'):\n",
    "            opt = OptimizerAE(preds = model.reconstructions,\n",
    "                              labels = tf.reshape(tf.sparse_tensor_to_dense(placeholders['adj_orig'],\n",
    "                                                                            validate_indices = False), [-1]),\n",
    "                              pos_weight = pos_weight,\n",
    "                              norm = norm)\n",
    "\n",
    "            # Optimizer for Variational Autoencoders\n",
    "        elif model_name in ('gcn_vae', 'linear_vae', 'deep_gcn_vae','deep6_gcn_vae','deep12_gcn_vae','deep18_gcn_vae','deep36_gcn_vae'):\n",
    "            opt = OptimizerVAE(preds = model.reconstructions,\n",
    "                               labels = tf.reshape(tf.sparse_tensor_to_dense(placeholders['adj_orig'],\n",
    "                                                                             validate_indices = False), [-1]),\n",
    "                               model = model,\n",
    "                               num_nodes = num_nodes,\n",
    "                               pos_weight = pos_weight,\n",
    "                               norm = norm)\n",
    "\n",
    "    # Normalization and preprocessing on adjacency matrix\n",
    "    adj_norm = preprocess_graph(adj)\n",
    "    adj_label = sparse_to_tuple(adj + sp.eye(adj.shape[0]))\n",
    "\n",
    "    # Initialize TF session\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Model training\n",
    "    if verbose:\n",
    "        print(\"Training...\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Flag to compute running time for each epoch\n",
    "        t = time.time()\n",
    "        # Construct feed dictionary\n",
    "        feed_dict = construct_feed_dict(adj_norm, adj_label, features,\n",
    "                                        placeholders)\n",
    "        feed_dict.update({placeholders['dropout']: dropout})\n",
    "        # Weights update\n",
    "        outs = sess.run([opt.opt_op, opt.cost, opt.accuracy],\n",
    "                        feed_dict = feed_dict)\n",
    "        # Compute average loss\n",
    "        avg_cost = outs[1]\n",
    "        if verbose:\n",
    "            # Display epoch information\n",
    "            print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(avg_cost),\n",
    "                  \"time=\", \"{:.5f}\".format(time.time() - t))\n",
    "            # Validation, for Link Prediction\n",
    "            if not kcore and validation and task == 'link_prediction':\n",
    "                feed_dict.update({placeholders['dropout']: 0})\n",
    "                emb = sess.run(model.z_mean, feed_dict = feed_dict)\n",
    "                feed_dict.update({placeholders['dropout']: dropout})\n",
    "                val_roc, val_ap = get_roc_score(val_edges, val_edges_false, emb)\n",
    "                print(\"val_roc=\", \"{:.5f}\".format(val_roc), \"val_ap=\", \"{:.5f}\".format(val_ap))\n",
    "\n",
    "    # Flag to compute Graph AE/VAE training time\n",
    "    t_model = time.time()\n",
    "\n",
    "    # Compute embedding\n",
    "\n",
    "    # Get embedding from model\n",
    "    emb = sess.run(model.z_mean, feed_dict = feed_dict)\n",
    "    \n",
    "    # Compute mean total running time\n",
    "    mean_time.append(time.time() - t_start)\n",
    "    \n",
    "    # Test model\n",
    "    if verbose:\n",
    "        print(\"Testing model...\")\n",
    "    # Link Prediction: classification edges/non-edges\n",
    "    if task == 'link_prediction':\n",
    "        # Get ROC and AP scores\n",
    "        roc_score, ap_score = get_roc_score(test_edges, test_edges_false, emb)\n",
    "        # Report scores\n",
    "        mean_roc.append(roc_score)\n",
    "        mean_ap.append(ap_score)\n",
    "\n",
    "mean_time_=np.array(mean_time)\n",
    "write_to_csv(mean_time_.reshape(1,len(mean_time_)),output_path+p_model_name+\"_time_\"+str(features_used)+\".csv\")\n",
    "\n",
    "mean_roc_=np.array(mean_roc)\n",
    "write_to_csv(mean_roc_.reshape(1,len(mean_roc_)),output_path+p_model_name+\"_roc_\"+str(features_used)+\".csv\")\n",
    "\n",
    "mean_ap_=np.array(mean_ap)\n",
    "write_to_csv(mean_ap_.reshape(1,len(mean_ap_)),output_path+p_model_name+\"_ap_\"+str(features_used)+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
